<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>拾荒志</title>
  
  <subtitle>虚怀若谷，大智若愚</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://murphypei.github.io/"/>
  <updated>2019-12-24T02:20:18.059Z</updated>
  <id>https://murphypei.github.io/</id>
  
  <author>
    <name>murphypei</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Git-LFS 使用和迁移</title>
    <link href="https://murphypei.github.io//blog/2019/12/git-lfs.html"/>
    <id>https://murphypei.github.io//blog/2019/12/git-lfs.html</id>
    <published>2019-12-23T12:39:50.000Z</published>
    <updated>2019-12-24T02:20:18.059Z</updated>
    
    <content type="html"><![CDATA[<p>一次 Git-LFS 的迁移记录。</p><a id="more"></a><p>网上说了一大堆 Git-LFS 的作用和好处，我觉得都是把官方文档零零碎碎翻译一下。在我看来，对于普通开发者而言，Git-LFS 的作用很简单，就是让你 <strong>pull 代码的时候不用每次都把一大堆大文件一块 pull 下来</strong>，而且我个人使用体验还有切换分支之类的操作都变快了。</p><h3 id="Git-LFS-安装"><a href="#Git-LFS-安装" class="headerlink" title="Git-LFS 安装"></a>Git-LFS 安装</h3><p><code>sudo apt/yum install git-lfs</code> 即可，然后 <code>git lfs install</code>。</p><h3 id="Git-LFS-使用"><a href="#Git-LFS-使用" class="headerlink" title="Git-LFS 使用"></a>Git-LFS 使用</h3><h4 id="追踪和推送"><a href="#追踪和推送" class="headerlink" title="追踪和推送"></a>追踪和推送</h4><p>在一个已经初始化后的 Git 仓库中使用 Git-LFS 来追踪大文件，命令如下：</p><p><code>git lfs track &lt;filepattern&gt;</code></p><p>track 会产生一个 <code>.gitattributes</code> 文件，和 <code>.gitignore</code> 类似，也是 git 自己的文件，用于描述 Git-LFS 的文件名匹配模板。一般而言，文件中的每一行类似这种：</p><p><code>*.pbtxt filter=lfs diff=lfs merge=lfs -text</code></p><p><code>-text</code> 就是表示这个文件<strong>不是文本文件</strong>。其余的就是告诉 Git 在处理 filter、diff、merge 时将 pbtxt 文件通过 LFS 的方式处理，打开 <code>.gitconfig</code> 可以看到相关命令的替换。</p><p>用 Git-LFS track 追踪档案之后，就可以添加、提交和推送到远端目录上，你在首次推上去的时候，会要一些时间将大型档案传输到远端。这里是很多教程很模糊的地方，事实上，Git-LFS 并不是什么魔法，仍然要将文件同步到远端。有的 git 仓库页面会显示 Git-LFS 的标记，gitlab 就可以，好评，tx 自用的工蜂，呵呵。</p><h4 id="拉取"><a href="#拉取" class="headerlink" title="拉取"></a>拉取</h4><p>其他用户使用这个仓库的时候，使用 <code>git clone</code> 会拉取普通的文件，但是 LFS 追踪的文件不会被拉下来。如果这些文件本地没有，则需要使用 <code>git lfs pull</code> 从远程仓库拉取。</p><blockquote><p>现在的 git 貌似是直接能够拉取所有文件，包括 lfs 文件，如果不想拉取 lfs 文件，可以使用 <code>GIT_LFS_SKIP_SMUDGE=1 git clone</code></p></blockquote><p>总结来看，Git-LFS 唯一的目的就是于其他 clone 使用者来说，他们若不需要异动大型档案，就不需要进行git lfs pull 的动作，于是那个原本的大型档案会变成一个130 bytes 的文字档。即使他clone 整个master，也是很小的储存库。Git-LFS 的使用无关档案大小，唯一的重点在于某些档案你想放在 master 内，或是说必须放在master 内，而其他人又不需要同步这个档案的话，就可以使用 Git-LFS 的方式来管理此档案。</p><h3 id="Git-LFS-迁移"><a href="#Git-LFS-迁移" class="headerlink" title="Git-LFS  迁移"></a>Git-LFS  迁移</h3><p>这个才是比较实用的，因为很多仓库是用着用着才想着用 lfs…</p><p>对于一个已经用了一段时间的 Git 仓库，直接执行  <code>git lfs migrate import --include=&quot;*.bin&quot; --everything</code> ，可以将所有本地分支上的匹配文件的提交历史版本都转换为 lfs，这个时候无论你切换到哪个分支，都会出现 <code>.gitattributes</code> 文件，且内容都是一样的。</p><blockquote><p>如果只想更新某个分支的话，可以使用 <code>git lfs migrate import --include=&quot;*.bin&quot; --include-ref=refs/heads/master</code></p></blockquote><p>可以通过 <code>git lfs ls-files</code> 查看哪些文件被转换成 lfs 了。</p><p>切换成功后，就需要把切换之后的本地分支提交到远程仓库了，需要手动 push 更新远程仓库中的各个分支。这里有个极大需要注意的地方，就是转换会更改所有提交的 hash，因此 push 的时候需要使用 force 选项，而当其他人员再次使用 pull 去远程拉取的时候会失败。这里当然可以使用 <code>pull --allow-unrelated-histories</code> 来把远程仓库被修改的历史与本地仓库历史做合并，但是最好是<strong>重新拉取</strong>。</p><p>切换成功后，git 仓库的大小可能并没有变化，主要是之前的提交还在，因此需要做一些清理工作：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git reflog expire --expire-unreachable=now --all</span><br><span class="line">git gc --prune=now</span><br></pre></td></tr></table></figure><p>但是，<strong>如果不是历史记录非常重要的仓库，建议不要像上述这么做，而是重新建立一个新的仓库。个人经验，迁移可以使用，但并没那么美好</strong>。</p><p>附一个迁移相关的<a href="https://github.com/Git-LFS/Git-LFS/wiki/Tutorial" target="_blank" rel="noopener">基础教程</a></p><h3 id="Git-LFS-需要多次输入密码的问题"><a href="#Git-LFS-需要多次输入密码的问题" class="headerlink" title="Git-LFS 需要多次输入密码的问题"></a>Git-LFS 需要多次输入密码的问题</h3><p>解决 Git-LFS 使用导致 push 需要输入多次用户名和密码。</p><p>Linux：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Set git to use the credential memory cache</span></span><br><span class="line">git config --global credential.helper cache</span><br><span class="line"></span><br><span class="line"><span class="comment"># Set the cache to timeout after 1 hour (setting is in seconds)</span></span><br><span class="line">git config --global credential.helper <span class="string">'cache --timeout=3600'</span></span><br></pre></td></tr></table></figure><p>其他平台可以参考：<a href="https://help.github.com/en/github/using-git/caching-your-github-password-in-git" target="_blank" rel="noopener">Caching your GitHub password in Git</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;一次 Git-LFS 的迁移记录。&lt;/p&gt;
    
    </summary>
    
      <category term="Git" scheme="https://murphypei.github.io/categories/Git/"/>
    
    
      <category term="Git" scheme="https://murphypei.github.io/tags/Git/"/>
    
      <category term="LFS" scheme="https://murphypei.github.io/tags/LFS/"/>
    
      <category term="migrate" scheme="https://murphypei.github.io/tags/migrate/"/>
    
      <category term=".gitattributes" scheme="https://murphypei.github.io/tags/gitattributes/"/>
    
  </entry>
  
  <entry>
    <title>聊聊梯度消失和梯度爆炸</title>
    <link href="https://murphypei.github.io//blog/2019/12/sigmoid-gradient.html"/>
    <id>https://murphypei.github.io//blog/2019/12/sigmoid-gradient.html</id>
    <published>2019-12-23T06:33:54.000Z</published>
    <updated>2019-12-24T02:04:56.209Z</updated>
    
    <content type="html"><![CDATA[<p>周末刷知乎看到一个问题，关于如何理解梯度消失和梯度爆炸的。有个回答讲的比较好，就和 sigmoid 函数一起总结一下吧。</p><a id="more"></a><h3 id="梯度消失和爆炸"><a href="#梯度消失和爆炸" class="headerlink" title="梯度消失和爆炸"></a>梯度消失和爆炸</h3><p>梯度消失和梯度爆炸本质就是<strong>激活函数（的导数）和权重相互作用产生的联合效果</strong>，这个很重要，因为很多人以为梯度消失和爆炸是只存在某些激活函数中，其实不然。梯度消失和爆炸不单单是激活函数的问题， 不管你用 sigmoid/tanh 还是 ReLU 都有可能发生梯度消失/爆炸，只是发生的频繁程度不同。</p><p>我们知道，神经网络的每层计算可以看重矩阵相乘之后接一个非线性映射也就是激活函数，可以表示为：</p><script type="math/tex; mode=display">h_{t+1}= \sigma (Wh_t)</script><p>求导以后就是：</p><script type="math/tex; mode=display">\frac {\partial h_{t+1}} {\partial ht}=diag(\sigma'(Wh_t))W</script><p>其中等式右边第一项是对角阵，表示激活函数的导函数，假如<strong>激活函数是 sigmoid 函数，则对角阵中每个元素都小于 1</strong> ，会产生压缩的效果；而第二项特征值的大小与 W 本身有关，既可能收缩也可能扩张。</p><p>假如 W 的所有特征值都小于 1，那么此时两项相乘也是收缩的效果；反之，两项的乘积有可能（注意不是一定）产生扩张的效果。多层累积以后，就有可能发生梯度消失和梯度爆炸。 因为 sigmoid 函数的导数值域小于 1，所以很依赖 W 的值，因此容易产生梯度消失，tanh 同理。但是并不是说一定会梯度消失。如果使用的激活函数的导数值域大于 1，则容易产生梯度爆炸，但是不一定会。ReLU 梯度等于 1，看上去比较合适。</p><h3 id="sigmoid-求导"><a href="#sigmoid-求导" class="headerlink" title="sigmoid 求导"></a>sigmoid 求导</h3><p>为什么 sigmoid 函数的导师小于 1 呢？求导就明白了。</p><p>sigmoid 函数：</p><script type="math/tex; mode=display">f(x) = \frac {1}{1 + e^{-x}}= (1 + e^{-x})^{-1}</script><p>求导：</p><script type="math/tex; mode=display">\begin {align}f'(x) &= (-1) (1 + e^{-x})^{-2}e^{-x}(-1) \\&= (1+e^{-x})^{-2}e^{-x} \\&= \frac {e^{-x}} {(1+e^{-x})^2} \\&= \frac {1+e^{-x}-1} {(1+e^{-x})^2} \\&= \frac {1+e^{-x}} {(1+e^{-x})^2} -  \frac {1} {(1+e^{-x})^2} \\&= \frac {1+e^{-x}} {(1+e^{-x})^2} -  \frac {1} {(1+e^{-x})^2} \\&= \frac {1} {1+e^{-x}} -  \frac {1} {(1+e^{-x})^2} \\&= f(x) - (f(x))^2\end {align}</script><p>因为 sigmoid 函数的值域： $0 &lt; f(x) &lt; 1$ ，因此 $0 &lt; f’(x) &lt; 1$。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;周末刷知乎看到一个问题，关于如何理解梯度消失和梯度爆炸的。有个回答讲的比较好，就和 sigmoid 函数一起总结一下吧。&lt;/p&gt;
    
    </summary>
    
      <category term="机器学习" scheme="https://murphypei.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="https://murphypei.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="sigmoid" scheme="https://murphypei.github.io/tags/sigmoid/"/>
    
      <category term="梯度消失" scheme="https://murphypei.github.io/tags/%E6%A2%AF%E5%BA%A6%E6%B6%88%E5%A4%B1/"/>
    
      <category term="梯度爆炸" scheme="https://murphypei.github.io/tags/%E6%A2%AF%E5%BA%A6%E7%88%86%E7%82%B8/"/>
    
  </entry>
  
  <entry>
    <title>PCA 数学原理总结</title>
    <link href="https://murphypei.github.io//blog/2019/12/pca-repost.html"/>
    <id>https://murphypei.github.io//blog/2019/12/pca-repost.html</id>
    <published>2019-12-09T02:59:54.000Z</published>
    <updated>2019-12-24T02:10:15.318Z</updated>
    
    <content type="html"><![CDATA[<p>PCA（Principal Component Analysis） 是一种常见的数据分析方式，常用于高维数据的降维，可用于提取数据的主要特征分量。我之前也写过一篇简单的 PCA 的数学理解，日前看到<a href="https://zhuanlan.zhihu.com/p/77151308" target="_blank" rel="noopener">一篇文章</a>讲解的很棒，就整理转载过来，作为以后复习的总结。</p><a id="more"></a><p>理解 PCA，我觉得从其数学推导入手是非常好的途径。PCA 的数学推导可以从最大可分型和最近重构性两方面进行，前者的优化条件为划分后方差最大，后者的优化条件为点到划分平面距离最小，这里我将从最大可分性的角度进行证明。</p><h3 id="特征表示和降维"><a href="#特征表示和降维" class="headerlink" title="特征表示和降维"></a>特征表示和降维</h3><p>在机器学习任务中，一般用一个特征向量描述一个样本，每个样本都有很多维特征，在机器学习中，一条样本由一个<strong>列向量</strong>表示。但是对于样本而言，某些特征之间有线性关系甚至直接关系。</p><p>举个例子，假如某学籍数据有两列 M 和 F，其中 M 列的取值是如何此学生为男性取值 1，为女性取值 0；而 F 列是学生为女性取值 1，男性取值 0。此时如果我们统计全部学籍数据，会发现对于任何一条记录来说，当 M 为 1 时 F 必定为 0，反之当 M 为 0 时 F 必定为 1。在这种情况下，我们将 M 或 F 去掉实际上没有任何信息的损失，因为只要保留一列就可以完全还原另一列。</p><p>当然上面是一个极端的情况，在现实中也许不会出现，不过类似的情况还是很常见的。例如上面淘宝店铺的数据，从经验我们可以知道，“浏览量”和“访客数”往往具有较强的相关关系，而“下单数”和“成交数”也具有较强的相关关系。这里我们非正式的使用“相关关系”这个词，可以直观理解为“当某一天这个店铺的浏览量较高（或较低）时，我们应该很大程度上认为这天的访客数也较高（或较低）”。这种情况表明，如果我们删除浏览量或访客数其中一个指标，我们应该期待并不会丢失太多信息。因此我们可以删除一个，以降低机器学习算法的复杂度。</p><p>上面这些让我们能够隐约感觉到特征之间的相关性，这些特征就可以去重。另一方面，对于样本个数比较少但是特征非常丰富的训练样本，少量样本在高维特征空间中就变成了稀疏分布，模型拟合就比较发散，而且计算量增加，通过降维把高维空间的特征映射到低维空间中，也就是降低特征的维度，可以减少计算量，加快模型拟合。以上就是降维的朴素思想描述和动机。</p><h3 id="向量内积"><a href="#向量内积" class="headerlink" title="向量内积"></a>向量内积</h3><p>文章首先介绍了关于向量内积的知识，这里不再对这些基础进行总结了。只需要记住：<strong>设向量 B 的模为 1，向量 A 与 B 的内积值等于 A 向 B 所在直线投影的矢量长度</strong>。这就是内积的一种几何解释，也是我们得到的第一个重要结论。</p><h3 id="基"><a href="#基" class="headerlink" title="基"></a>基</h3><p>向量的基（也称基向量）用于描述一个多维空间。在多维空间中，如果我们<strong>要准确描述向量，首先要确定一组基，然后给出在基所在的各个直线上的投影值，就可以了</strong>。关于多维空间的基，这里也不啰嗦了，线性代数基础知识，但是需要记住一个重要结论，也是我一直比较推崇的，理解关于矩阵相乘的物理解释：<strong>两个矩阵相乘的意义是将右边矩阵中的 <em>每一列</em> 向量 $a_i$ 变换到左边矩阵中以 <em>每一行</em> 向量为基所表示的空间中去</strong>。</p><p>这里也解释了为什么一个样本数据要用一个列向量来表示，因为这个列向量通过矩阵相乘的形式被变换到其他特征空间（特征维度可能不一样）中，就可以得到这个样本在另一个特征空间的描述了。</p><h3 id="最大可分性"><a href="#最大可分性" class="headerlink" title="最大可分性"></a>最大可分性</h3><p>描述一个多维空间中的某一向量，<strong>选择不同的基可以对同样一组数据给出不同的表示</strong>，如果基的数量少于向量本身的维数，则可以达到降维的效果。</p><blockquote><p>这里说的向量本身的维度其实也是数据的一种描述方式，比如如果一条数据的向量维度是13，则表示这条数据用13个基来描述，第 i 个特征值是该数据在第 i 个基上的投影长度。我们用 PCA 降维就是找到另一种用更少的基描述数据的方式。</p></blockquote><p>但是我们还没回答一个最关键的问题：如何选择基才是最优的。或者说，如果我们有一组 N 维向量，现在要将其降到 K 维（K 小于 N），那么我们应该如何选择 K 个基才能最大程度保留原有的信息？一种直观的看法是：希望投影后的投影值尽可能分散，因为如果重叠就会有样本消失。当然这个也可以从熵的角度进行理解，熵越大所含信息越多，这就是最大可分性的出发点。</p><h4 id="方差"><a href="#方差" class="headerlink" title="方差"></a>方差</h4><p>方差用于描述一组数组的分散程度，变量的方差可以看做是每个元素与变量均值的差的平方和的均值，即：</p><script type="math/tex; mode=display">Var(a) = \frac {1}{m} \sum_{i=1}^{m}(a_i-\mu)^2</script><p>为了方便处理，我们将每个变量的均值都化为 0 ，因此方差可以直接用每个元素的平方和除以元素个数表示：</p><script type="math/tex; mode=display">Var(a) = \frac {1}{m} \sum_{i=1}^{m}(a_i)^2</script><p>于是上面的如何判断分散问题被形式化表述为：<strong>寻找一个一维基，使得所有数据变换为这个基上的坐标表示后，方差值最大。</strong></p><h4 id="协方差"><a href="#协方差" class="headerlink" title="协方差"></a>协方差</h4><p>在一维空间中我们可以用方差来表示数据的分散程度。而对于高维数据，我们用协方差进行约束，协方差可以表示两个变量的相关性。为了让两个变量尽可能表示更多的原始信息，我们希望它们之间不存在线性相关性，因为相关性意味着两个变量不是完全独立，必然存在重复表示的信息。</p><p>协方差公式为：</p><script type="math/tex; mode=display">Cov(a,b)=\frac {1} {m-1} \sum_{i=1}^{m}(a_i-\mu_a)(b_i-\mu_b)</script><p>因为均值为 0，因此：</p><script type="math/tex; mode=display">Cov(a,b)=\frac {1} {m} \sum_{i=1}^{m}a_ib_i</script><blockquote><p>当样本数较大时，不必在意其是 m 还是 m-1，为了方便计算，我们分母取 m。</p></blockquote><p>当协方差为 0 时，表示两个变量完全独立。为了让协方差为 0，我们选择第二个基时只能在与第一个基正交的方向上进行选择，因此最终选择的两个方向一定是正交的。</p><p>至此，我们得到了降维问题的优化目标：<strong>将一组 N 维向量降为 K 维，其目标是选择 K 个单位正交基，使得原始数据变换到这组基上后，各变量两两间协方差为 0，而变量方差则尽可能大（在正交的约束下，取最大的 K 个方差）。</strong></p><blockquote><p>这里的变量不是指某条数据，而是一个表示特征的基向量。因此 PCA 降维的目标就是找 K 个正交基（向量内积为 0 则正交）。</p></blockquote><h4 id="协方差矩阵"><a href="#协方差矩阵" class="headerlink" title="协方差矩阵"></a>协方差矩阵</h4><p>针对我们给出的优化目标，接下来我们将从数学的角度来给出优化目标。</p><p>我们看到，最终要达到的目的与<strong>变量内方差及变量间协方差</strong>有密切关系。因此我们希望能将两者统一表示，仔细观察发现，两者均可以表示为内积的形式，而内积又与矩阵相乘密切相关。</p><p>假设我们只有 a 和 b 两个变量，有 m 个样本，那么我们将它们组成矩阵 X：</p><script type="math/tex; mode=display">X=\begin{pmatrix}a_1 & a_2 & \cdots & a_m \\b_1 & b_2 & \cdots & b_m\end{pmatrix}</script><p>然后：</p><script type="math/tex; mode=display">\frac{1}{m} X X^T=\begin{pmatrix}\frac{1}{m}\sum_{i=1}^{m}a_{i}^{2} & \frac{1}{m}\sum_{i=1}^{m}a_ib_i  \\\frac{1}{m}\sum_{i=1}^{m}a_ib_i & \frac{1}{m}\sum_{i=1}^{m}b_{i}^{2}\end{pmatrix}=\begin{pmatrix}Cov(a,a) & Cov(a,b) \\Cov(b,a) & Cov(b,b) \\\end{pmatrix}</script><p>我们可以看到这个矩阵对角线上的分别是两个变量的方差，而其它元素是 a 和 b 的协方差。两者被统一到了一个矩阵里。</p><p>根据上述公式，我们很容易被推广到一般情况：</p><p><strong>设我们有 m 个 n 维数据记录，将其排列成矩阵 $X_{n,m}$，设 $C=\frac{1}{m}XX^T$ ，则 C 是一个对称矩阵，其对角线分别对应各个变量的方差，而第 i 行 j 列和 j 行 i 列元素相同，表示 i 和 j 两个维度特征的协方差</strong>。</p><h3 id="矩阵对角化"><a href="#矩阵对角化" class="headerlink" title="矩阵对角化"></a>矩阵对角化</h3><p>根据我们的优化条件，<strong>我们需要将除对角线外的其它元素化为 0（协方差为 0），并且在对角线上将元素按大小从上到下排列（方差尽可能大）</strong>，这样我们就达到了优化目的。这样说可能还不是很明晰，我们进一步看下原矩阵与基变换后矩阵协方差矩阵的关系。</p><p>设原始数据矩阵 X 对应的协方差矩阵为 C，而 P 是一组基按行组成的矩阵，设 Y=PX，则 Y 为 X 对 P 做基变换后的数据。设 Y 的协方差矩阵为 D，我们推导一下 D 与 C 的关系：</p><script type="math/tex; mode=display">\begin{align} D &= \frac{1}{m}YY^T \\ &= \frac{1}{m}(PX)(PX)^T \\ &= \frac{1}{m}PXX^TP^T \\ &= P(\frac{1}{m}XX^T)P^T \\ &= P(C)P^T \\\end{align}</script><p>这样我们就看清楚了，我们要找的 P 是能让原始协方差矩阵对角化的 P。换句话说，优化目标变成了<strong>寻找一个矩阵 P，满足 $PCP^T$ 是一个对角矩阵，并且对角元素按从大到小依次排列，那么 P 的前 K 行就是要寻找的基，用 P 的前 K 行组成的矩阵乘以 X 就使得 X 从 N 维降到了 K 维并满足上述优化条件</strong>。</p><p>至此，我们离 PCA 还有仅一步之遥，我们还需要完成对角化。</p><p>由上文知道，协方差矩阵 C 是一个是对称矩阵，在线性代数中实对称矩阵有一系列非常好的性质：</p><ol><li>实对称矩阵不同特征值对应的特征向量必然正交。</li><li>设特征向量 $\lambda$ 重数为 r，则必然存在 r 个线性无关的特征向量对应于 $\lambda$  ，因此可以将这 r 个特征向量单位正交化。</li></ol><p>由上面两条可知，一个 n 行 n 列的实对称矩阵一定可以找到 n 个单位正交特征向量，设这 n 个特征向量为：$e_1,e_2,\cdots,e_n$，我们将其按列组成矩阵：$E=(e_1,e_2,\cdots,e_n)$。</p><p>则对协方差矩阵 C，有如下结论：</p><script type="math/tex; mode=display">E^TCE=\Lambda =\begin{pmatrix} \lambda_1 &  &  & \\ &  \lambda_2 &  & \\ &  &  \cdots & \\ &  &  & \lambda_n\end{pmatrix}</script><p>其中 $\Lambda$ 为对角矩阵，其对角元素为各特征向量对应的特征值（可能有重复）。</p><p>到这里，我们发现我们已经找到了需要的矩阵 P：$P=E^T$。</p><p>P 是协方差矩阵的特征向量单位化后按行排列出的矩阵，其中每一行都是 C 的一个特征向量。如果设 P 按照 $\Lambda$  中特征值的从大到小，将特征向量从上到下排列，则用 P 的前 K 行组成的矩阵乘以原始数据矩阵 X，就得到了我们需要的降维后的数据矩阵 Y。</p><blockquote><p>原文还介绍基于拉格朗日乘子法的 PCA 数学推导，我这里就不展开了。</p></blockquote><h3 id="PCA-求解步骤"><a href="#PCA-求解步骤" class="headerlink" title="PCA 求解步骤"></a>PCA 求解步骤</h3><p>总结一下 PCA 的算法步骤：</p><p>设有 m 条 n 维数据：</p><ol><li>将原始数据按列组成 n 行 m 列矩阵 X；</li><li>将 X 的每一行进行零均值化，即减去这一行的均值；</li><li>求出协方差矩阵  $C=\frac {1}{m}XX^T$  ；</li><li>求出协方差矩阵的特征值及对应的特征向量；</li><li>将特征向量按对应特征值大小从上到下按行排列成矩阵，取前 K 行组成矩阵 P；</li><li>求得矩阵 $Y=PX$，即为降维到 K 维后的数据。</li></ol><h4 id="零均值化"><a href="#零均值化" class="headerlink" title="零均值化"></a>零均值化</h4><p>当对训练集进行 PCA 降维时，也需要对验证集、测试集执行同样的降维。而<strong>对验证集、测试集执行零均值化操作时，均值必须从训练集计算而来</strong>，不能使用验证集或者测试集的中心向量。</p><p>其原因也很简单，因为我们的训练集时可观测到的数据，测试集不可观测所以不会知道其均值，而验证集再大部分情况下是在处理完数据后再从训练集中分离出来，一般不会单独处理。如果真的是单独处理了，不能独自求均值的原因是和测试集一样。</p><p>另外我们也需要保证一致性，我们拿训练集训练出来的模型用来预测测试集的前提假设就是两者是独立同分布的，如果不能保证一致性的话，会出现 Variance Shift 的问题。</p><h3 id="PCA-的一些性质"><a href="#PCA-的一些性质" class="headerlink" title="PCA 的一些性质"></a>PCA 的一些性质</h3><ol><li><strong>缓解维度灾难</strong>：PCA 算法通过舍去一部分信息之后能使得样本的采样密度增大（因为维数降低了），这是缓解维度灾难的重要手段；</li><li><strong>降噪</strong>：当数据受到噪声影响时，最小特征值对应的特征向量往往与噪声有关，将它们舍弃能在一定程度上起到降噪的效果；</li><li><strong>过拟合</strong>：PCA 保留了主要信息，但这个主要信息只是针对训练集的，而且这个主要信息未必是重要信息。有可能舍弃了一些看似无用的信息，但是这些看似无用的信息恰好是重要信息，只是在训练集上没有很大的表现，所以 <strong>PCA 也可能加剧了过拟合</strong>；</li><li><strong>特征独立</strong>：PCA 不仅将数据压缩到低维，它也使得降维之后的数据各特征相互独立；</li></ol><h3 id="PCA-和-SVD-的对比"><a href="#PCA-和-SVD-的对比" class="headerlink" title="PCA 和 SVD 的对比"></a>PCA 和 SVD 的对比</h3><p>这是两个不同的数学定义。我们先给结论：<strong>特征值和特征向量是针对方阵</strong>才有的，而<strong>对任意形状的矩阵都可以做奇异值分解</strong>。</p><h4 id="PCA"><a href="#PCA" class="headerlink" title="PCA"></a>PCA</h4><p>方阵的特征值分解，对于一个方针 A，总可以写成：$A=Q \Lambda Q^{-1}$。其中，Q 是这个矩阵 A 的特征向量组成的矩阵，$\Lambda$ 是一个对角矩阵，每一个对角线元素就是一个特征值，里面的特征值是由小排列的，这些特征值所对应的特征向量就是描述这个矩阵变化方向（从主要的变化到次要的变化排列）。也就是说<strong>矩阵 A 的信息可以由其特征值和特征向量表示</strong>，这也是矩阵特征值和特征向量的重要物理意义之一。</p><h4 id="SVD"><a href="#SVD" class="headerlink" title="SVD"></a>SVD</h4><p>矩阵的奇异值分解其实就是对于矩阵 A 的协方差矩阵 $A^TA$ 和 $AA^T$ 做特征值分解推导出来的：</p><script type="math/tex; mode=display">A_{m,n}=U_{m,m} \Lambda_{m,n} V_{n,n}^{T} \approx U_{m,k} \Lambda_{k,k} V_{k,n}^{T}</script><p>其中：U 和 V 都是正交矩阵，有 $U^TU=I_m$，$V^TV=I_n$。这里的约等于是因为 $\Lambda$ 中有 n 个奇异值，但是由于排在后面的很多接近 0，所以我们可以仅保留比较大的 k 个奇异值。</p><script type="math/tex; mode=display">A^TA=(U \Lambda V^T)^T U \Lambda V^T=V \Lambda^TU^TU \Lambda V^T=V \Lambda^2V^T</script><script type="math/tex; mode=display">AA^T=U \Lambda V^T(U \Lambda V^T)^T =U \Lambda V^TV \Lambda^TU^T=U \Lambda^2U^T</script><p>所以，V U 两个矩阵分别是 $A^TA$ 和 $AA^T$ 的特征向量，中间的矩阵对角线的元素是 $A^TA$ 和 $AA^T$ 的特征值。我们也很容易看出 A 的奇异值和 $A^TA$  的特征值之间的关系。</p><p>PCA 需要对协方差矩阵 $C=\frac {1}{m} XX^T$ 进行特征值分解；SVD 也是对 $A^TA$ 进行特征值分解。如果取 $A=\frac{X^T}{\sqrt{m}}$ ，则二者基本等价。所以 PCA 问题可以转换成 SVD 求解。实际上 Sklearn 的 PCA 就是用 SVD 进行求解的，原因有以下几点：</p><ol><li>当样本维度很高时，协方差矩阵计算太慢；</li><li>方针特征值分解计算效率不高；</li><li>SVD 出了特征值分解这种求解方式外，还有更高效更准球的迭代求解方式，避免了 $A^TA$ 的计算；</li><li>其实 PCA 与 SVD 的右奇异向量的压缩效果相同。</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;PCA（Principal Component Analysis） 是一种常见的数据分析方式，常用于高维数据的降维，可用于提取数据的主要特征分量。我之前也写过一篇简单的 PCA 的数学理解，日前看到&lt;a href=&quot;https://zhuanlan.zhihu.com/p/77151308&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;一篇文章&lt;/a&gt;讲解的很棒，就整理转载过来，作为以后复习的总结。&lt;/p&gt;
    
    </summary>
    
      <category term="机器学习" scheme="https://murphypei.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="https://murphypei.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="PCA" scheme="https://murphypei.github.io/tags/PCA/"/>
    
      <category term="矩阵分解" scheme="https://murphypei.github.io/tags/%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3/"/>
    
      <category term="协方差" scheme="https://murphypei.github.io/tags/%E5%8D%8F%E6%96%B9%E5%B7%AE/"/>
    
  </entry>
  
  <entry>
    <title>机器学习中关于熵的一些概念</title>
    <link href="https://murphypei.github.io//blog/2019/12/entropy.html"/>
    <id>https://murphypei.github.io//blog/2019/12/entropy.html</id>
    <published>2019-12-04T07:25:37.000Z</published>
    <updated>2019-12-04T08:43:37.629Z</updated>
    
    <content type="html"><![CDATA[<p>交叉熵是机器学习中常用的一个概念，一般用来衡量目标值与预测值之间的差距。熵的概念源于信息论，因此，首先从信息论角度进行分析。</p><a id="more"></a><h3 id="信息量"><a href="#信息量" class="headerlink" title="信息量"></a>信息量</h3><p>对于事件集合 $X$，其中一个随机发生的事件 $X=x_0$ 发生的概率是 $p(x_0)$，这个事件所包含的信息量为：</p><script type="math/tex; mode=display">I(x_0)-\log(p(x_0))</script><p>事件发生的概率越大，信息量越小，反之，概率越小，信息量越大。这也符合人们的直观感觉。</p><h3 id="信息熵"><a href="#信息熵" class="headerlink" title="信息熵"></a>信息熵</h3><p>在信息论与概率统计中，熵表示随机变量不确定性的度量。熵越大，表示不确定性越大。信息熵用来表示所有信息量的期望：</p><script type="math/tex; mode=display">H(X)=-\sum_{i=1}^{n}p(x_i)\log(p(x_i))</script><p>信息熵可以表示一个事件（变量）集合的不确定程度。</p><h3 id="联合熵"><a href="#联合熵" class="headerlink" title="联合熵"></a>联合熵</h3><p>假设要度量的对象不是单一变量的集合，而是一个联合分布的随即系统，这个系统的不确定程度可以用联合熵描述：</p><script type="math/tex; mode=display">H(X,Y)=-\sum_{x \in X} \sum_{y \in Y}p(x,y) \log p(x,y)</script><p>联合熵就是联合信息量的期望。</p><h3 id="条件熵"><a href="#条件熵" class="headerlink" title="条件熵"></a>条件熵</h3><p>如果联合分布中有一个条件已知，和概率论中条件概率类似，联合熵就变成了条件熵：</p><script type="math/tex; mode=display">H(Y|X)=-\sum_{x \in X} \sum_{y \in Y}p(x,y) \log p(y|x)</script><p>但是注意，条件熵这个定义其实是通过信息熵和联合熵推导出来的：</p><script type="math/tex; mode=display">\begin{align*}  H(X,Y) &= -\sum_{x \in X} \sum_{y \in Y}p(x,y) \log p(x,y) \\&= -\sum_{x \in X} \sum_{y \in Y}p(x,y) \log (p(x) \cdot p(y|x)) \\&= -\sum_{x \in X} \sum_{y \in Y}p(x,y) \log p(x) - \sum_{x \in X} \sum_{y \in Y}p(x,y) \log p(y|x) \\&= H(X)+H(Y|X)\end{align*}</script><p>条件熵公式表明，对拥有两个随机变量的随机系统，我们可以先观察一个随机变量获取信息量，观察完后，我们可以在拥有这个信息量的基础上观察第二个随机变量的信息量。并且我们可以很容易推导出，不论先观察谁，对信息量都不会有影响，这是非常符合直觉的。</p><p>以上联合熵和条件熵可以进一步推广到多个随机变量系统，根据链式法则可以很容易就推导出：</p><script type="math/tex; mode=display">H(X_1,X_2,\cdots ,X_n)=\sum_{i=1}^{n}H(X_i|X_{i-1},\cdots,X_1)</script><h3 id="信息增益"><a href="#信息增益" class="headerlink" title="信息增益"></a>信息增益</h3><p>信息增益是针对具体属性的，常用于机器学习决策树构建中的特征选择。指的是分类前的信息熵减去分类后的信息熵，即选用某个属性或者特征分类后，<strong>信息熵的减少量</strong>，计算如下：</p><script type="math/tex; mode=display">G(D,a)=H(D)-\sum_{v=1}^{V}\frac {|D^v|}{D}H(D^v)</script><p>$H(D)$ 为划分之前的信息熵，当根据特征 $a$ 分为 $V$ 类之后，每个子类别的信息熵为 $H(D^v)$，$\frac {|D^v|}{D}$ 表示子类别数目占总数目的比例。可以看出，等号右边的后半部分就是条件熵。</p><p>注意：$H(D)$ 和 $H(D^v)$ 均看作是一个随机变量集合，在内部按照实际的类别以及比例计算各自的信息熵。这里的计算一定要明白，不懂可以看《统计学习方法》的计算实例。</p><p>信息增益用于 ID3 决策树算法中。</p><h3 id="信息增益率"><a href="#信息增益率" class="headerlink" title="信息增益率"></a>信息增益率</h3><script type="math/tex; mode=display">G_R(D,a)=\frac {G(D,a)}{H(D)}</script><p>信息增益率用于 C4.5 决策树算法中。</p><h3 id="基尼系数"><a href="#基尼系数" class="headerlink" title="基尼系数"></a>基尼系数</h3><p>在分类问题中，假设有 $K$ 个类别，第 $k$ 个类别的概率为 $p_k$，则基尼系数的表达式为：</p><script type="math/tex; mode=display">G(p) = \sum\limits_{k=1}^{K}p_k(1-p_k) = 1- \sum\limits_{k=1}^{K}p_k^2</script><p>基尼系数用于 CART 决策树算法中。</p><h3 id="相对熵"><a href="#相对熵" class="headerlink" title="相对熵"></a>相对熵</h3><p>相对熵又称为KL散度，常用来度量两个分部的相似程度，计算公式：</p><script type="math/tex; mode=display">D_{KL}(p||q)=\sum_{i=1}^{n}p(x_i)\log(\frac {p(x_i)} {q(x_i)})</script><p>相对熵的值越小，表示一个新的分布 $q$ 和 原始分布 $p$ 越接近。相对熵用于 TensorRT 的量化校验。</p><h3 id="交叉熵"><a href="#交叉熵" class="headerlink" title="交叉熵"></a>交叉熵</h3><script type="math/tex; mode=display">H(p,q)=-\sum_{i=1}^{n}p(x_i)\log(q(x_i))</script><p>用于推导相对熵。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;交叉熵是机器学习中常用的一个概念，一般用来衡量目标值与预测值之间的差距。熵的概念源于信息论，因此，首先从信息论角度进行分析。&lt;/p&gt;
    
    </summary>
    
      <category term="机器学习" scheme="https://murphypei.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="https://murphypei.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="熵" scheme="https://murphypei.github.io/tags/%E7%86%B5/"/>
    
      <category term="信息增益" scheme="https://murphypei.github.io/tags/%E4%BF%A1%E6%81%AF%E5%A2%9E%E7%9B%8A/"/>
    
      <category term="基尼系数" scheme="https://murphypei.github.io/tags/%E5%9F%BA%E5%B0%BC%E7%B3%BB%E6%95%B0/"/>
    
  </entry>
  
  <entry>
    <title>STL 中的二分查找</title>
    <link href="https://murphypei.github.io//blog/2019/11/stl-binary.html"/>
    <id>https://murphypei.github.io//blog/2019/11/stl-binary.html</id>
    <published>2019-11-29T03:27:44.000Z</published>
    <updated>2019-11-29T03:37:11.835Z</updated>
    
    <content type="html"><![CDATA[<p>STL 中的算法都很精妙，有很多实现值得我们细究和学习。</p><a id="more"></a><p>STL 容器中有两个有趣的方法：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 返回一个非递减序列[first, last)中的第一个大于等于值val的位置。</span></span><br><span class="line"><span class="function">ForwardIter <span class="title">lower_bound</span><span class="params">(ForwardIter first, ForwardIter last,<span class="keyword">const</span> _Tp&amp; val)</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"><span class="comment">// 返回一个非递减序列[first, last)中第一个大于val的位置。</span></span></span><br><span class="line"><span class="function">ForwardIter <span class="title">upper_bound</span><span class="params">(ForwardIter first, ForwardIter last, <span class="keyword">const</span> _Tp&amp; val)</span></span></span><br></pre></td></tr></table></figure><p>这两个方法一般是用于确定 <code>val</code> 的上下边界，因为作用是一个<strong>非递减序列</strong>，因此用二分查找最好不过了。下面就是 STL 中这两个方法的实现。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 这个算法中，first是最终要返回的位置</span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">lower_bound</span><span class="params">(<span class="keyword">int</span> *<span class="built_in">array</span>, <span class="keyword">int</span> size, <span class="keyword">int</span> key)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> first = <span class="number">0</span>, middle;</span><br><span class="line">    <span class="keyword">int</span> half, len;</span><br><span class="line">    len = size;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">while</span>(len &gt; <span class="number">0</span>) </span><br><span class="line">    &#123;</span><br><span class="line">        half = len &gt;&gt; <span class="number">1</span>;    <span class="comment">// half 表示待查找序列的一半长度</span></span><br><span class="line">        middle = first + half;  <span class="comment">// 确定待查找序列的中间位置</span></span><br><span class="line">        <span class="comment">// 根据比较结果，更新待查找序列</span></span><br><span class="line">        <span class="keyword">if</span>(<span class="built_in">array</span>[middle] &lt; key) </span><br><span class="line">        &#123;     </span><br><span class="line">            first = middle + <span class="number">1</span>;  </span><br><span class="line">            len = len-half<span class="number">-1</span>;       <span class="comment">//在右边子序列中查找</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">        &#123;</span><br><span class="line">            len = half;            <span class="comment">//在左边子序列（包含middle）中查找</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> first;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">upper_bound</span><span class="params">(<span class="keyword">int</span> *<span class="built_in">array</span>, <span class="keyword">int</span> size, <span class="keyword">int</span> key)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> first = <span class="number">0</span>, len = size<span class="number">-1</span>;</span><br><span class="line">    <span class="keyword">int</span> half, middle;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span>(len &gt; <span class="number">0</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        half = len &gt;&gt; <span class="number">1</span>;</span><br><span class="line">        middle = first + half;</span><br><span class="line">        <span class="keyword">if</span>(<span class="built_in">array</span>[middle] &gt; key)     <span class="comment">//中位数大于key,在包含last的左半边序列中查找。</span></span><br><span class="line">        &#123;</span><br><span class="line">            len = half;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">        &#123;</span><br><span class="line">            first = middle + <span class="number">1</span>;    <span class="comment">//中位数小于等于key,在右半边序列中查找。</span></span><br><span class="line">            len = len - half - <span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> first;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>回想一下，我们日常见到的二分查找都是使用两个位置变量标记一段待查找序列，STL中使用一个起始位置和长度来标记一段待查找序列，都是通过缩小待查找范围来更新，原理并没有什么不同，实现的复杂度也是类似的。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;STL 中的算法都很精妙，有很多实现值得我们细究和学习。&lt;/p&gt;
    
    </summary>
    
      <category term="C++" scheme="https://murphypei.github.io/categories/C/"/>
    
    
      <category term="C++" scheme="https://murphypei.github.io/tags/C/"/>
    
      <category term="binary" scheme="https://murphypei.github.io/tags/binary/"/>
    
      <category term="lower_bound" scheme="https://murphypei.github.io/tags/lower-bound/"/>
    
      <category term="upper_bound" scheme="https://murphypei.github.io/tags/upper-bound/"/>
    
  </entry>
  
  <entry>
    <title>神经网络量化方法</title>
    <link href="https://murphypei.github.io//blog/2019/11/neural-network-quantization.html"/>
    <id>https://murphypei.github.io//blog/2019/11/neural-network-quantization.html</id>
    <published>2019-11-18T02:53:26.000Z</published>
    <updated>2019-11-19T07:28:57.504Z</updated>
    
    <content type="html"><![CDATA[<p>神经网络虽然在多个领域取得了非常巨大的成就，但是其本质是大量参数的拟合和泛化，如果想处理更加复杂的任务，在没有过拟合的情况下，增加训练数据和加大网络规模无疑是简单有效的手段。现实情况就是这么做的，但是巨大的参数量和复杂的网络结构造成了两个主要的问题：模型体积和运算速度。这两个问题会带来诸如内存容量，内存存取带宽，移动端还有电量消耗等一系列问题，大大限制了神经网络的应用场景。</p> <a id="more"></a><h2 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a>背景介绍</h2><p>为了解决这些问题，目前的研究方向主要就是两方面：一是精心设计小巧而有效的网络结构取代大网络模型，二是通过压缩和编码的方式直接减小现有网络的规模。量化就是一种很好的压缩和编码方式，量化的目的很简单，就是减小存储体积和加速运算，有效解决神经网络的根本问题，并且在实际的一些应用中表现出色，也是目前采用最广泛的压缩和编码方式。如果在一些小巧的网络中再使用量化，就可以进一步压缩和加速网络，使其能够移植到移动端，例如，TensorFlow 量化的 MobileNetV1  仅为 4.8 MB，这甚至比大多数 GIF 动图还要小，从而可以轻松地部署在任何移动平台上。</p><p>量化简单来说就是使用一种低精度的方式来作为存储和计算的数值表示方式。一般而言，在神经网络构建和训练时使用 float，也就是 FP32 作为一种通用的数据表示方式。量化使用 FP16（半精度浮点），INT8/UINT8（8 位的定点整数）等低精度数值格式来存储以及计算，目前低精度往往都是指 INT8/UINT8。当然，存储和计算并不是严格要保持一致的，有些参数或操作符必须采用 FP32 格式才能保持准确度，因此还有一种混合精度的表示方式，<a href="https://devblogs.Nvidia.com/mixed-precision-training-deep-neural-networks/" target="_blank" rel="noopener">TensorRT 中就使用了这种计算方式</a>。也有一些更加特殊的量化方式，二进制（0，1）、三元量化（-1，0，+1）、4 位整数等等，这些特殊的方式可以在一些特殊的网络中应用，用于进一步压缩，不过本文不对这些方法进行表述，有兴趣可以查阅这篇关于<a href="https://arxiv.org/abs/1710.09282" target="_blank" rel="noopener">模型压缩和加速的综述</a>。因为不同精度数值表示的范围和单位数值都不一样（如下表所示），因此我们必须做点什么来减少这种精度损失。</p><div class="table-container"><table><thead><tr><th style="text-align:center"></th><th style="text-align:center">Dynamic Range</th><th style="text-align:center">Min Positive Value</th></tr></thead><tbody><tr><td style="text-align:center">FP32</td><td style="text-align:center">-3.4x10^38 ~ +3.4x10^38</td><td style="text-align:center">1.4x10^-45</td></tr><tr><td style="text-align:center">FP16</td><td style="text-align:center">-65504 ~ +65504</td><td style="text-align:center">5.95x10^-8</td></tr><tr><td style="text-align:center">INT8</td><td style="text-align:center">-128 ~ +127</td><td style="text-align:center">1</td></tr></tbody></table></div><p>本文将简要介绍目前应用最为广泛的 NVIDIA 的 TensorRT 和 Google 的 IAO 量化方法，这两个量化方法都属于 8-bit 量化，其本质原理是类似的，只不过在一些实际应用操作上面，各有自己的理解和不同。</p><h2 id="TensorRT-量化方法"><a href="#TensorRT-量化方法" class="headerlink" title="TensorRT 量化方法"></a>TensorRT 量化方法</h2><p>神经网络的计算主要集中在<strong>卷积层和全连接层</strong>，量化也是针对这两个层做的。这两个层的计算都是可以表示为：output = input * weights + bias。因为现在的深度学习框架会将卷积和全连接层的计算都打包成矩阵相乘的形式，因此大量的计算都集中在矩阵相乘上了。TensorRT 的量化思路就是用 INT8 代替 FP32 进行两个矩阵相乘计算。</p><h3 id="TensorRT-量化原理"><a href="#TensorRT-量化原理" class="headerlink" title="TensorRT 量化原理"></a>TensorRT 量化原理</h3><p>TensorRT 的线性量化公式：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Tensor Values = FP32 scale factor * INT8 array + FP32 bias</span><br></pre></td></tr></table></figure><p>在这个量化公式中，FP32 数值（Tensor Values）被表示成 INT8 数值（INT8 array）乘以量化因子加上一个量化偏，两个参数均为 FP32 类型。因此，利用上述的公式可以表示神经网络中两个矩阵相乘：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">A = scale_A * QA + bias_A</span><br><span class="line">B = scale_B * QB + bias_B</span><br><span class="line">A * B = scale_A * scale_B * QA * QB + scale_A * QA * bias_B + scale_B * QB * bias_A + bias_A * bias_B</span><br></pre></td></tr></table></figure><p>NVIDIA 研究人员通过实现发现，其实我们并不需要在量化的时候加上偏置。我理解主要是因为偏置对于一组数值而言，其改变的是数值的分布位置，但是当前神经网络的归一化操作很多，因此可以去掉偏置。当然了，实验出的结果更有说服力。因此两个矩阵相乘的量化表示可以简化为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">A * B = scale_A * scale_B * QA * QB</span><br></pre></td></tr></table></figure><p>这样就很明显了，只要我们有两个矩阵的 scale 以及量化后的矩阵，我们就可以表示其 FP32 的相乘结果。而量化后的矩阵就是 FP32 除以 scale 得到的，FP32 的数值是已知的（训练好的参数或者输入），因此量化的问题就变成了如何得到量化参数 scale factor。</p><p>既然是相乘，我们首先想大了线性映射，线性映射就是找一个值除以 INT8 的最大值，就可以求得 scale factor。TensorRT 介绍关于这个线性映射倍数的求解方法，有两种不同的方式：</p><p><img src="/images/posts/dl/quantization/map.jpg" alt></p><ul><li>非饱和映射：找到这组 FP32 数值的绝对值最大值 |max| 作为 FP32 的映射最大值</li><li>饱和映射：通过其他方法找到一个更加合适的阈值 T&lt;=|max| 作为 FP32 的映射最大值</li></ul><p>很明显，如果数值分布不够集中，比如有一些奇异点（很大或者很小），非饱和映射导致 scale factor 偏大，因为 INT8 单位精度远小于 FP32，就会让 FP32 中很多数集中在 INT8 的某几个数字上，带来了严重的精度影响。因此 TensorRT 采用了饱和映射，并且使用 KLD（KL 散度）方法寻找阈值 T。下图是 NVIDIA 官方 PPT 中对一些网络的激活值的分布的统计：</p><p><img src="/images/posts/dl/quantization/fp32_number_count.jpg" alt></p><h3 id="KLD"><a href="#KLD" class="headerlink" title="KLD"></a>KLD</h3><p>FP32 用 INT8 表示，本质就是一种再编码，这个学过通信技术的同学可能会容易理解。对于两种不同的编码方式，可以采用一种称为交叉熵的方式计算二者的差异性，本文并不想过多的着墨于信息论中关于信息熵的这些知识，这些知识通过搜索引擎可以获取，只介绍相关知识。</p><p>首先是信息熵，对于一种编码，其是符号的集合，每种符号都有其出现的概率，<strong>信息熵</strong>的大小可以表示为：</p><script type="math/tex; mode=display">H(X,p) = -\sum_{x \in X}p(x)\log p(x)</script><p>其中 $p(x)$ 是符号出现的概率，$-\log p(x)$ 就是这个符号的信息，这就是信息论的核心和理论基础，信息的表示。$-\log p(x)$ 也可以看作是每个符号的编码长度，因此信息熵也可以表示编码长度的期望。</p><p>当我们使用另一种编码 $q(x)$ 方式去表示这个信息，求得编码长度的期望称之为<strong>交叉熵</strong>：</p><script type="math/tex; mode=display">H(X,p,q) = -\sum_{x \in X}p(x)\log q(x)</script><p>一般而言，信息熵是最优编码，因此其编码期望就是最小编码长度，因此交叉熵必然是大于等于信息熵，我们可以计算两种不同编码表示的长度期望的差异，也是两个信息熵的差值：</p><script type="math/tex; mode=display">D(p||q) = H(X,p,q) - H(X,p) = -\sum_{x \in X}p(x)(\log q(x)- \log p(x))</script><p>上述两个信息熵的差值称之为<strong>相对熵</strong>，KLD 就是使用相对熵来描述两个不同数值分布的差异性。如果想要量化某一组数值，其具体做法如下：</p><ol><li>准备一个校准数据集，覆盖模型的使用场景即可，数量不需要很多。</li><li>将数据集的每张图片都通过模型做一次预测，在这个过程中，对所有要量化的层的 FP32 数值分布进行统计，得到 |max|。<ul><li>量化是针对每个 channel 单独做的，因此<strong>卷积层的每个 channel 都是单独统计、计算和量化的</strong>，后续操作也是。</li></ul></li><li>将 0~|max| 分成 n 个 bin，然后再次遍历所有图片，让每个量化层中的数值落到其属于的 bin 中，统计每个 bin 的数目。<ul><li>|max| / n 就可以得到每个 bin 的宽度 w，因此  就分为了 0~w, w~2*w…(n-1)*w~|max| 总共 n 个 bin。</li><li>对每个数值按照其绝对值分到不同 bin 中。</li><li>TensorRT 官方使用的 n 是 2048，mxnet 是 4096，n 越大越好，但是计算量会上升。</li></ul></li><li>遍历第 128~n 个 bin：<ul><li>以当前 bin 的中值作为阈值 T，在其上做截断，将大于当前 bin 以外的 bin 的统计数目加到当前 bin 上，这一步是为了减少直接抹去这些数值带来的影响；</li><li>计算此时的概率分布 P，每个 bin 的概率就是其统计数目除以数值的总数；</li><li>创建一个新的编码 Q，其长度是128，其元素的值就是 P 量化后的 INT8 数值（正数是0~+127，负数是-128~-1)；</li><li>因为 Q 分布只有 128 个编码，为了计算交叉熵，将其扩展到和 P 同样的长度；</li><li>计算 P 和 Q 的相对熵，记录当前相对熵和阈值 T</li></ul></li><li>选择最小的相对熵和其对应阈值 T，计算 scale factor = T / 127<ul><li>实际代码中使用的是 scale factor = 127 / T，这样 FP32 到 INT8 量化的时候可以使用乘法而不是除法。</li></ul></li><li>对每个 bin，取其中值作为这个 bin 当前的 FP32 表示，然后除以 scale factor，然后四舍五入，就得到了其量化后的 INT8 数值，将这个 bin 中所有的 FP32 数值都映射为这个 INT8 表示的数。多个 bin 可能映射为同一个 INT8 数字。</li></ol><p>上述流程就是 TensorRT 中寻找阈值和计算 scale factor 的流程，有几个点还需要注意：首先为什么阈值遍历要从 128 开始呢？因为 INT8 可以表示的整数个数（正值）有128个，小于这个数值则直接一一对应即可。其次如果扩展 q 分布呢？TensorRT 官方 PPT 的例子，据说是这样的：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">P=[1 0 2 3 5 3 1 7]     // fp32 的统计直方图，T=8</span><br><span class="line">// 假设只量化到两个 bins，即量化后的值只有 -1/0/+1 三种</span><br><span class="line">Q=[1+0+2+3, 5+3+1+7] = [6, 16]</span><br><span class="line">// P 和 Q 现在没法做 KL 散度，所以要将 Q 扩展到和 P 一样的长度</span><br><span class="line">Q_expand = [6/3, 0, 6/3, 6/3, 16/4, 16/4, 16/4, 16/4] = [2 0 2 2 4 4 4 4]  // P 中有 0 时，不算在内</span><br><span class="line">D = KL(P||Q_expand)  // 这样就可以做 KL 散度计算了</span><br></pre></td></tr></table></figure><p>这个扩展的操作，就像图像的上采样一样，将低精度的统计直方图(Q)，上采样的高精度的统计直方图上去(Q_expand)。由于 Q 中一个 bin 对应 P 中的 4 个bin，因此在 Q 上采样的 Q_expand 的过程中，所有的数据要除以 4。但若分布P 中有 bin 值为 0 时，是不算在内的，所以 6 只需要除以 3。</p><p>以上内容很多细节都来自 NCNN，其使用了和 TensorRT 一样的量化机制，因为 TensorRT 不开源，细节不得知，因此只有通过 NCNN 代码来了解一些细节的实现。下面具体讲讲 NCNN 中量化的一些实现。</p><h3 id="NCNN-量化实现"><a href="#NCNN-量化实现" class="headerlink" title="NCNN 量化实现"></a>NCNN 量化实现</h3><p>NCNN 主要对 conv 和 fc 的计算进行量化，具体就是对输入数据 input_data 和 模型权重 weights 进行量化，实现的量化机制就是 TensorRT 的量化方法。我主要讲解 conv 层的量化实现。</p><p>首先是通过校准数据集生成量化表，这个量化表主要存放的就是量化的 scale factor，这个表的生成是离线的，量化表的实现在 <a href="https://github.com/Tencent/ncnn/blob/master/tools/quantize/ncnn2table.cpp" target="_blank" rel="noopener">ncnn2table.cpp</a> 中。NCNN 将 weights 和 input_data 分开计算的 scale factor。</p><h4 id="量化权重"><a href="#量化权重" class="headerlink" title="量化权重"></a>量化权重</h4><p>对于 weights，NCNN 并没有通过 KLD 来寻找阈值，而是<strong>直接利用最大值来计算 scale factor</strong>，这个做法和 NVIDIA 官方 PPT 中的做法是一致的，其中也提到了 <strong>weights 不需要饱和量化，只需要非饱和量化</strong>。我猜测其原因是 weights 的数值分布比较集中。关于 weights 的 scale factor 计算可以查看 <a href="https://github.com/Tencent/ncnn/blob/master/tools/quantize/ncnn2table.cpp#L142" target="_blank" rel="noopener">QuantNet::get_conv_weight_blob_scales</a> 这个函数。这里贴出其核心逻辑：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> n=<span class="number">0</span>; n&lt;((ncnn::Convolution*)layer)-&gt;num_output; n++)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">const</span> ncnn::Mat weight_data_n = ((ncnn::Convolution*)layer)-&gt;weight_data.range(weight_data_size_output * n, weight_data_size_output);</span><br><span class="line">    <span class="keyword">const</span> <span class="keyword">float</span> *data_n = weight_data_n;</span><br><span class="line">    <span class="keyword">float</span> max_value = <span class="built_in">std</span>::numeric_limits&lt;<span class="keyword">float</span>&gt;::min();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; weight_data_size_output; i++)</span><br><span class="line">        max_value = <span class="built_in">std</span>::max(max_value, <span class="built_in">std</span>::<span class="built_in">fabs</span>(data_n[i]));</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (quant_6bit)</span><br><span class="line">        scales.push_back(<span class="number">31</span> / max_value);</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        scales.push_back(<span class="number">127</span> / max_value);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="量化输入数据"><a href="#量化输入数据" class="headerlink" title="量化输入数据"></a>量化输入数据</h4><p>可以看出，NCNN 居然还有 6-bit 量化。还有补充一点就是 weights 是固定的，因此 weights 的量化是可以离线做的，而且可以看出，对于卷积层，其按照 channel 数目（<code>weight_data_size_output</code>），每个 channel 分别量化。</p><p>weights 的量化比较简单，麻烦的是输入数据的量化。NCNN 是按需量化，也就是如果这一层需要量化，才会将输入的数据进行量化，这个输入的数据因为是在 inference 的时候才能拿到，所以不可能离线量化，只能在线。而且因为输入数据分布不规律（conv 和 fc 的输入来自上一层的激活值），因此需要用饱和量化，也就是 KLD 寻找最佳阈值，这一步如果放到 inference 在线操作，太耗时了，因此使用校准数据集去模拟 inference 行为，然后在这个过程中寻找最佳阈值，计算 scale factor，作为输入数据的量化尺度。每一层都只有一个输入数据的 scale factor，并且将其也保存在量化表中。这部分代码实现在 <a href="https://github.com/Tencent/ncnn/blob/master/tools/quantize/ncnn2table.cpp#L514" target="_blank" rel="noopener">post_training_quantize</a> 函数中。核心逻辑如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">float</span> QuantizeData::get_data_blob_scale()</span><br><span class="line">&#123;   </span><br><span class="line">    normalize_histogram();</span><br><span class="line">    threshold_bin = threshold_distribution(histogram);</span><br><span class="line">    threshold = (threshold_bin + <span class="number">0.5</span>) * histogram_interval;</span><br><span class="line">    scale = <span class="number">127</span> / threshold;</span><br><span class="line">    <span class="keyword">return</span> scale;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="使用量化计算"><a href="#使用量化计算" class="headerlink" title="使用量化计算"></a>使用量化计算</h4><p>有了量化参数 scale factor，就可以使用它将 FP32 数值转换到 INT8了。权重是已经离线量化好的，因此只需要将输入按照量化表中那个已经计算好的 scale factor 进行量化就可以了。<strong>NCNN 并不量化卷积层和全连接层的偏置项</strong>，因此需要将矩阵乘法得到的结果（INT32）<strong>反量化</strong>到 FP32，然后和 bias 做加法，输出到下一层。其中反量化也很简单，只需要使用权重和输入数据量化的 scale factor 乘积的倒数作为反量化的 scale factor 即可。计算流程图如下：</p><p><img src="/images/posts/dl/quantization/ncnn_conv_quantization.jpg" alt></p><p>NCNN 中还有一些针对多个量化层的融合机制，简单来说就是当一个 Conv1 后面紧跟着另一个 Conv2 时，NCNN 会进行 requantize 的操作。大致意思就是在得到 Conv1 的 INT32 输出后，会顺手帮 Conv2 做量化，得到 Conv2 的 INT8 输入。这中间不会输出 FP32 的结果，节省一次内存读写。</p><p><img src="/images/posts/dl/quantization/ncnn_conv_quantization.jpg" alt></p><p>针对具体的操作过程以及上图，都引自<a href="https://zhuanlan.zhihu.com/p/71881443" target="_blank" rel="noopener">这篇文章</a>，有兴趣可以查看。</p><h2 id="IAO-量化方法"><a href="#IAO-量化方法" class="headerlink" title="IAO 量化方法"></a>IAO 量化方法</h2><p>IAO 是 Google 提出的量化方法，主要应用在 TensorFlow Lite 中，有了 TensorRT 的知识铺垫，讲 IAO 就比较简单了。</p><h3 id="IAO-量化原理"><a href="#IAO-量化原理" class="headerlink" title="IAO 量化原理"></a>IAO 量化原理</h3><p>首先是量化公式：</p><script type="math/tex; mode=display">Q = \frac{R}{S} + Z</script><p>其中，$R$ 表示真实的浮点值，$Q$ 表示量化后的定点值，$Z$ 表示 0 浮点值对应的量化定点值，也称<strong>零点漂移</strong>，$S$ 则为量化的 scale factor，$S$ 和 $Z$ 的求值公式如下：</p><script type="math/tex; mode=display">S = \frac{R_{max} - R_{min}}{Q_{max} - Q_{min}}</script><script type="math/tex; mode=display">Z = Q_{max} - \frac{R_{max}}{S}</script><p><strong>这里的 $S$ 和 $Z$ 均是量化参数，$S$ 是 FP32 类型，而 $Z$ 是 INT8 类型</strong>。 $Q$ 和 $R$ 均可由公式进行求值，不管是量化后的 $Q$ 还是反推求得的浮点值 $R$，如果它们超出各自可表示的最大范围，那么均需要进行截断处理。</p><p>文章中指出 0 值对于神经网络具有重大意义，需要小心的处理，因此引入了零点偏移的概念。在我个人看来，我觉得<strong>这个量化公式和 TensorRT 中权重量化的区别就在于加入了 TensorRT 去掉的偏置项</strong>。虽然 NVIDIA 研究人员用实验说明了这个偏置项不重要，但是 Google 也有自己的理由和考虑，我觉得求同存异，看个人的理解吧。下面以一组例子说明这个公式的用法：</p><p>假设训练后的权重或者激活值的分布范围是[-3.0, 7.0]，INT8 量化后表示的范围[-128，127]，$S$ 和 $Z$ 可以计算如下：</p><script type="math/tex; mode=display">S=\frac{7.0-(-3.0)}{127-(-128)}=\frac{10}{255} \approx 0.039216</script><script type="math/tex; mode=display">Z=127- \frac{7.0}{0.039216} \approx -51.498572 \approx -51</script><p>假设我们有一个激活值 0.78，即 $R=0.78$，则对应定点值求解如下：</p><script type="math/tex; mode=display">Q=\frac{0.78}{0.039216} + (-51) \approx -31.11016 \approx -31</script><p>可以看出，只要确定了浮点数的边界（定点数的边界时已知的），计算量化参数以及量化浮点数这些都和 TensorRT 以及 NCNN 非常的像，<strong>只不过 IAO 没有使用 KLD 那种方式寻找最佳阈值，而是直接使用要量化的数值集合的浮点数边界，和 NCNN 中 weights 的量化类似</strong>。</p><h3 id="IAO-量化计算"><a href="#IAO-量化计算" class="headerlink" title="IAO 量化计算"></a>IAO 量化计算</h3><p>和 TensorRT，我们根据量化公式也可以直接表示矩阵相乘：</p><script type="math/tex; mode=display">S_3(q_3^{(i,k)}-Z_3)=\sum_{j=1}^N{S_1(q_1^{(i,j)}-Z_1)S_2(q_2^{(j,k)}-Z_2)}</script><script type="math/tex; mode=display">q_3^{(i,k)}=Z_3 + M \sum_{j=1}^N{(q_1^{(i,j)}-Z_1)(q_2^{(j,k)}-Z_2)}</script><p>其中 $M=\frac{S_1S_2}{S_3}$，可以看到，整个式子中只有 $M$ 是浮点数，其余都是整型（INT8 或者 INT32）。实验经验表明 $M$ 的范围是 (0, 1)，因此想办法将其也用整数表示，做法如下：</p><script type="math/tex; mode=display">M_0=2^nM</script><p>$M_0$ 是一个 (0.5, 1] 的数，记录 $M$ 到 $M_0$ 的扩大（缩小）幅度 $n$（在计算机中可以用右移位数表示），然后将 $M_0$ 乘以 $2^{31}$，截断，得到一个 INT32 整形数 $M_q$。这里还有一个特别处理，如果 $M_0$ 接近 1，上述乘积结果 $M_q$ 等于 $2^{31}$，超过 INT32 表示的最大值（$2^{31}$-1），因此将结果除以 2，相应的将记录的倍数 n 也减小 1。这样我们就可以用一个 INT32 整型数 $M_q$ 和 一个变化因子 $n$ 来表示浮点数 $M$，从 $M_q$ 恢复 $M$ 就是上述过程的逆向操作。</p><h3 id="IAO-量化训练"><a href="#IAO-量化训练" class="headerlink" title="IAO 量化训练"></a>IAO 量化训练</h3><p>IAO 方法将权重、激活值及输入值均全部做 INT8 量化，并且将所有模型运算操作置于 INT8 下进行执行，以达到最好的量化效果。为了达到此目的，需要实施量化精度补偿训练。下面还是以一个卷积层计算的具体例子说明 IAO 量化训练：</p><ol><li>输入 量化的特征图 lhs_quantized_val，INT8 类型，偏移量 lhs_zero_point，INT32 类型；</li><li>输入 量化的卷积核 rhs_quantized_val，INT8 类型，偏移量 rhs_zero_point，INT32 类型；</li><li>转换 INT8 到 INT32类型；</li><li>每一块卷积求和（INT32 乘法求和有溢出风险，可换成固定点小数树乘法）；<ul><li><code>int32_accumulator += (lhs_quantized_val(i, j) - lhs_zero_point) * (rhs_quantized_val(j, k) - rhs_zero_point)</code></li></ul></li><li>输入 量化的乘子 quantized_multiplier（$M_q$，INT32 类型 ）和右移次数记录 right_shift（$n$)，INT 类型；<ul><li><code>real_multiplier = (S_in * S_W / S_out) * (2^n)</code></li><li><code>quantized_multiplier = round(real_multiplier * (1 &lt;&lt; 31))</code></li></ul></li><li>计算乘法，得到 INT32 类型的结果 (INT32乘法有溢出风险，可换成固定点小数树乘法);<ul><li><code>int32_result = quantized_multiplier * int32_accumulator</code></li></ul></li><li>再左移动 right_shift 位还原，得到 INT32 的结果；</li><li>最后再加上结果的偏移量 result_zero_point；</li><li>将 INT32 类型结果强制转换到 INT8 类型，就得到了量化后的矩阵计算结果；</li><li>之后再反量化到浮点数，更新统计输出值分布信息 $R_{max}$, $R_{min}$；</li><li>再量化回 INT8；</li><li>之后经过量化激活层；</li><li>最后反量化到浮点数，本层网络输出；</li><li>进入下一层，循环执行 1~12 步骤</li></ol><p>可以看出，上述的操作就是在传统神经网络的前向传播过程中加入量化和反量化的操作，这其中无疑引入了量化带来的精度误差，我个人理解量化训练的目的就是为了让参数分布适应这种误差。Relu层的流程可以表示如下：</p><p><img src="/images/posts/dl/quantization/iao_relu_layer.jpg" alt></p><p>量化精度补偿训练需要一个具有代表性的小数据集，用于统计激活值和输入值等非确定性值的浮点型范围，以便进行精准量化，而输出值的 scale 计算则更加有意思，在训练最开始的时候将输出的值看作量化好的 INT8 类型，然后通过训练，不同搜集值得范围、计算 scale、调整，最后收敛。总体而言，其思想是和 TensorRT 中的校准数据集类似，只不过 IAO 方法直接收集的数值集合的最大最小值。全整型量化的输入输出依然是浮点型的，但如果某些 Op 未实现该方法，则转化是没问题的且其依然会自动保存为浮点型。</p><p>虽然是直接收集，但是针对卷积层和全连接层以及激活层的处理方式还是不同的。卷积层和全连接层处理方式类似都是直接统计最大值最小值，而激活层的值变化较大，因此使用一种称为 EMA 的方法来统计最大最小值。量化精度补偿训练一般是浮点模型训练的比较好的时候再进行，并且模拟量化的时候，反向传播仍然使用 FP32 类型，这是为了保证反向传播的精度。</p><p>TensorFlow 中使用 IAO 方法也将卷积和结果和偏置项相加，激活层等操作进行了融合，还有一些实现细节，包括 BN 的更新等我就不展开叙述了。融合的计算流程如下：</p><p><img src="/images/posts/dl/quantization/iao_fusion.png" alt></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>最后想说说量化适合的应用场景，由于量化是牺牲了部分精度（虽然比较小）来压缩和加速网络，因此不适合精度非常敏感的任务。量化目前最适合的领域就是图像处理，因为图片的信息冗余是非常大的，比如相邻一块的像素几乎都一模一样，因此用量化处理一些图像任务，比如目标检测、分类等对于精度不是非常敏感的 CV 任务而言是很适合的。</p><p>需要说明的是，量化只是深度神经网络压缩和加速的一种方法，还有包括蒸馏、矩阵秩分解、网络剪枝等多种方法。但是量化是一种已经获得了工业界认可和使用的方法，在训练（training）中使用 FP32，在推理（inference）期间使用 INT8 这套量化体系已经被包括 TensorRT，TensorFlow，PyTorch，MxNet 等众多深度学习框架启用。</p><p>就这两套方案而言，TensorRT 更加简单，实现起来也比较方便，IAO 方法在理论上精度更高，但是实际我自身只使用过前者，并没有验证过。后者如果使用 TensorFlow 的接口，使用也不难。</p><h4 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h4><ul><li><a href="https://zhuanlan.zhihu.com/p/71881443" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/71881443</a></li><li><a href="http://on-demand.gputechconf.com/gtc/2017/presentation/s7310-8-bit-inference-with-tensorrt.pdf" target="_blank" rel="noopener">http://on-demand.gputechconf.com/gtc/2017/presentation/s7310-8-bit-inference-with-tensorrt.pdf</a></li><li><a href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Jacob_Quantization_and_Training_CVPR_2018_paper.pdf" target="_blank" rel="noopener">http://openaccess.thecvf.com/content_cvpr_2018/papers/Jacob_Quantization_and_Training_CVPR_2018_paper.pdf</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;神经网络虽然在多个领域取得了非常巨大的成就，但是其本质是大量参数的拟合和泛化，如果想处理更加复杂的任务，在没有过拟合的情况下，增加训练数据和加大网络规模无疑是简单有效的手段。现实情况就是这么做的，但是巨大的参数量和复杂的网络结构造成了两个主要的问题：模型体积和运算速度。这两个问题会带来诸如内存容量，内存存取带宽，移动端还有电量消耗等一系列问题，大大限制了神经网络的应用场景。&lt;/p&gt;
    
    </summary>
    
      <category term="深度学习" scheme="https://murphypei.github.io/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="深度学习" scheme="https://murphypei.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="TensorRT" scheme="https://murphypei.github.io/tags/TensorRT/"/>
    
      <category term="神经网络" scheme="https://murphypei.github.io/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="量化" scheme="https://murphypei.github.io/tags/%E9%87%8F%E5%8C%96/"/>
    
  </entry>
  
  <entry>
    <title>CUDA 多线程并行</title>
    <link href="https://murphypei.github.io//blog/2019/10/cuda-parallel.html"/>
    <id>https://murphypei.github.io//blog/2019/10/cuda-parallel.html</id>
    <published>2019-10-30T09:47:03.000Z</published>
    <updated>2019-11-25T07:53:38.073Z</updated>
    
    <content type="html"><![CDATA[<p>cuda 中核函数执行使用多线程并行（SIMD）的方式，同时计算多个数据，因此核函数的线程管理以及相应的任务分配就显得尤为重要。</p><a id="more"></a><p>首先说明一点，cuda 中使用 <code>dim3</code> 作为三维数据的表示方式，其表示的意义如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">dim3 <span class="title">blocks1D</span><span class="params">( <span class="number">5</span>       )</span></span>; <span class="comment">// 5*1*1</span></span><br><span class="line"><span class="function">dim3 <span class="title">blocks2D</span><span class="params">( <span class="number">5</span>, <span class="number">5</span>    )</span></span>;<span class="comment">// 5*5*1</span></span><br><span class="line"><span class="function">dim3 <span class="title">blocks3D</span><span class="params">( <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span> )</span></span>;<span class="comment">// 5*5*5</span></span><br></pre></td></tr></table></figure><p>再来看看 cuda 中 kernel 函数的典型调用形式：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kernel&lt;&lt;&lt;Dg, Db, Ns, S&gt;&gt;&gt;(params);</span><br></pre></td></tr></table></figure><ul><li>参数 <code>Dg</code> 是一个 <code>dim3</code> 类型，用于定义整个 grid 的维度，也就是一个 grid 中有多少个 block。<code>dim3 Dg(Dg.x, Dg.y, 1)</code> 表示 grid 中每行有 <code>Dg.x</code> 个block，每列有 <code>Dg.y</code> 个block，第三维恒为 1。整个 grid 中共有 <code>Dg.x*Dg.y</code> 个 block，其中 <code>Dg.x</code> 和 <code>Dg.y</code> 最大值为 65535。<ul><li>对于一个 grid，其中包含了多个 block，使用 <code>unit3</code> 类型的 <code>blockIdx</code> 来表示，通过 <code>blockIdx.x</code>，<code>blockIdx.y</code>，<code>blockIdx.z</code> 三个坐标可以定位 grid 中的一个 block。</li><li>注意：<code>dim3</code> 是手工定义的，主机端可见。<code>uint3</code> 是设备端在执行的时候可见的，不可以在核函数运行时修改，初始化完成后 <code>uint3</code> 值就不变了。他们是有区别的，这一点必须要注意。</li></ul></li><li>参数 <code>Db</code> 是一个 <code>dim3</code> 类型，用于定义一个 block 的维度，即一个 block 有多少个 thread。<code>Dim3 Db(Db.x, Db.y, Db.z)</code> 表示整个 block 中每行有 <code>Db.x</code> 个thread，每列有 <code>Db.y</code> 个thread，高度为 <code>Db.z</code>。<code>Db.x</code> 和 <code>Db.y</code>最大值为 512，<code>Db.z</code> 最大值为 62。 一个 block中 共有 <code>Db.x*Db.y*Db.z</code> 个 thread。不同计算能力这个乘积的最大值不一样。<ul><li>和在 grid 中定位一个 block 类似，在一个 block 中定位一个 thread 也是用一个 <code>unit3</code> 类型的 <code>threadIdx</code> 的三个坐标来表示的。</li></ul></li><li>参数 <code>Ns</code> 是一个可选参数，用于设置每个 block 除了静态分配的 shared memory 以外，最多能动态分配的 shared memory 大小，单位为 byte。不需要动态分配时该值为0或省略不写。</li><li>参数 <code>S</code> 是一个 <code>cudaStream_t</code> 类型的可选参数，初始值为零，表示该核函数处在哪个流之中。</li></ul><p>kernel 可以通过 grid 和 block 的设置实现了多线程并行计算，下面是 cuda 官方的一个向量相加的例子，其中的 kernel 函数就是实际计算程序：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"../common/book.h"</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> N   (33 * 1024)</span></span><br><span class="line"></span><br><span class="line">__<span class="function">global__ <span class="keyword">void</span> <span class="title">add</span><span class="params">( <span class="keyword">int</span> *a, <span class="keyword">int</span> *b, <span class="keyword">int</span> *c )</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> tid = threadIdx.x + blockIdx.x * blockDim.x;</span><br><span class="line">    <span class="keyword">while</span> (tid &lt; N) &#123;</span><br><span class="line">        c[tid] = a[tid] + b[tid];</span><br><span class="line">        tid += blockDim.x * gridDim.x;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">( <span class="keyword">void</span> )</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> *a, *b, *c;</span><br><span class="line">    <span class="keyword">int</span> *dev_a, *dev_b, *dev_c;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// allocate the memory on the CPU</span></span><br><span class="line">    a = (<span class="keyword">int</span>*)<span class="built_in">malloc</span>( N * <span class="keyword">sizeof</span>(<span class="keyword">int</span>) );</span><br><span class="line">    b = (<span class="keyword">int</span>*)<span class="built_in">malloc</span>( N * <span class="keyword">sizeof</span>(<span class="keyword">int</span>) );</span><br><span class="line">    c = (<span class="keyword">int</span>*)<span class="built_in">malloc</span>( N * <span class="keyword">sizeof</span>(<span class="keyword">int</span>) );</span><br><span class="line"></span><br><span class="line">    <span class="comment">// allocate the memory on the GPU</span></span><br><span class="line">    HANDLE_ERROR( cudaMalloc( (<span class="keyword">void</span>**)&amp;dev_a, N * <span class="keyword">sizeof</span>(<span class="keyword">int</span>) ) );</span><br><span class="line">    HANDLE_ERROR( cudaMalloc( (<span class="keyword">void</span>**)&amp;dev_b, N * <span class="keyword">sizeof</span>(<span class="keyword">int</span>) ) );</span><br><span class="line">    HANDLE_ERROR( cudaMalloc( (<span class="keyword">void</span>**)&amp;dev_c, N * <span class="keyword">sizeof</span>(<span class="keyword">int</span>) ) );</span><br><span class="line"></span><br><span class="line">    <span class="comment">// fill the arrays 'a' and 'b' on the CPU</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;N; i++) &#123;</span><br><span class="line">        a[i] = i;</span><br><span class="line">        b[i] = <span class="number">2</span> * i;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// copy the arrays 'a' and 'b' to the GPU</span></span><br><span class="line">    HANDLE_ERROR( cudaMemcpy( dev_a, a, N * <span class="keyword">sizeof</span>(<span class="keyword">int</span>),</span><br><span class="line">                              cudaMemcpyHostToDevice ) );</span><br><span class="line">    HANDLE_ERROR( cudaMemcpy( dev_b, b, N * <span class="keyword">sizeof</span>(<span class="keyword">int</span>),</span><br><span class="line">                              cudaMemcpyHostToDevice ) );</span><br><span class="line"></span><br><span class="line">    add&lt;&lt;&lt;<span class="number">128</span>,<span class="number">128</span>&gt;&gt;&gt;( dev_a, dev_b, dev_c );</span><br><span class="line"></span><br><span class="line">    <span class="comment">// copy the array 'c' back from the GPU to the CPU</span></span><br><span class="line">    HANDLE_ERROR( cudaMemcpy( c, dev_c, N * <span class="keyword">sizeof</span>(<span class="keyword">int</span>),</span><br><span class="line">                              cudaMemcpyDeviceToHost ) );</span><br><span class="line"></span><br><span class="line">    <span class="comment">// verify that the GPU did the work we requested</span></span><br><span class="line">    <span class="keyword">bool</span> success = <span class="literal">true</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;N; i++) &#123;</span><br><span class="line">        <span class="keyword">if</span> ((a[i] + b[i]) != c[i]) &#123;</span><br><span class="line">            <span class="built_in">printf</span>( <span class="string">"Error:  %d + %d != %d\n"</span>, a[i], b[i], c[i] );</span><br><span class="line">            success = <span class="literal">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (success)    </span><br><span class="line">        <span class="built_in">printf</span>( <span class="string">"We did it!\n"</span> );</span><br><span class="line"></span><br><span class="line">    <span class="comment">// free the memory we allocated on the GPU</span></span><br><span class="line">    HANDLE_ERROR( cudaFree( dev_a ) );</span><br><span class="line">    HANDLE_ERROR( cudaFree( dev_b ) );</span><br><span class="line">    HANDLE_ERROR( cudaFree( dev_c ) );</span><br><span class="line"></span><br><span class="line">    <span class="comment">// free the memory we allocated on the CPU</span></span><br><span class="line">    <span class="built_in">free</span>( a );</span><br><span class="line">    <span class="built_in">free</span>( b );</span><br><span class="line">    <span class="built_in">free</span>( c );</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上面的代码中可以通过 <code>threadIdx.x + blockIdx.x * blockDim.x</code> 定位当前执行线程的 index。但是我们实际操作的数据长度(33*1024) 大于设置的线程数量 (128*128)。因此一个线程可能会处理多个数据，因此使用 <code>tid += blockDim.x * gridDim.x</code> 来执行多个数据的处理。当然，需要判断 <code>tid</code> 是否越界。</p><p>因为我们都是通过多线程并行来实现 kernel 的高效执行，因此也可以说编写核函数的精髓就是如何利用线程的序号（索引值）来分配计算任务。这里有一个题外话，<strong>之所以在硬件上将线程抽象成三维数组来表示，就是为了方便图像处理里，利用三维的线程索引来对应图像数据索引，并行加速，其实对于底层硬件，不存在三维线程的概念</strong>。</p><p>至于对于一个任务应该分配多少线程，grid 和 block 应该设置为多大，这根据需求和硬件素质。通常选取 2 的倍数作为线程总数，合理地平均分配任务到各个线程。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;cuda 中核函数执行使用多线程并行（SIMD）的方式，同时计算多个数据，因此核函数的线程管理以及相应的任务分配就显得尤为重要。&lt;/p&gt;
    
    </summary>
    
      <category term="C++" scheme="https://murphypei.github.io/categories/C/"/>
    
    
      <category term="cuda" scheme="https://murphypei.github.io/tags/cuda/"/>
    
      <category term="kernel" scheme="https://murphypei.github.io/tags/kernel/"/>
    
      <category term="simd" scheme="https://murphypei.github.io/tags/simd/"/>
    
      <category term="block" scheme="https://murphypei.github.io/tags/block/"/>
    
      <category term="grid" scheme="https://murphypei.github.io/tags/grid/"/>
    
  </entry>
  
  <entry>
    <title>C++11 的随机数</title>
    <link href="https://murphypei.github.io//blog/2019/10/cpp-random.html"/>
    <id>https://murphypei.github.io//blog/2019/10/cpp-random.html</id>
    <published>2019-10-30T09:46:32.000Z</published>
    <updated>2019-10-30T09:48:47.633Z</updated>
    
    <content type="html"><![CDATA[<p>C++11 带来了丰富便捷的随机数生成方法。</p><a id="more"></a><p>C++11 的随机数分为三个层次，下面分别叙述。</p><h3 id="产生随机数"><a href="#产生随机数" class="headerlink" title="产生随机数"></a>产生随机数</h3><p>标准库提供了一个<strong>非确定性随机数</strong>生成设备。在 Linux 的实现中，是读取 <code>/dev/urandom</code> 设备；Windows 的实现是用<code>rand_s</code>，在这里强烈谴责一下。<code>random_device</code> 提供 <code>()</code> 操作符，用来返回一个 <code>min()</code> 到 <code>max()</code> 之间的一个数字。因此 Linux（包括类 Unix）下调用 <code>random_device()</code> 获取的是一个真随机数，Windows 是伪随机数。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;random&gt;</span></span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="built_in">std</span>::random_device rd;</span><br><span class="line">  <span class="keyword">for</span>(<span class="keyword">int</span> n=<span class="number">0</span>; n&lt;<span class="number">20000</span>; ++n)</span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; rd() &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="随机数引擎"><a href="#随机数引擎" class="headerlink" title="随机数引擎"></a>随机数引擎</h3><p>C++ 中的均匀随机位生成器 (URBG) ，也就是随机数引擎是伪随机数生成器。这种随机数生成器传入一个种子，根据种子生成随机数，这也是我们最常见的一种随机数生成器。这种随机数引擎本质是一种算数算法，因此<strong>相同的种子多次调用产生的随机数是完全相同的</strong>。</p><p>标准提供三种常用的引擎：linear_congruential_engine，mersenne_twister_engine 和 subtract_with_carry_engine。第一种是线性同余算法，第二种是梅森旋转算法，第三种带进位的线性同余算法。第一种是最常用的，而且速度也是非常快的；第二种号称是最好的伪随机数生成器；第三种目前还不太清楚。</p><p>随机数引擎接受一个整形参数当作种子，不提供的话，会使用默认值。如果想多次运行产生相同的随机数，可以使用一个确定的数作为种子。如果是想每次运行生成不一样的随机数，Linux 推荐使用 <code>random_device</code> 来产生一个随机数当作种子，windows 产生一个伪随机数作为种子吧。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;random&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="built_in">std</span>::random_device rd;</span><br><span class="line">  <span class="built_in">std</span>::<span class="function">mt19937 <span class="title">mt</span><span class="params">(rd())</span></span>;<span class="comment">// 梅森旋转算法</span></span><br><span class="line">  <span class="keyword">for</span>(<span class="keyword">int</span> n = <span class="number">0</span>; n &lt; <span class="number">10</span>; n++)</span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; mt() &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="随机分布"><a href="#随机分布" class="headerlink" title="随机分布"></a>随机分布</h3><p>STL 标准库还提供各种各样的随机分布，不过我们经常用的比较少，比如平均分布，正太分布…使用也很简单。随机分布是利用一定的算法处理 URBG 的输出，以使得输出结果按照定义的统计概率密度函数分布。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//平均分布</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;random&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">std</span>::random_device rd;</span><br><span class="line">    <span class="built_in">std</span>::<span class="function">mt19937 <span class="title">gen</span><span class="params">(rd())</span></span>;</span><br><span class="line">    <span class="built_in">std</span>::uniform_int_distribution&lt;&gt; dis(<span class="number">1</span>, <span class="number">6</span>);</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> n=<span class="number">0</span>; n&lt;<span class="number">10</span>; ++n)</span><br><span class="line">        <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; dis(gen) &lt;&lt; <span class="string">' '</span>;</span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="string">'\n'</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//正太分布</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iomanip&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;string&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;map&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;random&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;cmath&gt;</span></span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">std</span>::random_device rd;</span><br><span class="line">    <span class="built_in">std</span>::<span class="function">mt19937 <span class="title">gen</span><span class="params">(rd())</span></span>;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">// values near the mean are the most likely</span></span><br><span class="line">    <span class="comment">// standard deviation affects the dispersion of generated values from the mean</span></span><br><span class="line">    <span class="built_in">std</span>::normal_distribution&lt;&gt; d(<span class="number">5</span>,<span class="number">2</span>);</span><br><span class="line"> </span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">map</span>&lt;<span class="keyword">int</span>, <span class="keyword">int</span>&gt; hist;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> n=<span class="number">0</span>; n&lt;<span class="number">10000</span>; ++n) &#123;</span><br><span class="line">        ++hist[<span class="built_in">std</span>::round(d(gen))];</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">auto</span> p : hist) &#123;</span><br><span class="line">        <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="built_in">std</span>::fixed &lt;&lt; <span class="built_in">std</span>::setprecision(<span class="number">1</span>) &lt;&lt; <span class="built_in">std</span>::setw(<span class="number">2</span>)</span><br><span class="line">                  &lt;&lt; p.first &lt;&lt; <span class="string">' '</span> &lt;&lt; <span class="built_in">std</span>::<span class="built_in">string</span>(p.second/<span class="number">200</span>, <span class="string">'*'</span>) &lt;&lt; <span class="string">'\n'</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;C++11 带来了丰富便捷的随机数生成方法。&lt;/p&gt;
    
    </summary>
    
      <category term="C++" scheme="https://murphypei.github.io/categories/C/"/>
    
    
      <category term="C++" scheme="https://murphypei.github.io/tags/C/"/>
    
      <category term="C++11" scheme="https://murphypei.github.io/tags/C-11/"/>
    
      <category term="random" scheme="https://murphypei.github.io/tags/random/"/>
    
      <category term="engine" scheme="https://murphypei.github.io/tags/engine/"/>
    
  </entry>
  
  <entry>
    <title>程序绑定 CPU 核心</title>
    <link href="https://murphypei.github.io//blog/2019/09/bind-cpu.html"/>
    <id>https://murphypei.github.io//blog/2019/09/bind-cpu.html</id>
    <published>2019-09-26T08:33:17.000Z</published>
    <updated>2019-12-24T06:21:37.825Z</updated>
    
    <content type="html"><![CDATA[<p>有时候需要将程序绑定到固定 CPU 的某个核心上运行。</p><a id="more"></a><p>我们知道多核 CPU 系统中，进程和线程的运行在哪个核心是由操作系统内核根据一定的调度算法进行调度的。但是实际软件开发过程中，我们出于一些目的，想要进程或者线程稳定运行在某个 CPU  核心上。比如我想测试两种算法的性能，因为服务器上有一些其他的进程干扰，测试的时间总是有波动，此时就需要将测试程序稳定在某个核心上测试。</p><p>Linux 中有 CPU 亲和性这种说法（Windows 有没有我不知道，也不关心）。引用一下维基百科的说法：</p><blockquote><p>CPU 亲和性就是绑定某一进程（或线程）到特定的 CPU（或 CPU 集合），从而使得该进程（或线程）只能运行在绑定的 CPU（或 CPU 集合）上。CPU 亲和性利用了这样一个事实：进程上一次运行后的残余信息会保留在 CPU 的状态中（也就是指 CPU 的缓存）。如果下一次仍然将该进程调度到同一个 CPU 上，就能避免缓存未命中等对 CPU 处理性能不利的情况，从而使得进程的运行更加高效。</p></blockquote><p>Linux 系统中每个进程的 <code>task_struct</code> 结构中有一个 <code>cpus_allowed</code> 位掩码，该掩码的位数与系统CPU 核数相同（若 CPU 启用了超线程则为核数乘以 2），通过修改该位掩码可以控制进程可运行在哪些特定 CPU 上。Linux 系统为我们提供了 CPU 亲和性相关的调用函数和一些操作的宏定义。</p><p>Linux 提供了一些宏定义来修改掩码，如 <code>CPU_ZERO()</code> （将位掩码全部设置为 0）和<code>CPU_SET()</code>（设置特定掩码位为 1）。CPU 的亲合力掩码用一个 <code>cpu_set_t</code> 结构体来表示一个 CPU 集合，下面的几个宏分别对这个掩码集进行操作:</p><ul><li><code>CPU_ZERO()</code>：清空一个集合。</li><li><code>CPU_SET()</code> 与 <code>CPU_CLR()</code> 分别对将一个给定的 CPU 号加到一个集合或者从一个集合中去掉。</li><li><code>CPU_ISSET()</code> 检查一个 CPU 号是否在这个集合中。</li></ul><p>然后还有两个接口帮助我们绑定进程到某个 CPU 或者 CPU 集合上。</p><ul><li><code>sched_setaffinity(pid_t pid， unsigned int cpusetsize， cpu_set_t *mask)</code><ul><li>该函数设置<strong>进程</strong>为 <code>pid</code> 的这个进程，让它运行在 <code>mask</code> 所设定的 CPU 上。如果 <code>pid</code> 的值为 0，则表示指定的是当前进程，使当前进程运行在 <code>mask</code> 所设定的那些 CPU 上。第二个参数 <code>cpusetsize</code> 是 mask 所指定的数的长度。通常设定为 <code>sizeof(cpu_set_t)</code>。如果当前 <code>pid</code> 所指定的进程此时没有运行在 <code>mask</code> 所指定的任意一个 CPU 上，则该指定的进程会从其它 CPU 上迁移到 <code>mask</code> 的指定的一个 CPU 上运行。</li></ul></li><li><code>sched_getaffinity(pid_t pid， unsigned int cpusetsize， cpu_set_t *mask)</code><ul><li>该函数获得 <code>pid</code> 所指示的进程的 CPU 位掩码，并将该掩码返回到 <code>mask</code> 所指向的结构中。即获得指定 <code>pid</code> 当前可以运行在哪些 CPU 上。同样，如果 <code>pid</code> 值为0，也表示的是当前进程。</li></ul></li></ul><p>因此，一个简易常见的将当前进程绑定到 CPU 某个核心（比如 6，CPU ID 从 0 开始）的示例如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">cpu_set_t</span> mask;</span><br><span class="line"><span class="keyword">cpu_set_t</span> get;</span><br><span class="line">CPU_ZERO(&amp;mask);</span><br><span class="line"><span class="keyword">int</span> cpu_id = <span class="number">6</span>;</span><br><span class="line">CPU_SET(cpu_id， &amp;mask);</span><br><span class="line"><span class="keyword">if</span> (sched_setaffinity(<span class="number">0</span>， <span class="keyword">sizeof</span>(mask)， &amp;mask) == <span class="number">-1</span>)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="string">"WARNING: Could not set CPU Affinity， continuing。。。"</span> &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="string">"Bind process to cpu id: "</span> &lt;&lt; cpu_id &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Linux 还提供了线程绑定核心的接口：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">threadBindCPU</span><span class="params">(<span class="built_in">std</span>::thread &amp;thread, <span class="keyword">int</span> cpuID)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">unsigned</span> num_cpus = <span class="built_in">std</span>::thread::hardware_concurrency();</span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="string">"Launching "</span> &lt;&lt; num_cpus &lt;&lt; <span class="string">" threads\n"</span>;</span><br><span class="line">    <span class="keyword">cpu_set_t</span> mask;</span><br><span class="line">    CPU_ZERO(&amp;mask);</span><br><span class="line">    CPU_SET(cpuID, &amp;mask);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">int</span> rc = pthread_setaffinity_np(thread.native_handle(), <span class="keyword">sizeof</span>(<span class="keyword">cpu_set_t</span>), &amp;mask);</span><br><span class="line">    <span class="keyword">if</span> (rc != <span class="number">0</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">std</span>::<span class="built_in">cerr</span> &lt;&lt; <span class="string">"Error calling pthread_setaffinity_np: "</span> &lt;&lt; rc &lt;&lt; <span class="string">"\n"</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="string">"thread id: "</span> &lt;&lt; <span class="built_in">std</span>::hash&lt;<span class="built_in">std</span>::thread::id&gt;&#123;&#125;(thread.get_id()) &lt;&lt; <span class="string">", cpu id: "</span> &lt;&lt; cpuID &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>查看某个线程绑定的 CPU 核心，需要在线程内部调用：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sched_getcpu()</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;有时候需要将程序绑定到固定 CPU 的某个核心上运行。&lt;/p&gt;
    
    </summary>
    
      <category term="C++" scheme="https://murphypei.github.io/categories/C/"/>
    
    
      <category term="C++" scheme="https://murphypei.github.io/tags/C/"/>
    
      <category term="Linux" scheme="https://murphypei.github.io/tags/Linux/"/>
    
      <category term="CPU" scheme="https://murphypei.github.io/tags/CPU/"/>
    
      <category term="sched_setaffinity" scheme="https://murphypei.github.io/tags/sched-setaffinity/"/>
    
  </entry>
  
  <entry>
    <title>OpenBLAS 中矩阵运算函数学习</title>
    <link href="https://murphypei.github.io//blog/2019/09/cblas-gemm-gemv.html"/>
    <id>https://murphypei.github.io//blog/2019/09/cblas-gemm-gemv.html</id>
    <published>2019-09-25T06:20:11.000Z</published>
    <updated>2019-10-21T12:02:24.763Z</updated>
    
    <content type="html"><![CDATA[<p>GEMM 是矩阵乘法最成熟的优化计算方式，也有很多现成的优化好的库可以调用。</p><a id="more"></a><h2 id="OpenBLAS-矩阵计算"><a href="#OpenBLAS-矩阵计算" class="headerlink" title="OpenBLAS 矩阵计算"></a>OpenBLAS 矩阵计算</h2><p>OpenBLAS 库实现成熟优化的矩阵与矩阵乘法的函数 <code>cblas_sgemm</code> 和矩阵与向量乘法函数 <code>cblas_sgemv</code>，二者使用方法基本相同，参数较多，所以对参数的使用做个记录。</p><h4 id="矩阵与矩阵乘法"><a href="#矩阵与矩阵乘法" class="headerlink" title="矩阵与矩阵乘法"></a>矩阵与矩阵乘法</h4><p><code>cblas_sgemm</code> 计算的矩阵公式：<code>C=alpha*A*B+beta*C</code>，其中 <code>A</code>、<code>B</code>、<code>C</code> 都是矩阵，<code>C</code> 初始中存放的可以是偏置值。</p><p><code>cblas_sgemm</code> 函数定义：</p><p><code>cblas_sgemm(layout, transA, transB, M, N, K, alpha, A, LDA, B, LDB, beta, C, LDC);</code></p><ul><li><code>layout</code>：存储格式，有行主序（<code>CblasRowMajor</code>）和列主序（<code>CblasRowMajor</code>），C/C++ 一般是行主序。</li><li><code>transA</code>：<code>A</code> 矩阵是否需要转置。</li><li><code>transB</code>：<code>B</code> 矩阵是否需要转置。</li><li><code>M</code>，<code>N</code>，<code>K</code>：<code>A</code> 矩阵经过 <code>transA</code> 之后的维度是 <code>M*K</code> ，<code>B</code> 矩阵经过 <code>transB</code> 之后的维度是 <code>K*N</code> ，<code>C</code> 矩阵的维度是 <code>M*N</code>。</li><li><code>LDA</code>，<code>LDB</code>，<code>LDC</code>：<strong>矩阵在 <code>trans</code> （如果需要转置）之前</strong>，在主维度方向的维度（如果是行主序，那这个参数就是列数）。</li></ul><p>示例代码：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;cblas.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">int</span> i, j;</span><br><span class="line">  <span class="keyword">float</span> a[<span class="number">6</span>]=&#123;<span class="number">1</span>,<span class="number">3</span>,<span class="number">5</span>,<span class="number">2</span>,<span class="number">7</span>,<span class="number">8</span>&#125;;</span><br><span class="line">  <span class="keyword">float</span> b[<span class="number">6</span>]=&#123;<span class="number">5</span>,<span class="number">3</span>,<span class="number">7</span>,<span class="number">2</span>,<span class="number">4</span>,<span class="number">2</span>&#125;;</span><br><span class="line">  <span class="keyword">float</span> c[<span class="number">6</span>]=&#123;<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>&#125;;</span><br><span class="line">  cblas_sgemm(CblasRowMajor, CblasTrans, CblasTrans, <span class="number">3</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">1.0</span>, a, <span class="number">3</span>, b, <span class="number">2</span>, <span class="number">0.0</span>, c, <span class="number">3</span>);</span><br><span class="line">  <span class="keyword">for</span>(i = <span class="number">0</span>; i &lt; <span class="number">3</span>; ++i)&#123;</span><br><span class="line">    <span class="keyword">for</span>(j = <span class="number">0</span>; j &lt; <span class="number">3</span>; ++j)&#123;</span><br><span class="line">      <span class="built_in">printf</span>(<span class="string">"%f "</span>, c[i*<span class="number">3</span>+j]);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"\n"</span>);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="矩阵与向量乘法"><a href="#矩阵与向量乘法" class="headerlink" title="矩阵与向量乘法"></a>矩阵与向量乘法</h4><p>矩阵与向量乘法本质也是矩阵与矩阵，只不过 <code>gemv</code> 比 <code>gemm</code> 要快一些，所以有时候也需要用 <code>gemv</code>。计算式：<code>C=alpha*A*b+beta*C</code></p><p><code>cblas_sgemv</code> 函数定义：</p><p><code>cblas_sgemv(layout, trans, M, N, alpha, A, LDA, b, 1, beta, C, 1)</code></p><p>参数的定义基本和 <code>gemm</code> 相同，<code>M</code> 和 <code>N</code> 是 <code>A</code> 的行数和列数，<code>b</code> 和 <code>C</code> 的列数都是 1。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;GEMM 是矩阵乘法最成熟的优化计算方式，也有很多现成的优化好的库可以调用。&lt;/p&gt;
    
    </summary>
    
      <category term="C++" scheme="https://murphypei.github.io/categories/C/"/>
    
    
      <category term="OpenBLAS" scheme="https://murphypei.github.io/tags/OpenBLAS/"/>
    
      <category term="cblas_sgemm" scheme="https://murphypei.github.io/tags/cblas-sgemm/"/>
    
      <category term="cblas_sgemv" scheme="https://murphypei.github.io/tags/cblas-sgemv/"/>
    
      <category term="gemm" scheme="https://murphypei.github.io/tags/gemm/"/>
    
  </entry>
  
  <entry>
    <title>CUDA 函数前缀</title>
    <link href="https://murphypei.github.io//blog/2019/09/cuda-function-prefix.html"/>
    <id>https://murphypei.github.io//blog/2019/09/cuda-function-prefix.html</id>
    <published>2019-09-11T06:46:47.000Z</published>
    <updated>2019-11-25T07:52:15.350Z</updated>
    
    <content type="html"><![CDATA[<p>CUDA 函数前缀作为 CUDA 编程中一种特殊的使用技巧，其具有一定的限制意义。</p><a id="more"></a><p>CUDA 使用 cu 作为文件类型后缀，而在文件中又存在几种前缀，如果在修改编写 .cu 文件时不注意，会出现问题，比如：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">error : calling a __host__ <span class="keyword">function</span> from a __global__ <span class="keyword">function</span> is not allowed.</span><br></pre></td></tr></table></figure><p>在 CUDA 中有三种常见的前缀：<code>__device__</code>， <code>__global__</code>，<code>__host__</code>，其分别代表不同的意思，而这三个单词其实也是 CUDA 中常见的三种运行场景：</p><div class="table-container"><table><thead><tr><th style="text-align:center">限定符</th><th style="text-align:center">执行</th><th style="text-align:center">调用</th><th style="text-align:center">备注</th></tr></thead><tbody><tr><td style="text-align:center">__global__</td><td style="text-align:center">设备端执行</td><td style="text-align:center">可以从主机调用也可以从计算能力3以上的设备调用</td><td style="text-align:center">必须有一个void的返回类型</td></tr><tr><td style="text-align:center">__device__</td><td style="text-align:center">设备端执行</td><td style="text-align:center">设备端调用</td><td style="text-align:center"></td></tr><tr><td style="text-align:center">__host__</td><td style="text-align:center">主机端执行</td><td style="text-align:center">主机调用</td><td style="text-align:center">可以省略</td></tr></tbody></table></div><p>因为函数前缀设定了函数的运行环境，因此对函数内部实现也做出了一定的限制，具体来说就是，device 函数因为只能在 GPU 上执行，因此不能调用常见的一些 C/C++ 函数（没有 GPU 实现），global 函数虽然能在 CPU 上运行，但是也能在 GPU 上面运行，因此同理。host 函数则没有这个限制，可以调用普通函数实现。</p><p>因此，在出现报错如：<code>error : calling a __host__ function from a __global__ function is not allowed.</code> 时候，即为将一个普通的函数错误地添加进入了 global 前缀定义函数，在 .cu 文件中是不允许的。</p><p>注意，有时候一个函数可以同时被多个前缀修饰的，比如 CUDA 10 浮点数的转换：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">__host__ ​ __device__ ​ __half __float2half ( <span class="keyword">const</span> <span class="keyword">float</span>  a ) <span class="keyword">throw</span> ( )</span><br></pre></td></tr></table></figure><p>以上修饰这个函数可以在 host 端被调用，也可以在 device 端被调用。实际上这个函数在 CUDA 9.2 以后才允许在 host 端调用，其 CUDA 8.0 的版本：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">__device__ ​ __half __float2half ( <span class="keyword">const</span> <span class="keyword">float</span>  a )</span><br></pre></td></tr></table></figure><p>因此，我们通过一个函数的前缀就可以判断这个函数的运行环境。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;CUDA 函数前缀作为 CUDA 编程中一种特殊的使用技巧，其具有一定的限制意义。&lt;/p&gt;
    
    </summary>
    
      <category term="C++" scheme="https://murphypei.github.io/categories/C/"/>
    
    
      <category term="cuda" scheme="https://murphypei.github.io/tags/cuda/"/>
    
      <category term="global" scheme="https://murphypei.github.io/tags/global/"/>
    
      <category term="host" scheme="https://murphypei.github.io/tags/host/"/>
    
      <category term="device" scheme="https://murphypei.github.io/tags/device/"/>
    
  </entry>
  
  <entry>
    <title>Python 日志库 logging 总结</title>
    <link href="https://murphypei.github.io//blog/2019/09/python-logging.html"/>
    <id>https://murphypei.github.io//blog/2019/09/python-logging.html</id>
    <published>2019-09-11T06:45:42.000Z</published>
    <updated>2019-09-11T08:26:05.757Z</updated>
    
    <content type="html"><![CDATA[<p>标准日志库 logging 即使不是 Python 中最好的日志库，也是使用最多的日志库了，我个人非常喜欢。本文较为全面的总结了 logging 库的知识点。</p><a id="more"></a><h3 id="logging-介绍"><a href="#logging-介绍" class="headerlink" title="logging 介绍"></a>logging 介绍</h3><h4 id="日志级别"><a href="#日志级别" class="headerlink" title="日志级别"></a>日志级别</h4><p>Python 标准库 logging 用作记录日志，默认分为六种日志级别（括号为级别对应的数值），NOTSET（0）、DEBUG（10）、INFO（20）、WARNING（30）、ERROR（40）、CRITICAL（50）。我们自定义日志级别时注意不要和默认的日志级别数值相同，logging 执行时输出大于等于设置的日志级别的日志信息，如设置日志级别是 INFO，则 INFO、WARNING、ERROR、CRITICAL 级别的日志都会输出。</p><h4 id="工作流程"><a href="#工作流程" class="headerlink" title="工作流程"></a>工作流程</h4><p>官方的 logging 模块工作流程图如下：</p><p><img src="/images/posts/python/python-logging-flow.png" alt="logging 工作流程"></p><p>从下图中我们可以看出看到这几种 Python 类型，Logger、LogRecord、Filter、Handler、Formatter。它们的作用分别为：</p><ul><li>Logger：日志，暴露函数给应用程序，基于日志记录器和过滤器级别决定哪些日志有效。</li><li>LogRecord ：日志记录器，将日志传到相应的处理器处理。</li><li>Handler ：处理器, 将(日志记录器产生的)日志记录发送至合适的目的地。</li><li>Filter ：过滤器, 提供了更好的粒度控制,它可以决定输出哪些日志记录。</li><li>Formatter：格式化器, 指明了最终输出中日志记录的布局。</li></ul><p>logging 的整个工作流程：</p><ol><li>判断 Logger 对象对于设置的级别是否可用，如果可用，则往下执行，否则，流程结束。</li><li>创建 LogRecord 对象，如果注册到 Logger 对象中的 Filter 对象过滤后返回 False，则不记录日志，流程结束，否则，则向下执行。</li><li>LogRecord 对象将 Handler 对象传入当前的 Logger 对象，（图中的子流程）如果 Handler 对象的日志级别大于设置的日志级别，再判断注册到 Handler 对象中的 Filter 对象过滤后是否返回 True 而放行输出日志信息，否则不放行，流程结束。</li><li>如果传入的 Handler 大于 Logger 中设置的级别，也即 Handler 有效，则往下执行，否则，流程结束。</li><li>判断这个 Logger 对象是否还有父 Logger 对象，如果没有（代表当前 Logger 对象是最顶层的 Logger 对象 root Logger），流程结束。否则将 Logger 对象设置为它的父 Logger 对象，重复上面的 3、4 两步，输出父类 Logger 对象中的日志输出，直到是 root Logger 为止。</li></ol><h4 id="输出格式"><a href="#输出格式" class="headerlink" title="输出格式"></a>输出格式</h4><p>日志输出格式可以自定义，默认的比较简单： </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 日志级别:日志记录名称:日志消息内容</span></span><br><span class="line">WARNING:ROOT:MESSAGE</span><br></pre></td></tr></table></figure><h3 id="loggging-使用"><a href="#loggging-使用" class="headerlink" title="loggging 使用"></a>loggging 使用</h3><p>下面重点说说 logging 的使用，这也是大家最关心的。</p><h4 id="基本使用"><a href="#基本使用" class="headerlink" title="基本使用"></a>基本使用</h4><p>首先是基本使用，我所认为的基本使用就是我这个 Python 文件临时要记录一下，就这么简单。示例如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> logging</span><br><span class="line"></span><br><span class="line">logging.basicConfig()</span><br><span class="line">logging.debug(<span class="string">'This is a debug message'</span>)</span><br><span class="line">logging.info(<span class="string">'This is an info message'</span>)</span><br><span class="line">logging.warning(<span class="string">'This is a warning message'</span>)</span><br><span class="line">logging.error(<span class="string">'This is an error message'</span>)</span><br><span class="line">logging.critical(<span class="string">'This is a critical message'</span>)</span><br></pre></td></tr></table></figure><p>输出结果</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">WARNING:root:This <span class="keyword">is</span> a warning message</span><br><span class="line">ERROR:root:This <span class="keyword">is</span> an error message</span><br><span class="line">CRITICAL:root:This <span class="keyword">is</span> a critical message</span><br></pre></td></tr></table></figure><p>可以看到，<strong>默认打印的日志级别是 WARNING，不输出到文件，格式默认</strong>。</p><p>当然，如果我们不懒，在 <code>basicConfig</code> 中传入一些参数就可以定制一下了：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> logging</span><br><span class="line"></span><br><span class="line">logging.basicConfig(filename=<span class="string">"test.log"</span>,</span><br><span class="line">                    filemode=<span class="string">"w"</span>,</span><br><span class="line">                    format=<span class="string">"%(asctime)s %(name)s:%(levelname)s:%(message)s"</span>,</span><br><span class="line">                    datefmt=<span class="string">"%d-%M-%Y %H:%M:%S"</span>,</span><br><span class="line">                    level=logging.DEBUG)</span><br><span class="line"></span><br><span class="line">logging.debug(<span class="string">'This is a debug message'</span>)</span><br><span class="line">logging.info(<span class="string">'This is an info message'</span>)</span><br><span class="line">logging.warning(<span class="string">'This is a warning message'</span>)</span><br><span class="line">logging.error(<span class="string">'This is an error message'</span>)</span><br><span class="line">logging.critical(<span class="string">'This is a critical message'</span>)</span><br></pre></td></tr></table></figure><p>运行完毕，我们就可以在 test.log 中看到如下内容了：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">13</span><span class="number">-10</span><span class="number">-18</span> <span class="number">21</span>:<span class="number">10</span>:<span class="number">32</span> root:DEBUG:This <span class="keyword">is</span> a debug message</span><br><span class="line"><span class="number">13</span><span class="number">-10</span><span class="number">-18</span> <span class="number">21</span>:<span class="number">10</span>:<span class="number">32</span> root:INFO:This <span class="keyword">is</span> an info message</span><br><span class="line"><span class="number">13</span><span class="number">-10</span><span class="number">-18</span> <span class="number">21</span>:<span class="number">10</span>:<span class="number">32</span> root:WARNING:This <span class="keyword">is</span> a warning message</span><br><span class="line"><span class="number">13</span><span class="number">-10</span><span class="number">-18</span> <span class="number">21</span>:<span class="number">10</span>:<span class="number">32</span> root:ERROR:This <span class="keyword">is</span> an error message</span><br><span class="line"><span class="number">13</span><span class="number">-10</span><span class="number">-18</span> <span class="number">21</span>:<span class="number">10</span>:<span class="number">32</span> root:CRITICAL:This <span class="keyword">is</span> a critical message</span><br></pre></td></tr></table></figure><blockquote><p>注意，此时输出到文件中，因此屏幕是不会打印任何内容的。</p></blockquote><p><code>basicConfig</code> 的参数如下：</p><div class="table-container"><table><thead><tr><th style="text-align:center">参数名称</th><th style="text-align:center">参数描述</th></tr></thead><tbody><tr><td style="text-align:center">filename</td><td style="text-align:center">日志输出到文件的文件名</td></tr><tr><td style="text-align:center">filemode</td><td style="text-align:center">文件模式，r[+]、w[+]、a[+]</td></tr><tr><td style="text-align:center">format</td><td style="text-align:center">日志输出的格式</td></tr><tr><td style="text-align:center">datefat</td><td style="text-align:center">日志附带日期时间的格式</td></tr><tr><td style="text-align:center">style</td><td style="text-align:center">格式占位符，默认为 “%” 和 “{}”</td></tr><tr><td style="text-align:center">level</td><td style="text-align:center">设置日志输出级别</td></tr><tr><td style="text-align:center">stream</td><td style="text-align:center">定义输出流，用来初始化 StreamHandler 对象，不能 filename 参数一起使用，否则会 ValueError 异常</td></tr><tr><td style="text-align:center">handles</td><td style="text-align:center">定义处理器，用来创建 Handler 对象，不能和 filename 、stream 参数一起使用，否则也会抛出 ValueError 异常</td></tr></tbody></table></div><p>这里有一个需要注意的地方，当发生异常时，直接使用无参数的 <code>debug()</code>、<code>info()</code>、<code>warning()</code>、<code>error()</code>、<code>critical()</code> 方法并不能记录异常信息，需要设置 <code>exc_info</code> 参数为 <code>True</code> 才可以，或者使用 <code>exception()</code> 方法，还可以使用 <code>log()</code> 方法，但还要设置日志级别和 <code>exc_info</code> 参数。示例如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> logging</span><br><span class="line"></span><br><span class="line">logging.basicConfig(filename=<span class="string">"test.log"</span>,</span><br><span class="line">                    filemode=<span class="string">"w"</span>,</span><br><span class="line">                    format=<span class="string">"%(asctime)s %(name)s:%(levelname)s:%(message)s"</span>,</span><br><span class="line">                    datefmt=<span class="string">"%d-%M-%Y %H:%M:%S"</span>,</span><br><span class="line">                    level=logging.DEBUG)</span><br><span class="line">a = <span class="number">5</span></span><br><span class="line">b = <span class="number">0</span></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    c = a / b</span><br><span class="line"><span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">    <span class="comment"># 下面三种方式三选一，推荐使用第一种</span></span><br><span class="line">    logging.exception(<span class="string">"Exception occurred"</span>)</span><br><span class="line">    logging.error(<span class="string">"Exception occurred"</span>, exc_info=<span class="literal">True</span>)</span><br><span class="line">    logging.log(level=logging.DEBUG, msg=<span class="string">"Exception occurred"</span>, exc_info=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><h4 id="自定义-logger"><a href="#自定义-logger" class="headerlink" title="自定义 logger"></a>自定义 logger</h4><p>以上的使用肯定不能满足大型项目的日志记录需求，因此就来到了喜闻乐见的自定义阶段了。。</p><p>首先需要明确一个比较重要的知识点：<strong>一个系统只有一个 Logger 对象</strong>，并且该对象不能被直接实例化，没错，这里用到了单例模式，获取 Logger 对象的方法为 <code>getLogger</code>。</p><blockquote><p>这里的单例模式并不是说只有一个 Logger 对象，而是指<strong>整个系统只有一个 root Logger 对象</strong>，Logger 对象在执行 <code>info()</code>、<code>error()</code> 等方法时实际上调用都是 root Logger 对象对应的 <code>info()</code>、<code>error()</code> 等方法。</p></blockquote><p>以上这句话需要深刻理解，因为在大型项目中，有很多文件，我们可以在每个文件中调用 <code>getLogger()</code> 来获取一个当前文件的 logger，存在以下情况：</p><ul><li>假如 <code>getLogger()</code> 不传入任何参数，则不同文件获取的都是 root Logger，因此对这些 Logger 对象的操作都将影响其他文件的输入，比如我在 A 文件中对 logger 添加了一个 <code>logging.StreamHandler()</code>，同时在 B 文件中也添加了一个，则最后打印出来的每条日志都有两行一样的，因为处理了两次。</li><li>假如我们在不同文件中调用 <code>getLogger()</code> 传入不同的名字，比如当前文件的模块名字，那么得到的 Logger 对象也是不同的，因此不同的 Logger 对象可以添加不同的 hanlder 来控制当前文件中日志的输出。</li><li>以上两种方式实际输出都是由 root Logger 作为代理来调用的，因此实际输出操作是 root Logger，但是我们可以根据第二条来实现同一项目不同文件不同输出的控制，也可以根据第一条实现统一的输出控制。在打印出来的日志示例名称（默认的第二列）中可以看到 Logger 对象的名字（默认 root）。</li></ul><p>每个 Logger 对象都可以设置一个名字，如果想区别不同文件的 logger，可以设置 <code>logger = logging.getLogger(__name__)</code>，<code>__name__</code> 是 Python 中的一个特殊内置变量，他代表当前模块的名称（默认为 <code>__main__</code>）。Logger 对象的 <code>name</code> 为建议使用使用以点号作为分隔符的命名空间等级制度。</p><p>Logger 对象可以设置多个 Handler 对象和 Filter 对象，Handler 对象又可以设置 Formatter 对象。Formatter 对象用来设置具体的输出格式，常用变量格式如下表所示，所有可以参数见官方文档：</p><div class="table-container"><table><thead><tr><th style="text-align:center">变量</th><th style="text-align:center">格式</th><th style="text-align:center">变量描述</th></tr></thead><tbody><tr><td style="text-align:center">asctime</td><td style="text-align:center">%(asctime)s</td><td style="text-align:center">将日志的时间构造成可读的形式，默认情况下是精确到毫秒，如 2018-10-13 23:24:57,832，可以额外指定 datefmt 参数来指定该变量的格式</td></tr><tr><td style="text-align:center">name</td><td style="text-align:center">%(name)</td><td style="text-align:center">日志对象的名称</td></tr><tr><td style="text-align:center">filename</td><td style="text-align:center">%(filename)s</td><td style="text-align:center">不包含路径的文件名</td></tr><tr><td style="text-align:center">pathname</td><td style="text-align:center">%(pathname)s</td><td style="text-align:center">包含路径的文件名</td></tr><tr><td style="text-align:center">funcName</td><td style="text-align:center">%(funcName)s</td><td style="text-align:center">日志记录所在的函数名</td></tr><tr><td style="text-align:center">levelname</td><td style="text-align:center">%(levelname)s</td><td style="text-align:center">日志的级别名称</td></tr><tr><td style="text-align:center">message</td><td style="text-align:center">%(message)s</td><td style="text-align:center">具体的日志信息</td></tr><tr><td style="text-align:center">lineno</td><td style="text-align:center">%(lineno)d</td><td style="text-align:center">日志记录所在的行号</td></tr><tr><td style="text-align:center">pathname</td><td style="text-align:center">%(pathname)s</td><td style="text-align:center">完整路径</td></tr><tr><td style="text-align:center">process</td><td style="text-align:center">%(process)d</td><td style="text-align:center">当前进程ID</td></tr><tr><td style="text-align:center">processName</td><td style="text-align:center">%(processName)s</td><td style="text-align:center">当前进程名称</td></tr><tr><td style="text-align:center">thread</td><td style="text-align:center">%(thread)d</td><td style="text-align:center">当前线程ID</td></tr><tr><td style="text-align:center">threadName</td><td style="text-align:center">%threadName)s</td><td style="text-align:center">当前线程名称</td></tr></tbody></table></div><p>Logger 对象和 Handler 对象都可以设置级别，而默认 Logger 对象级别为 30，也即 WARNING，默认 Handler 对象级别为 0，也即 NOTSET。logging 模块这样设计是为了更好的灵活性，比如有时候我们既想在控制台中输出 DEBUG 级别的日志，又想在文件中输出WARNING 级别的日志。</p><blockquote><p>日志最后的输出级别是 Logger 和 Handler 中级别最高的，因此如果我们想输出低级别的，比如 INFO，不仅仅要设置 Handler 的级别，还需要修改 Logger 的级别。</p></blockquote><p>可以只设置一个最低级别的 Logger 对象，两个不同级别的 Handler 对象，示例代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> logging</span><br><span class="line"><span class="keyword">import</span> logging.handlers</span><br><span class="line"></span><br><span class="line">logger = logging.getLogger(<span class="string">"logger"</span>)</span><br><span class="line"></span><br><span class="line">handler1 = logging.StreamHandler()</span><br><span class="line">handler2 = logging.FileHandler(filename=<span class="string">"test.log"</span>)</span><br><span class="line"></span><br><span class="line">logger.setLevel(logging.DEBUG)</span><br><span class="line">handler1.setLevel(logging.WARNING)</span><br><span class="line">handler2.setLevel(logging.DEBUG)</span><br><span class="line"></span><br><span class="line">formatter = logging.Formatter(<span class="string">"%(asctime)s %(name)s %(levelname)s %(message)s"</span>)</span><br><span class="line">handler1.setFormatter(formatter)</span><br><span class="line">handler2.setFormatter(formatter)</span><br><span class="line"></span><br><span class="line">logger.addHandler(handler1)</span><br><span class="line">logger.addHandler(handler2)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 分别为 10、30、30</span></span><br><span class="line"><span class="comment"># print(handler1.level)</span></span><br><span class="line"><span class="comment"># print(handler2.level)</span></span><br><span class="line"><span class="comment"># print(logger.level)</span></span><br><span class="line"></span><br><span class="line">logger.debug(<span class="string">'This is a customer debug message'</span>)</span><br><span class="line">logger.info(<span class="string">'This is an customer info message'</span>)</span><br><span class="line">logger.warning(<span class="string">'This is a customer warning message'</span>)</span><br><span class="line">logger.error(<span class="string">'This is an customer error message'</span>)</span><br><span class="line">logger.critical(<span class="string">'This is a customer critical message'</span>)</span><br></pre></td></tr></table></figure><p>控制台输出结果为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">2018</span><span class="number">-10</span><span class="number">-13</span> <span class="number">23</span>:<span class="number">24</span>:<span class="number">57</span>,<span class="number">832</span> logger WARNING This <span class="keyword">is</span> a customer warning message</span><br><span class="line"><span class="number">2018</span><span class="number">-10</span><span class="number">-13</span> <span class="number">23</span>:<span class="number">24</span>:<span class="number">57</span>,<span class="number">832</span> logger ERROR This <span class="keyword">is</span> an customer error message</span><br><span class="line"><span class="number">2018</span><span class="number">-10</span><span class="number">-13</span> <span class="number">23</span>:<span class="number">24</span>:<span class="number">57</span>,<span class="number">832</span> logger CRITICAL This <span class="keyword">is</span> a customer critical message</span><br></pre></td></tr></table></figure><p>文件中输出内容为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">2018</span><span class="number">-10</span><span class="number">-13</span> <span class="number">23</span>:<span class="number">44</span>:<span class="number">59</span>,<span class="number">817</span> logger DEBUG This <span class="keyword">is</span> a customer debug message</span><br><span class="line"><span class="number">2018</span><span class="number">-10</span><span class="number">-13</span> <span class="number">23</span>:<span class="number">44</span>:<span class="number">59</span>,<span class="number">817</span> logger INFO This <span class="keyword">is</span> an customer info message</span><br><span class="line"><span class="number">2018</span><span class="number">-10</span><span class="number">-13</span> <span class="number">23</span>:<span class="number">44</span>:<span class="number">59</span>,<span class="number">817</span> logger WARNING This <span class="keyword">is</span> a customer warning message</span><br><span class="line"><span class="number">2018</span><span class="number">-10</span><span class="number">-13</span> <span class="number">23</span>:<span class="number">44</span>:<span class="number">59</span>,<span class="number">817</span> logger ERROR This <span class="keyword">is</span> an customer error message</span><br><span class="line"><span class="number">2018</span><span class="number">-10</span><span class="number">-13</span> <span class="number">23</span>:<span class="number">44</span>:<span class="number">59</span>,<span class="number">817</span> logger CRITICAL This <span class="keyword">is</span> a customer critical message</span><br></pre></td></tr></table></figure><p>创建了自定义的 Logger 对象，就不要在用 logging 中的日志输出方法了，这些方法使用的是默认配置的 Logger 对象，否则会输出的日志信息会重复。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> logging</span><br><span class="line"><span class="keyword">import</span> logging.handlers</span><br><span class="line"></span><br><span class="line">logger = logging.getLogger(<span class="string">"logger"</span>)</span><br><span class="line">handler = logging.StreamHandler()</span><br><span class="line">handler.setLevel(logging.DEBUG)</span><br><span class="line">formatter = logging.Formatter(<span class="string">"%(asctime)s %(name)s %(levelname)s %(message)s"</span>)</span><br><span class="line">handler.setFormatter(formatter)</span><br><span class="line">logger.addHandler(handler)</span><br><span class="line">logger.debug(<span class="string">'This is a customer debug message'</span>)</span><br><span class="line">logging.info(<span class="string">'This is an customer info message'</span>)</span><br><span class="line">logger.warning(<span class="string">'This is a customer warning message'</span>)</span><br><span class="line">logger.error(<span class="string">'This is an customer error message'</span>)</span><br><span class="line">logger.critical(<span class="string">'This is a customer critical message'</span>)`</span><br></pre></td></tr></table></figure><p>输出结果如下（可以看到日志信息被输出了两遍）：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">2018</span><span class="number">-10</span><span class="number">-13</span> <span class="number">22</span>:<span class="number">21</span>:<span class="number">35</span>,<span class="number">873</span> logger WARNING This <span class="keyword">is</span> a customer warning message</span><br><span class="line">WARNING:logger:This <span class="keyword">is</span> a customer warning message</span><br><span class="line"><span class="number">2018</span><span class="number">-10</span><span class="number">-13</span> <span class="number">22</span>:<span class="number">21</span>:<span class="number">35</span>,<span class="number">873</span> logger ERROR This <span class="keyword">is</span> an customer error message</span><br><span class="line">ERROR:logger:This <span class="keyword">is</span> an customer error message</span><br><span class="line"><span class="number">2018</span><span class="number">-10</span><span class="number">-13</span> <span class="number">22</span>:<span class="number">21</span>:<span class="number">35</span>,<span class="number">873</span> logger CRITICAL This <span class="keyword">is</span> a customer critical message</span><br><span class="line">CRITICAL:logger:This <span class="keyword">is</span> a customer critical message</span><br></pre></td></tr></table></figure><blockquote><p>在引入有日志输出的 Python 文件时，如 import test.py，在满足大于当前设置的日志级别后就会输出导入文件中的日志，在大型项目中尤其要注意。</p></blockquote><h4 id="logger-配置"><a href="#logger-配置" class="headerlink" title="logger 配置"></a>logger 配置</h4><p>通过上面的例子，我们知道创建一个 Logger 对象所需的配置了，上面直接硬编码在程序中配置对象，配置还可以从字典类型的对象和配置文件获取。打开 logging.config Python 文件，可以看到其中的配置解析转换函数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> logging.config</span><br><span class="line"></span><br><span class="line">config = &#123;</span><br><span class="line">    <span class="string">'version'</span>: <span class="number">1</span>,</span><br><span class="line">    <span class="string">'formatters'</span>: &#123;</span><br><span class="line">        <span class="string">'simple'</span>: &#123;</span><br><span class="line">            <span class="string">'format'</span>: <span class="string">'%(asctime)s - %(name)s - %(levelname)s - %(message)s'</span>,</span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="comment"># 其他的 formatter</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="string">'handlers'</span>: &#123;</span><br><span class="line">        <span class="string">'console'</span>: &#123;</span><br><span class="line">            <span class="string">'class'</span>: <span class="string">'logging.StreamHandler'</span>,</span><br><span class="line">            <span class="string">'level'</span>: <span class="string">'DEBUG'</span>,</span><br><span class="line">            <span class="string">'formatter'</span>: <span class="string">'simple'</span></span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="string">'file'</span>: &#123;</span><br><span class="line">            <span class="string">'class'</span>: <span class="string">'logging.FileHandler'</span>,</span><br><span class="line">            <span class="string">'filename'</span>: <span class="string">'logging.log'</span>,</span><br><span class="line">            <span class="string">'level'</span>: <span class="string">'DEBUG'</span>,</span><br><span class="line">            <span class="string">'formatter'</span>: <span class="string">'simple'</span></span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="comment"># 其他的 handler</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="string">'loggers'</span>:&#123;</span><br><span class="line">        <span class="string">'StreamLogger'</span>: &#123;</span><br><span class="line">            <span class="string">'handlers'</span>: [<span class="string">'console'</span>],</span><br><span class="line">            <span class="string">'level'</span>: <span class="string">'DEBUG'</span>,</span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="string">'FileLogger'</span>: &#123;</span><br><span class="line">            <span class="comment"># 既有 console Handler，还有 file Handler</span></span><br><span class="line">            <span class="string">'handlers'</span>: [<span class="string">'console'</span>, <span class="string">'file'</span>],</span><br><span class="line">            <span class="string">'level'</span>: <span class="string">'DEBUG'</span>,</span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="comment"># 其他的 Logger</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">logging.config.dictConfig(config)</span><br><span class="line">StreamLogger = logging.getLogger(<span class="string">"StreamLogger"</span>)</span><br><span class="line">FileLogger = logging.getLogger(<span class="string">"FileLogger"</span>)</span><br><span class="line"><span class="comment"># 省略日志输出</span></span><br></pre></td></tr></table></figure><p>因此我们也可以从配置文件中获取配置信息。常见的配置文件有 ini 格式、yaml 格式、JSON 格式，或者从网络中获取都是可以的，只要有相应的文件解析器解析配置即可，下面只展示了 ini 格式和 yaml 格式的配置。</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">[loggers]</span></span><br><span class="line"><span class="attr">keys</span>=root,sampleLogger</span><br><span class="line"></span><br><span class="line"><span class="section">[handlers]</span></span><br><span class="line"><span class="attr">keys</span>=consoleHandler</span><br><span class="line"></span><br><span class="line"><span class="section">[formatters]</span></span><br><span class="line"><span class="attr">keys</span>=sampleFormatter</span><br><span class="line"></span><br><span class="line"><span class="section">[logger_root]</span></span><br><span class="line"><span class="attr">level</span>=DEBUG</span><br><span class="line"><span class="attr">handlers</span>=consoleHandler</span><br><span class="line"></span><br><span class="line"><span class="section">[logger_sampleLogger]</span></span><br><span class="line"><span class="attr">level</span>=DEBUG</span><br><span class="line"><span class="attr">handlers</span>=consoleHandler</span><br><span class="line"><span class="attr">qualname</span>=sampleLogger</span><br><span class="line"><span class="attr">propagate</span>=<span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="section">[handler_consoleHandler]</span></span><br><span class="line"><span class="attr">class</span>=StreamHandler</span><br><span class="line"><span class="attr">level</span>=DEBUG</span><br><span class="line"><span class="attr">formatter</span>=sampleFormatter</span><br><span class="line"><span class="attr">args</span>=(sys.stdout,)</span><br><span class="line"></span><br><span class="line"><span class="section">[formatter_sampleFormatter]</span></span><br><span class="line"><span class="attr">format</span>=%(asctime)s - %(name)s - %(levelname)s - %(message)s</span><br></pre></td></tr></table></figure><p>因为默认有 ini 的解析器，所以我们不需要额外操作就可以直接解析上述 test.ini 文件的配置信息来初始化 logger：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> logging.config</span><br><span class="line"></span><br><span class="line">logging.config.fileConfig(fname=<span class="string">'test.ini'</span>, disable_existing_loggers=<span class="literal">False</span>)</span><br><span class="line">logger = logging.getLogger(<span class="string">"sampleLogger"</span>)</span><br></pre></td></tr></table></figure><p>也可以使用 yaml 文件作为配置文件格式：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">version:</span> <span class="number">1</span></span><br><span class="line"><span class="attr">formatters:</span></span><br><span class="line"><span class="attr">  simple:</span></span><br><span class="line"><span class="attr">    format:</span> <span class="string">'%(asctime)s - %(name)s - %(levelname)s - %(message)s'</span></span><br><span class="line"><span class="attr">handlers:</span></span><br><span class="line"><span class="attr">  console:</span></span><br><span class="line"><span class="attr">    class:</span> <span class="string">logging.StreamHandler</span></span><br><span class="line"><span class="attr">    level:</span> <span class="string">DEBUG</span></span><br><span class="line"><span class="attr">    formatter:</span> <span class="string">simple</span></span><br><span class="line">  </span><br><span class="line"><span class="attr">loggers:</span></span><br><span class="line"><span class="attr">  simpleExample:</span></span><br><span class="line"><span class="attr">    level:</span> <span class="string">DEBUG</span></span><br><span class="line"><span class="attr">    handlers:</span> <span class="string">[console]</span></span><br><span class="line"><span class="attr">    propagate:</span> <span class="literal">no</span></span><br><span class="line"><span class="attr">root:</span></span><br><span class="line"><span class="attr">  level:</span> <span class="string">DEBUG</span></span><br><span class="line"><span class="attr">  handlers:</span> <span class="string">[console]</span></span><br></pre></td></tr></table></figure><p>因为默认不是 yaml 解析器，因此需要安装额外的 yaml 解析器，将文件解析为字典传入：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> logging.config</span><br><span class="line"><span class="comment"># 需要安装 pyymal 库</span></span><br><span class="line"><span class="keyword">import</span> yaml</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> open(<span class="string">'test.yaml'</span>, <span class="string">'r'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    config = yaml.safe_load(f.read())</span><br><span class="line">    logging.config.dictConfig(config)</span><br><span class="line"></span><br><span class="line">logger = logging.getLogger(<span class="string">"sampleLogger"</span>)</span><br><span class="line"><span class="comment"># 省略日志输出</span></span><br></pre></td></tr></table></figure><h3 id="实战问题"><a href="#实战问题" class="headerlink" title="实战问题"></a>实战问题</h3><h4 id="中文乱码"><a href="#中文乱码" class="headerlink" title="中文乱码"></a>中文乱码</h4><p>上面的例子中日志输出都是英文内容，发现不了将日志输出到文件中会有中文乱码的问题，如何解决到这个问题呢？FileHandler 创建对象时可以设置文件编码，如果将文件编码设置为 “utf-8”（utf-8 和 utf8 等价），就可以解决中文乱码问题啦。一种方法是自定义 Logger 对象，需要写很多配置，另一种方法是使用默认配置方法 basicConfig()，传入 handlers 处理器列表对象，在其中的 handler 设置文件的编码。网上很多都是无效的方法，关键参考代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 自定义 Logger 配置</span></span><br><span class="line">handler = logging.FileHandler(filename=<span class="string">"test.log"</span>, encoding=<span class="string">"utf-8"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用默认的 Logger 配置</span></span><br><span class="line">logging.basicConfig(handlers=[logging.FileHandler(<span class="string">"test.log"</span>, encoding=<span class="string">"utf-8"</span>)], level=logging.DEBUG)</span><br></pre></td></tr></table></figure><h4 id="临时禁用日志输出"><a href="#临时禁用日志输出" class="headerlink" title="临时禁用日志输出"></a>临时禁用日志输出</h4><p>有时候我们又不想让日志输出，但在这后又想输出日志。如果我们打印信息用的是 <code>print()</code> 方法，那么就需要把所有的 <code>print()</code> 方法都注释掉，而使用了 logging 后，我们就有了一键开关闭日志的 “魔法”。一种方法是在使用默认配置时，给 <code>logging.disabled()</code> 方法传入禁用的日志级别，就可以禁止设置级别以下的日志输出了，另一种方法时在自定义 Logger 时，Logger 对象的 <code>disable</code> 属性设为 <code>True</code>（默认值是 <code>False</code>，也即不禁用）。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">logging.disable(logging.INFO)</span><br><span class="line"></span><br><span class="line">logger.disabled = <span class="literal">True</span></span><br></pre></td></tr></table></figure><h4 id="日志文件按照时间划分或者按照大小划分"><a href="#日志文件按照时间划分或者按照大小划分" class="headerlink" title="日志文件按照时间划分或者按照大小划分"></a>日志文件按照时间划分或者按照大小划分</h4><p>如果将日志保存在一个文件中，那么时间一长，或者日志一多，单个日志文件就会很大，既不利于备份，也不利于查看。我们会想到能不能按照时间或者大小对日志文件进行划分呢？答案肯定是可以的，并且还很简单，logging 考虑到了我们这个需求。logging.handlers 文件中提供了 <code>TimedRotatingFileHandler</code> 和 <code>RotatingFileHandler</code> 类分别可以实现按时间和大小划分。打开这个 handles 文件，可以看到还有其他功能的 Handler 类，它们都继承自基类 <code>BaseRotatingHandler</code>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># TimedRotatingFileHandler 类构造函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, filename, when=<span class="string">'h'</span>, interval=<span class="number">1</span>, backupCount=<span class="number">0</span>, encoding=None, delay=False, utc=False, atTime=None)</span>:</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># RotatingFileHandler 类的构造函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, filename, mode=<span class="string">'a'</span>, maxBytes=<span class="number">0</span>, backupCount=<span class="number">0</span>, encoding=None, delay=False)</span></span></span><br></pre></td></tr></table></figure><p>使用示例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 每隔 1000 Byte 划分一个日志文件，备份文件为 3 个</span></span><br><span class="line">file_handler = logging.handlers.RotatingFileHandler(<span class="string">"test.log"</span>, mode=<span class="string">"w"</span>, maxBytes=<span class="number">1000</span>, backupCount=<span class="number">3</span>, encoding=<span class="string">"utf-8"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 每隔 1小时 划分一个日志文件，interval 是时间间隔，备份文件为 10 个</span></span><br><span class="line">handler2 = logging.handlers.TimedRotatingFileHandler(<span class="string">"test.log"</span>, when=<span class="string">"H"</span>, interval=<span class="number">1</span>, backupCount=<span class="number">10</span>)</span><br></pre></td></tr></table></figure><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>logging 作为 Python 标准日志库，灵活并且强大，但是实际使用中也需要注意一些配置，对此我觉得需要深入理解 logging 的整个流程，才能达到随心所欲的掌握这个强大的工具。</p><h4 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h4><ul><li><a href="https://cloud.tencent.com/developer/article/1354396" target="_blank" rel="noopener">https://cloud.tencent.com/developer/article/1354396</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;标准日志库 logging 即使不是 Python 中最好的日志库，也是使用最多的日志库了，我个人非常喜欢。本文较为全面的总结了 logging 库的知识点。&lt;/p&gt;
    
    </summary>
    
      <category term="Python" scheme="https://murphypei.github.io/categories/Python/"/>
    
    
      <category term="python" scheme="https://murphypei.github.io/tags/python/"/>
    
      <category term="logging" scheme="https://murphypei.github.io/tags/logging/"/>
    
      <category term="handler" scheme="https://murphypei.github.io/tags/handler/"/>
    
      <category term="logger" scheme="https://murphypei.github.io/tags/logger/"/>
    
  </entry>
  
  <entry>
    <title>TensorRT 实战教程</title>
    <link href="https://murphypei.github.io//blog/2019/09/trt-useage.html"/>
    <id>https://murphypei.github.io//blog/2019/09/trt-useage.html</id>
    <published>2019-09-09T07:39:03.000Z</published>
    <updated>2019-10-21T12:02:21.349Z</updated>
    
    <content type="html"><![CDATA[<p>TensorRT(TRT) 作为一种能显著加快深度学习模型 inference 的工具，如果能够较好的利用，可以显著提高我们的 GPU 使用效率和模型运行速度。</p><a id="more"></a><p>TensorRT(TRT) 作为一种快速的 GPU 推理框架，其常规流程就是利用现有的模型文件编译一个 engine，在编译 engine 的过程中，会为每一层的计算操作找寻最优的算子方法，这样编译好的 engine 执行起来就非常高效。很类似 C++ 编译过程。</p><p>关于 TRT 的相关资料，我觉得还是以 NV 官方的为准。对于 TRT 而言，其在推理上的速度优势肯定是不言而喻的，它有多好，有多快，适不适合你的业务场景，这个需要大家自行判断。而其大概流程和一些基本优化，NV 官方的资料也做出了说明，可以参考这票文章 <a href="https://devblogs.nvidia.com/deploying-deep-learning-nvidia-tensorrt/" target="_blank" rel="noopener">deploying-deep-learning-nvidia-tensorrt</a> 。想快速了解 TRT 以及安装过程，也可以参考 <a href="https://arleyzhang.github.io/articles/7f4b25ce/" target="_blank" rel="noopener">TensorRT-介绍-使用-安装</a></p><p>本文根据自身实际使用过程中的记录而来，使用了 TRT 的 C++ 接口，更加注重编码的流程，配合讲解 TRT 的一些知识点，作为使用的总结。</p><h3 id="构建模型-和-engine"><a href="#构建模型-和-engine" class="headerlink" title="构建模型 和 engine"></a>构建模型 和 engine</h3><p>TRT 将模型结构和参数以及相应 kernel 计算方法都编译成一个二进制 engine，因此在部署之后大大加快了推理速度。为了能够使用 TRT 进行推理，需要创建一个 eninge。TRT 中 engine 的创建有两种方式：</p><ul><li>通过网络模型结构和参数文件编译得到，很慢。</li><li>读取一个已有的 engine（gie 文件），因为跳过了模型解析等过程，速度更快。</li></ul><p>第一种方式很慢，但是在第一次部署某个模型，或者修改模型的精度、输入数据类型、网络结构等等，只要修改了模型，就必须重新编译（其实 TRT 还有一种可以重新加载参数的方式，不是本文所涉及的）。</p><p>现在假设我们是第一次用 TRT，所以就只能选择第一种方式来创建一个 engine。为了创建一个 engine，我们需要有模型结构和模型参数两个文件，同时需要能够解析这两个文件的方法。在 TRT 中，编译 engine 是通过 <code>IBuilder</code> 对象进行的，因此我们首先需要新键一个 <code>IBuilder</code> 对象：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nvinfer1::IBuilder *builder = createInferBuilder(gLogger);</span><br></pre></td></tr></table></figure><blockquote><p><code>gLogger</code> 是 TRT 中的日志接口 <code>ILogger</code> ，继承这个接口并创建自己的 logger 对象传入即可。</p></blockquote><p>为了编译一个 engine，<code>builder</code> 首先需要创建一个 <code>INetworkDefinition</code> 作为模型的容器：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nvinfer1::INetworkDefinition *network = builder-&gt;createNetwork();</span><br></pre></td></tr></table></figure><p>注意，<strong>此时 <code>network</code> 是空的</strong>，我们需要填充模型结构和参数，也就是解析我们自己的模型结构和参数文件，获取数据放到其中。</p><p>TRT 官方给了三种主流框架模型格式的解析器（parser），分别是：</p><ul><li>ONNX：<code>IOnnxParser parser = nvonnxparser::createParser(*network, gLogger);</code></li><li>Caffe：<code>ICaffeParser parser = nvcaffeparser1::createCaffeParser();</code></li><li>UFF：<code>IUffParser parser = nvuffparser::createUffParser();</code></li></ul><p>其中 UFF 是用于 TensorFlow 的格式。调用这三种解析器就可以解析相应的文件。以 <code>ICaffeParser</code> 为例，调用其 <code>parse</code> 方法来填充 <code>network</code>。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">virtual</span> <span class="keyword">const</span> IBlobNameToTensor* nvcaffeparser1::ICaffeParser::parse(</span><br><span class="line">    <span class="keyword">const</span> <span class="keyword">char</span>* deploy, </span><br><span class="line">    <span class="keyword">const</span> <span class="keyword">char</span> * model, </span><br><span class="line">nvinfer1::INetworkDefinition &amp;network, </span><br><span class="line">nvinfer1::DataType weightType)</span><br><span class="line"></span><br><span class="line"><span class="comment">//Parameters</span></span><br><span class="line"><span class="comment">//deploy    The plain text, prototxt file used to define the network configuration.</span></span><br><span class="line"><span class="comment">//model        The binaryproto Caffe model that contains the weights associated with the network.</span></span><br><span class="line"><span class="comment">//network    Network in which the CaffeParser will fill the layers.</span></span><br><span class="line"><span class="comment">//weightType    The type to which the weights will transformed.</span></span><br></pre></td></tr></table></figure><p>这样就能得到一个填充好的 <code>network</code> ，就可以编译 engine 了，似乎一切都很美妙呢…</p><p>然而实际 TRT 并不完善，比如 TensorFlow 的很多操作并不支持，因此你传入的文件往往是根本就解析不了（深度学习框架最常见的困境之一）。因此我们需要自己去做填充 <code>network</code> 这件事，这就需要调用 TRT 中低级别的接口来创建模型结构，类似于你在 Caffe 或者 TensorFlow 中做的那样。</p><p>TRT 提供了较为丰富的接口让你可以直接通过这些接口创建自己的网络，比如添加一个卷积层：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">virtual</span> IConvolutionLayer* nvinfer1::INetworkDefinition::addConvolution(ITensor &amp;input, </span><br><span class="line">                                                                        <span class="keyword">int</span> nbOutputMaps,</span><br><span class="line">                                                                        DimsHW kernelSize,</span><br><span class="line">                                                                        Weights kernelWeights,</span><br><span class="line">                                                                        Weights biasWeights)</span><br><span class="line"></span><br><span class="line"><span class="comment">// Parameters</span></span><br><span class="line"><span class="comment">// inputThe input tensor to the convolution.</span></span><br><span class="line"><span class="comment">// nbOutputMapsThe number of output feature maps for the convolution.</span></span><br><span class="line"><span class="comment">// kernelSizeThe HW-dimensions of the convolution kernel.</span></span><br><span class="line"><span class="comment">// kernelWeightsThe kernel weights for the convolution.</span></span><br><span class="line"><span class="comment">// biasWeightsThe optional bias weights for the convolution.</span></span><br></pre></td></tr></table></figure><p>这里的参数基本上就是和其他深度学习框架类似的意思，没有什么好讲的。就是把数据封装成 TRT 中的数据结构即可。可能和平时构建训练网络不同的地方就是需要填充好模型的参数，因为 TRT 是推理框架，参数是已知确定的。这个过程一般是读取已经训练好的模型，构造 TRT 的数据结构类型放到其中，也就是需要你自己去解析模型参数文件。</p><p>之所以说 TRT 的网络构造接口是<strong>较为丰富</strong>，是因为即使使用这些低级接口这样，很多操作还是没办法完成，也就是没有相应的 <code>add*</code> 方法，更何况现实业务可能还会涉及很多自定义的功能层，因此 TRT 又有了 plugin 接口，允许你自己定义一个 <code>add*</code> 的操作。其流程就是继承 <code>nvinfer1::IPluginV2</code> 接口，利用 cuda 编写一个自定义层的功能，然后继承 <code>nvinfer1::IPluginCreator</code> 编写其创建类，需要重写其虚方法 <code>createPlugin</code>。最后调用 <code>REGISTER_TENSORRT_PLUGIN</code> 宏来注册这个 plugin 就可以用了。plugin 接口的成员函数介绍。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 获得该自定义层的输出个数，比如 leaky relu 层的输出个数为1</span></span><br><span class="line"><span class="function"><span class="keyword">virtual</span> <span class="keyword">int</span> <span class="title">getNbOutputs</span><span class="params">()</span> <span class="keyword">const</span> </span>= <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 得到输出 Tensor 的维数</span></span><br><span class="line"><span class="function"><span class="keyword">virtual</span> Dims <span class="title">getOutputDimensions</span><span class="params">(<span class="keyword">int</span> index, <span class="keyword">const</span> Dims* inputs, <span class="keyword">int</span> nbInputDims)</span> </span>= <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 配置该层的参数。该函数在 initialize() 函数之前被构造器调用。它为该层提供了一个机会，可以根据其权重、尺寸和最大批量大小来做出算法选择。</span></span><br><span class="line"><span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">configure</span><span class="params">(<span class="keyword">const</span> Dims* inputDims, <span class="keyword">int</span> nbInputs, <span class="keyword">const</span> Dims* outputDims, <span class="keyword">int</span> nbOutputs, <span class="keyword">int</span> maxBatchSize)</span> </span>= <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 对该层进行初始化，在 engine 创建时被调用。</span></span><br><span class="line"><span class="function"><span class="keyword">virtual</span> <span class="keyword">int</span> <span class="title">initialize</span><span class="params">()</span> </span>= <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 该函数在 engine 被摧毁时被调用</span></span><br><span class="line"><span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">terminate</span><span class="params">()</span> </span>= <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 获得该层所需的临时显存大小。</span></span><br><span class="line"><span class="function"><span class="keyword">virtual</span> size_t <span class="title">getWorkspaceSize</span><span class="params">(<span class="keyword">int</span> maxBatchSize)</span> <span class="keyword">const</span> </span>= <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 执行该层</span></span><br><span class="line"><span class="function"><span class="keyword">virtual</span> <span class="keyword">int</span> <span class="title">enqueue</span><span class="params">(<span class="keyword">int</span> batchSize, <span class="keyword">const</span> <span class="keyword">void</span>*<span class="keyword">const</span> * inputs, <span class="keyword">void</span>** outputs, <span class="keyword">void</span>* workspace, cudaStream_t stream)</span> </span>= <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 获得该层进行 serialization 操作所需要的内存大小</span></span><br><span class="line"><span class="function"><span class="keyword">virtual</span> size_t <span class="title">getSerializationSize</span><span class="params">()</span> </span>= <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 序列化该层，根据序列化大小 getSerializationSize()，将该类的参数和额外内存空间全都写入到系列化buffer中。</span></span><br><span class="line"><span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">serialize</span><span class="params">(<span class="keyword">void</span>* buffer)</span> </span>= <span class="number">0</span>;</span><br></pre></td></tr></table></figure><p>我们需要根据自己层的功能，重写这里全部或者部分函数的实现，这里有很多细节，没办法一一展开，需要自定义的时候还是需要看官方 API。</p><p>构建好了网络模型，就可以执行 engine 的编译了，还需要对 engine 进行一些设置。比如计算精度，支持的 batch size 等等，因为这些设置不同，编译出来的 engine 也不同。</p><p>TRT 支持 FP16 计算，也是官方推荐的计算精度，其设置也比简单，直接调用：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">builder-&gt;setFp16Mode(<span class="literal">true</span>);</span><br></pre></td></tr></table></figure><p>另外在设置精度的时候，还有一个设置 strict 策略的接口：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">builder-&gt;setStrictTypeConstraints(<span class="literal">true</span>);</span><br></pre></td></tr></table></figure><p>这个接口就是是否严格按照设置的精度进行类型转换，如果不设置 strict 策略，则 TRT 在某些计算中可能会选择更高精度（不影响性能）的计算类型。 </p><p>除了精度，还需要设置好运行的 batch size 和 workspace size：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">builder-&gt;setMaxBatchSize(batch_size);</span><br><span class="line">builder-&gt;setMaxWorkspaceSize(workspace_size);</span><br></pre></td></tr></table></figure><p>这里的 batch size 是运行时最大能够支持的 batch size，运行时可以选择比这个值小的 batch size，workspace 也是相对于这个最大 batch size 设置的。</p><p>设置好上述参数，就可以编译 engine 了。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nvinfer1::ICudaEngine *engine = builder-&gt;buildCudaEngine(*network);</span><br></pre></td></tr></table></figure><p>编译需要花较长时间，耐心等待。</p><h3 id="Engine-序列化和反序列化"><a href="#Engine-序列化和反序列化" class="headerlink" title="Engine 序列化和反序列化"></a>Engine 序列化和反序列化</h3><p>编译 engine 需要较长时间，在模型和计算精度、batch size 等均保持不变的情况下，我们可以选择保存 engine 到本地，供下次运行使用，也就是 engine 序列化。TRT 提供了很方便的序列化方法：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nvinfer1::IHostMemory *modelStream = engine-&gt;serialize();</span><br></pre></td></tr></table></figure><p>通过这个调用，得到的是一个二进制流，将这个流写入到一个文件中即可保存下来。</p><p>如果需要再次部署，可以直接反序列化保存好的文件，略过编译环节。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">IRuntime* runtime = createInferRuntime(gLogger);</span><br><span class="line">ICudaEngine* engine = runtime-&gt;deserializeCudaEngine(modelData, modelSize, <span class="literal">nullptr</span>);</span><br></pre></td></tr></table></figure><h3 id="使用-engine-进行预测"><a href="#使用-engine-进行预测" class="headerlink" title="使用 engine 进行预测"></a>使用 engine 进行预测</h3><p>有了 engine 之后就可以使用它进行 inference 了。</p><p>首先创建一个 inference 的 context。这个 context 类似命名空间，用于保存一个 inference 任务的变量。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">IExecutionContext *context = engine-&gt;createExecutionContext();</span><br></pre></td></tr></table></figure><p><strong>一个 engine 可以有多个 context</strong>，也就是说一个 engine 可以同时进行多个预测任务。</p><p>然后就是绑定输入和输出的 index。这一步的原因在于 TRT 在 build engine 的过程中，将输入和输出映射为索引编号序列，因此我们只能通过索引编号来获取输入和输出层的信息。虽然 TRT 提供了通过名字获取索引编号的接口，但是本地保存可以方便后续操作。</p><p>我们可以先获取索引编号的数量：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> index_number = engine-&gt;getNbBindings();</span><br></pre></td></tr></table></figure><p>我们可以判断这个编号数量是不是和我们网络的输入输出之和相同，比如你有一个输入和一个输出，那么编号的数量就是2。如果不是，则说明这个 engine 是有问题的；如果没问题，我们就可以通过名字获取输入输出对应的序号：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> input_index = engine-&gt;getBindingIndex(input_layer_name);</span><br><span class="line"><span class="keyword">int</span> output_index = engine-&gt;getBindingIndex(output_layer_name);</span><br></pre></td></tr></table></figure><p>对于常见的一个输入和输出的网络，输入的索引编号就是 0，输出的索引编号就是 1，所以这一步也不是必须的。</p><p>接下来就需要为输入和输出层分配显存空间了。为了分配显存空间，我们需要知道输入输出的维度信息和存放的数据类型，TRT 中维度信息和数据类型的表示如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Dims</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="keyword">static</span> <span class="keyword">const</span> <span class="keyword">int</span> MAX_DIMS = <span class="number">8</span>; <span class="comment">//!&lt; The maximum number of dimensions supported for a tensor.</span></span><br><span class="line">    <span class="keyword">int</span> nbDims;                    <span class="comment">//!&lt; The number of dimensions.</span></span><br><span class="line">    <span class="keyword">int</span> d[MAX_DIMS];               <span class="comment">//!&lt; The extent of each dimension.</span></span><br><span class="line">    DimensionType type[MAX_DIMS];  <span class="comment">//!&lt; The type of each dimension.</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">enum</span> <span class="class"><span class="keyword">class</span> <span class="title">DataType</span> :</span> <span class="keyword">int</span></span><br><span class="line">&#123;</span><br><span class="line">    kFLOAT = <span class="number">0</span>, <span class="comment">//!&lt; FP32 format.</span></span><br><span class="line">    kHALF = <span class="number">1</span>,  <span class="comment">//!&lt; FP16 format.</span></span><br><span class="line">    kINT8 = <span class="number">2</span>,  <span class="comment">//!&lt; quantized INT8 format.</span></span><br><span class="line">    kINT32 = <span class="number">3</span>  <span class="comment">//!&lt; INT32 format.</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>我们通过索引编号获取输入和输出的数据维度（dims）和数据类型（dtype），然后为每个输出层开辟显存空间，存放输出结果：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; index_number; ++i)</span><br><span class="line">&#123;</span><br><span class="line">nvinfer1::Dims dims = engine-&gt;getBindingDimensions(i);</span><br><span class="line">nvinfer1::DataType dtype = engine-&gt;getBindingDataType(i);</span><br><span class="line">    <span class="comment">// 获取数据长度</span></span><br><span class="line">    <span class="keyword">auto</span> buff_len = <span class="built_in">std</span>::accumulate(dims.d, dims.d + dims.nbDims, <span class="number">1</span>, <span class="built_in">std</span>::multiplies&lt;<span class="keyword">int64_t</span>&gt;());</span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">    <span class="comment">// 获取数据类型大小</span></span><br><span class="line">    dtype_size = getTypeSize(dtype);<span class="comment">// 自定义函数</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 为 output 分配显存空间</span></span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">auto</span> &amp;output_i : outputs)</span><br><span class="line">&#123;</span><br><span class="line">    cudaMalloc(buffer_len_i * dtype_size_i * batch_size);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>本文给出的是伪代码，仅表示逻辑，因此会涉及一些简单的自定义函数。</p></blockquote><p>至此，我们已经做好了准备工作，现在就可以把数据塞进模型进行推理了。</p><h4 id="前向预测"><a href="#前向预测" class="headerlink" title="前向预测"></a>前向预测</h4><p>TRT 的前向预测执行是异步的，context 通过一个 enqueue 调用来提交任务：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cudaStream_t stream;</span><br><span class="line">cudaStreamCreate(&amp;stream);</span><br><span class="line">context-&gt;enqueue(batch_size, buffers, stream, <span class="literal">nullptr</span>);</span><br><span class="line">cudaStreamSynchronize(stream);</span><br></pre></td></tr></table></figure><p>enqueue 是 TRT 的实际执行任务的函数，我们在写 plugin 的时候也需要实现这个函数接口。其中：</p><ul><li><p><code>batch_size</code>：engine 在 build 过程中传入的 <code>max_batch_size</code>。</p></li><li><p><code>buffers</code>：是一个指针数组，其下标对应的就是输入输出层的索引编号，存放的就是输入的数据指针以及输出的数据存放地址（也就是开辟的显存地址）。</p></li><li><p><code>stream</code>：stream 是 cuda 一系列顺序操作的概念。对于我们的模型来说就是将所有的模型操作按照（网络结构）指定的顺序在指定的设备上执行。</p><blockquote><p>cuda stream 是指一堆异步的 cuda 操作，他们按照 host 代码调用的顺序执行在 device 上。stream 维护了这些操作的顺序，并在所有预处理完成后允许这些操作进入工作队列，同时也可以对这些操作进行一些查询操作。这些操作包括 host 到 device 的数据传输，launch kernel 以及其他的 host 发起由 device 执行的动作。这些操作的执行总是异步的，cuda runtime 会决定这些操作合适的执行时机。我们则可以使用相应的cuda api 来保证所取得结果是在所有操作完成后获得的。<strong>同一个 stream 里的操作有严格的执行顺序</strong>，不同的 stream 则没有此限制。</p></blockquote></li></ul><p>这里需要注意，输入数据和输出数据在 buffers 数组中都是在 GPU 上的，可以通过 <code>cudaMemcpy</code> 拷贝 CPU 上的输入数据到 GPU 中（需要提前开辟一块显存来存放）。同理，输出数据也需要从 GPU 中拷贝到 CPU 中。</p><p>前两句创建了一个 cuda stream，最后一句则是等待这个异步 stream 执行完毕，然后从显存中将数据拷贝出来即可。</p><p>至此，我们就完成了 TRT 一个基本的预测流程。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>本文仅仅是针对 TRT 的预测流程和一些常见调用进行了说明，并不涉及具体网络和具体实现，也没有太多编码的细节。不同网络不同操作需要一些扩展 plugin 的编写，而对于编码，包括内存和显存的开辟管理，TRT 的析构清理工作等等都不在本文叙述范围之内。</p><h4 id="参考资料："><a href="#参考资料：" class="headerlink" title="参考资料："></a>参考资料：</h4><ul><li><a href="https://docs.nvidia.com/deeplearning/sdk/tensorrt-developer-guide/index.html#c_topics" target="_blank" rel="noopener">https://docs.nvidia.com/deeplearning/sdk/tensorrt-developer-guide/index.html#c_topics</a></li><li><a href="https://docs.nvidia.com/deeplearning/sdk/tensorrt-api/c_api/index.html" target="_blank" rel="noopener">https://docs.nvidia.com/deeplearning/sdk/tensorrt-api/c_api/index.html</a></li><li><a href="https://www.cnblogs.com/1024incn/p/5891051.html" target="_blank" rel="noopener">https://www.cnblogs.com/1024incn/p/5891051.html</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;TensorRT(TRT) 作为一种能显著加快深度学习模型 inference 的工具，如果能够较好的利用，可以显著提高我们的 GPU 使用效率和模型运行速度。&lt;/p&gt;
    
    </summary>
    
      <category term="深度学习" scheme="https://murphypei.github.io/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="tensorflow" scheme="https://murphypei.github.io/tags/tensorflow/"/>
    
      <category term="cuda" scheme="https://murphypei.github.io/tags/cuda/"/>
    
      <category term="c++" scheme="https://murphypei.github.io/tags/c/"/>
    
      <category term="TensorRT" scheme="https://murphypei.github.io/tags/TensorRT/"/>
    
      <category term="trt" scheme="https://murphypei.github.io/tags/trt/"/>
    
      <category term="caffe" scheme="https://murphypei.github.io/tags/caffe/"/>
    
  </entry>
  
  <entry>
    <title>win10 虚拟机黑屏卡死</title>
    <link href="https://murphypei.github.io//blog/2019/08/vm-black-screen.html"/>
    <id>https://murphypei.github.io//blog/2019/08/vm-black-screen.html</id>
    <published>2019-08-31T07:07:38.000Z</published>
    <updated>2019-10-21T12:02:19.633Z</updated>
    
    <content type="html"><![CDATA[<p>在 windows10 上面装好 virtualbox 虚拟机之后卡死黑屏，开不了机。</p><a id="more"></a><p>我以为是系统不兼容问题，搞了很多试验，换不同的虚拟机系统，不同版本的 virtualbox，检查 bios 中的 VT/X，都解决不了问题，<strong>还没有任何提示</strong>。最后我安装了 vmware pro，加载系统盘的时候提示：<strong>VMware Workstation 与 Device/Credential Guard 不兼容</strong>，一查原来是不知道什么时候开启了 win10 的内核保护隔离，虚拟机运行需要关闭。</p><p>官方给的方法比较麻烦，知乎上面有一个比较简单的方法：</p><ul><li>关闭</li></ul><p><code>bcdedit /set hypervisorlaunchtype off</code></p><ul><li>开启</li></ul><p><code>bcdedit /set hypervisorlaunchtype auto</code></p><p>亲测有效解决。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在 windows10 上面装好 virtualbox 虚拟机之后卡死黑屏，开不了机。&lt;/p&gt;
    
    </summary>
    
      <category term="Windows" scheme="https://murphypei.github.io/categories/Windows/"/>
    
    
      <category term="Windows" scheme="https://murphypei.github.io/tags/Windows/"/>
    
      <category term="vm" scheme="https://murphypei.github.io/tags/vm/"/>
    
      <category term="vmware" scheme="https://murphypei.github.io/tags/vmware/"/>
    
      <category term="virtualbox" scheme="https://murphypei.github.io/tags/virtualbox/"/>
    
  </entry>
  
  <entry>
    <title>Socket 读写就绪条件</title>
    <link href="https://murphypei.github.io//blog/2019/08/socket-ready.html"/>
    <id>https://murphypei.github.io//blog/2019/08/socket-ready.html</id>
    <published>2019-08-27T07:07:38.000Z</published>
    <updated>2019-10-21T12:02:17.785Z</updated>
    
    <content type="html"><![CDATA[<p>关于 Socket 的读写就绪条件。</p><a id="more"></a><p>我们知道 Socket 读写都是有缓冲区，而且读写时阻塞的，因此通常用 I/O 多路复用来监听多个 Socket 的就绪。这个就绪是十分有意思的，内核是如何得知某个 Socket 就绪了呢？引用《Unix网络编程》中的解释：</p><p>当满足下列条件之一时，一个套接字准备好读：</p><ul><li>该套接字接收缓冲区中的数据字节数大于等于套接字接收缓冲区低水位标记的当前大小。对这样的套接字执行读操作不会阻塞并将返回一个大于 0 的值（也就是返回准备好读入的数据）。我们可以使用 <code>SO_RCVLOWAT</code> 套接字选项设置该套接字的低水位标记。对于 TCP 和 UDP 套接字而言，其默认值为 1。</li><li>该连接的读半部关闭（也就是接收了 FIN 的 TCP 连接）。对这样的套接字的读操作将不阻塞并返回 0 （也就是返回 EOF）。</li><li>该套接字是一个监听套接字且已完成的连接数不为 0。对这样的套接字的 accept 通常不会阻塞。</li><li>其上有一个套接字错误待处理。对这样的套接字的读操作将不阻塞并返回 -1（也就是返回一个错误），同时把 <code>errno</code> 设置成确切的错误条件。这些待处理错误也可以通过指定 <code>SO_ERROR</code> 套接字选项调用 <code>getsockopt</code> 获取并清除。</li></ul><p>当满足下列条件之一时，一个套接字准备好写：</p><ul><li>该套接字发送缓冲区中的可用空间字节数大于等于套接字发送缓冲区低水位标记的当前大小，并且要求该套接字已连接（TCP）或者不需要连接（UDP）。这意味着如果我们把这样的套接字设置为非阻塞，写操作将不阻塞并返回一个正值（例如由传输层接收的字节数）。我们可以使用 <code>SO_SNDLOWAT</code> 套接字选项来设置该套接字的低水位标记。对于 TCP 和 UDP 套接字而言，其默认值通常为 2048。</li><li>该连接的写半部关闭，对这样的套接字的写操作将产生 <code>SIGPIPE</code> 信号。</li><li>使用非阻塞式 <code>connect</code> 的套接字已建立连接，或者已经以失败告终。</li><li>其上有一个套接字错误待处理。对这样的套接字的写操作将不阻塞并返回 -1（也就是返回一个错误），同时把 <code>errno</code> 设置成确切的错误条件。这些待处理的错误也可以通过指定 <code>SO_ERROR</code> 套接字选项调用 <code>getsockopt</code> 获取并清除。</li></ul><p>另外，如果一个套接字存在带外数据或者仍处于带外标记，那么它有异常条件待处理。从上面可以看出，如果一个套接字发生错误，那么它是可读可写条件。</p><p>可以看出，读写就绪条件一般情况（非异常）都是内核通过判断缓冲区中是否有数据。因为网络上数据的到来是随时的，因此当缓冲区中有网络的数据（大于 1），说明可读。而写数据则将数据积攒起来，大于低水位或者发送方主动关闭了连接，才会通过网络发送出去。</p><p>除了上述条件，缓冲区的读写在满和空的时候也会引起阻塞，下面以管理为例说明。</p><p>假设有一个管道，进程 A 为管道的写入方，B 为管道的读出方。</p><p>假设一开始内核缓冲区是空的，B 作为读出方，被阻塞着。然后首先 A 往管道写入，这时候内核缓冲区由空的状态变到非空状态，内核就会产生一个事件告诉 B 该醒来了（也就是我们上面说的套接字准备好读），这个事件姑且称之为“缓冲区非空”。</p><p>但是“缓冲区非空”事件通知 B 后，B 却还没有读出数据；且内核许诺了不能把写入管道中的数据丢掉这个时候，A 写入的数据会滞留在内核缓冲区中，如果内核也缓冲区满了，B 仍未开始读数据，最终内核缓冲区会被填满，这个时候会产生一个 I/O 事件，告诉进程 A，你该等等（阻塞）了，我们把这个事件定义为“缓冲区满”。可见，缓冲区满也会引起阻塞。</p><p>假设后来 B 终于开始读数据了，于是内核的缓冲区空了出来，这时候内核会告诉 A，内核缓冲区有空位了，你可以从长眠中醒来了，继续写数据了，我们把这个事件叫做“缓冲区非满”。也许事件 Y1 已经通知了 A，但是 A 也没有数据写入了，而 B 继续读出数据，知道内核缓冲区空了。这个时候内核就告诉 B，你需要阻塞了！我们把这个时间定为“缓冲区空”。因此，缓冲区空也会引起阻塞。</p><p>以上四个情形涵盖了四个 I/O 事件，缓冲区满，缓冲区空，缓冲区非空，缓冲区非满（说的内核缓冲区）。这四个 I/O 事件是进行阻塞同步的根本。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;关于 Socket 的读写就绪条件。&lt;/p&gt;
    
    </summary>
    
      <category term="Linux" scheme="https://murphypei.github.io/categories/Linux/"/>
    
    
      <category term="Linux" scheme="https://murphypei.github.io/tags/Linux/"/>
    
      <category term="socket" scheme="https://murphypei.github.io/tags/socket/"/>
    
      <category term="read" scheme="https://murphypei.github.io/tags/read/"/>
    
      <category term="write" scheme="https://murphypei.github.io/tags/write/"/>
    
      <category term="unix" scheme="https://murphypei.github.io/tags/unix/"/>
    
  </entry>
  
  <entry>
    <title>僵尸进程和孤儿进程总结</title>
    <link href="https://murphypei.github.io//blog/2019/08/zombie-orphan-process.html"/>
    <id>https://murphypei.github.io//blog/2019/08/zombie-orphan-process.html</id>
    <published>2019-08-26T12:03:07.000Z</published>
    <updated>2019-08-27T09:15:25.523Z</updated>
    
    <content type="html"><![CDATA[<p>最近看到一个进程状态的博客写的比较好，转载记录复习，顺便加点自己的理解注释，形成了这篇文章。</p><a id="more"></a><h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>之前在看《unix环境高级编程》第八章进程时候，提到孤儿进程和僵尸进程，一直对这两个概念比较模糊。今天被人问到什么是孤儿进程和僵尸进程，会带来什么问题，怎么解决，我只停留在概念上面，没有深入，倍感惭愧。晚上回来 google了一下，再次参考 APUE，认真总结一下，加深理解。</p><h3 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h3><p>我们知道在 unix/linux 中，正常情况下，子进程是通过父进程创建的，子进程在创建新的进程。子进程的结束和父进程的运行是一个异步过程,即父进程永远无法预测子进程到底什么时候结束。 当一个 进程完成它的工作终止之后，它的父进程需要调用 <code>wait()</code> 或者 <code>waitpid()</code> 系统调用取得子进程的终止状态。</p><p><strong>孤儿进程</strong>：一个父进程退出，而它的一个或多个子进程还在运行，那么那些子进程将成为孤儿进程。孤儿进程将被 init 进程（进程号为 1）所收养，并由 init 进程对它们完成状态收集工作。</p><p><strong>僵尸进程</strong>：一个进程使用 <code>fork()</code> 创建子进程，如果子进程退出，而父进程并没有调用  <code>wait()</code> 或者 <code>waitpid()</code>  获取子进程的状态信息，那么子进程的<strong>进程描述符仍然保存在系统中</strong>。这种进程称之为僵尸进程。</p><p>这里注意概念的区分，僵尸进程是无效的、不再运行的。</p><h3 id="问题及危害"><a href="#问题及危害" class="headerlink" title="问题及危害"></a>问题及危害</h3><p>unix 提供了一种机制可以保证只要父进程想知道子进程结束时的状态信息，就可以得到。这种机制就是：在每个进程退出的时候，内核释放该进程所有的资源，包括打开的文件，占用的内存等。但是仍然为其保留一定的信息（包括进程号，退出状态，运行时间等)。直到父进程通过 <code>wait</code> / <code>waitpid</code> 来取时才释放。 但这样就导致了问题，<strong>如果进程不调用 <code>wait</code> / <code>waitpid</code> 的话，那么保留的那段信息就不会释放，其进程号就会一直被占用，但是系统所能使用的进程号是有限的，如果大量的产生僵死进程，将因为没有可用的进程号而导致系统不能产生新的进程。此即为僵尸进程的危害，应当避免。</strong></p><blockquote><p>需要牢记的事，僵尸进程的产生是由于父进程没有调用  <code>wait</code> / <code>waitpid</code> 。</p></blockquote><p><strong>孤儿进程是没有父进程的进程，孤儿进程这个重任就落到了init进程身上</strong>，init 进程就好像是一个民政局，专门负责处理孤儿进程的善后工作。每当出现一个孤儿进程的时候，内核就把孤儿进程的父进程设置为 init，而 init 进程会循环地 <code>wait()</code> 它的已经退出的子进程。这样，当一个孤儿进程凄凉地结束了其生命周期的时候，init 进程就会代表党和政府出面处理它的一切善后工作。<strong>因此孤儿进程并不会有什么危害。</strong></p><p><strong>任何一个子进程（<code>init</code> 除外）在 <code>exit()</code> 之后，并非马上就消失掉，而是留下一个称为僵尸进程（Zombie）的数据结构，等待父进程处理。</strong>这是每个子进程在结束时都要经过的阶段。如果子进程在 <code>exit()</code> 之后，父进程没有来得及处理，这时用 <code>ps</code> 命令就能看到子进程的状态是 <code>Z</code>。如果父进程能及时处理，可能用 <code>ps</code> 命令就来不及看到子进程的僵尸状态，但这并不等于子进程不经过僵尸状态。  <strong>如果父进程在子进程结束之前退出</strong>，则子进程将由 init 接管。init 将会以父进程的身份对僵尸状态的子进程进行处理。</p><blockquote><p>也就是说，如果一个子进程的父进程提前结束，则其变为一个孤儿进程被 init 接管，如果其执行完毕，就会变成僵尸状态，等 init 调用  <code>wait</code> / <code>waitpid</code> 才会释放它。因为 init 会周期调用 <code>wait()</code> ，所以孤儿进程不会变成僵尸进程。</p></blockquote><h4 id="僵尸进程危害场景"><a href="#僵尸进程危害场景" class="headerlink" title="僵尸进程危害场景"></a>僵尸进程危害场景</h4><p>例如有个进程，它定期的产 生一个子进程，这个子进程需要做的事情很少，做完它该做的事情之后就退出了，因此这个子进程的生命周期很短，但是，父进程只管生成新的子进程，至于子进程 退出之后的事情，则一概不闻不问，这样，系统运行上一段时间之后，系统中就会存在很多的僵死进程，倘若用 <code>ps</code> 命令查看的话，就会看到很多状态为 <code>Z</code> 的进程。 严格地来说，僵死进程并不是问题的根源，罪魁祸首是产生出大量僵死进程的那个父进程。因此，当我们寻求如何消灭系统中大量的僵死进程时，答案就是把产生大量僵死进程的那个元凶枪毙掉（也就是通过 <code>kill</code> 发送 <code>SIGTERM</code> 或者 <code>SIGKILL</code> 信号啦）。枪毙了元凶进程之后，它产生的僵死进程就变成了孤儿进 程，这些孤儿进程会被 init 进程接管，init 进程会 <code>wait()</code> 这些孤儿进程，释放它们占用的系统进程表中的资源，这样，这些已经僵死的孤儿进程就能瞑目而去了。</p><h3 id="代码测试"><a href="#代码测试" class="headerlink" title="代码测试"></a>代码测试</h3><p>孤儿进程测试：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;errno.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;unistd.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">pid_t</span> pid;</span><br><span class="line">    <span class="comment">//创建一个进程</span></span><br><span class="line">    pid = fork();</span><br><span class="line">    <span class="comment">//创建失败</span></span><br><span class="line">    <span class="keyword">if</span> (pid &lt; <span class="number">0</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        perror(<span class="string">"fork error:"</span>);</span><br><span class="line">        <span class="built_in">exit</span>(<span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//子进程</span></span><br><span class="line">    <span class="keyword">if</span> (pid == <span class="number">0</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"I am the child process.\n"</span>);</span><br><span class="line">        <span class="comment">//输出进程ID和父进程ID</span></span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"pid: %d\tppid:%d\n"</span>,getpid(),getppid());</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"I will sleep five seconds.\n"</span>);</span><br><span class="line">        <span class="comment">//睡眠5s，保证父进程先退出</span></span><br><span class="line">        sleep(<span class="number">5</span>);</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"pid: %d\tppid:%d\n"</span>,getpid(),getppid());</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"child process is exited.\n"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//父进程</span></span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"I am father process.\n"</span>);</span><br><span class="line">        <span class="comment">//父进程睡眠1s，保证子进程输出进程id</span></span><br><span class="line">        sleep(<span class="number">1</span>);</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"father process is  exited.\n"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>运行结果：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># g++ a.cpp -o a.out</span></span><br><span class="line"><span class="comment"># ./a.out</span></span><br><span class="line">I am father process.</span><br><span class="line">I am the child process.</span><br><span class="line">pid: 371        ppid:370</span><br><span class="line">I will sleep five seconds.</span><br><span class="line">father process is  exited.</span><br><span class="line">pid: 371        ppid:1</span><br><span class="line">child process is exited.</span><br></pre></td></tr></table></figure><p>可以看到，父进程退出之后，子进程被 init 接管了。</p><p>僵尸进程测试：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;unistd.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;errno.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">pid_t</span> pid;</span><br><span class="line">    pid = fork();</span><br><span class="line">    <span class="keyword">if</span> (pid &lt; <span class="number">0</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        perror(<span class="string">"fork error:"</span>);</span><br><span class="line">        <span class="built_in">exit</span>(<span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span> (pid == <span class="number">0</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"I am child process.I am exiting.\n"</span>);</span><br><span class="line">        <span class="built_in">exit</span>(<span class="number">0</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"I am father process.I will sleep two seconds\n"</span>);</span><br><span class="line">    <span class="comment">//等待子进程先退出</span></span><br><span class="line">    sleep(<span class="number">2</span>);</span><br><span class="line">    <span class="comment">//输出进程信息</span></span><br><span class="line">    system(<span class="string">"ps -o pid,ppid,state,tty,command"</span>);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"father process is exiting.\n"</span>);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>运行结果：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">I am father process.I will sleep two seconds</span><br><span class="line">I am child process.I am exiting.</span><br><span class="line">  PID  PPID S TT       COMMAND</span><br><span class="line">  273   238 S pts/3    -bash</span><br><span class="line">  409   273 S pts/3    ./a.out</span><br><span class="line">  410   409 Z pts/3    [a.out] &lt;defunct&gt;</span><br><span class="line">  411   409 S pts/3    sh -c ps -o pid,ppid,state,tty,<span class="built_in">command</span></span><br><span class="line">  412   411 R pts/3    ps -o pid,ppid,state,tty,<span class="built_in">command</span></span><br><span class="line">father process is exiting.</span><br></pre></td></tr></table></figure><p>很明显，父进程睡眠了，子进程退出之后，父进程并没有调用 <code>wati()</code>/<code>waitpid()</code>，因此子进程没有被回收，变成了僵尸进程。</p><h3 id="僵尸进程的解决办法"><a href="#僵尸进程的解决办法" class="headerlink" title="僵尸进程的解决办法"></a>僵尸进程的解决办法</h3><h4 id="信号机制"><a href="#信号机制" class="headerlink" title="信号机制"></a>信号机制</h4><p>子进程退出时向父进程发送 <code>SIGCHILD</code> 信号，父进程处理 <code>SIGCHILD</code> 信号。在信号处理函数中调用 <code>wait</code> 进行处理僵尸进程。测试程序如下所示：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;unistd.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;errno.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;signal.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">sig_child</span><span class="params">(<span class="keyword">int</span> signo)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">pid_t</span> pid;</span><br><span class="line">    <span class="comment">//创建捕捉子进程退出信号</span></span><br><span class="line">    signal(SIGCHLD,sig_child);</span><br><span class="line">    pid = fork();</span><br><span class="line">    <span class="keyword">if</span> (pid &lt; <span class="number">0</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        perror(<span class="string">"fork error:"</span>);</span><br><span class="line">        <span class="built_in">exit</span>(<span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span> (pid == <span class="number">0</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"I am child process,pid id %d.I am exiting.\n"</span>,getpid());</span><br><span class="line">        <span class="built_in">exit</span>(<span class="number">0</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"I am father process.I will sleep two seconds\n"</span>);</span><br><span class="line">    <span class="comment">//等待子进程先退出</span></span><br><span class="line">    sleep(<span class="number">2</span>);</span><br><span class="line">    <span class="comment">//输出进程信息</span></span><br><span class="line">    system(<span class="string">"ps -o pid,ppid,state,tty,command"</span>);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"father process is exiting.\n"</span>);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">sig_child</span><span class="params">(<span class="keyword">int</span> signo)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">     <span class="keyword">pid_t</span>        pid;</span><br><span class="line">     <span class="keyword">int</span>        stat;</span><br><span class="line">     <span class="comment">//处理僵尸进程</span></span><br><span class="line">     <span class="keyword">while</span> ((pid = waitpid(<span class="number">-1</span>, &amp;stat, WNOHANG)) &gt;<span class="number">0</span>)</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">"child %d terminated.\n"</span>, pid);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>我觉得是没啥用的，能记住要信号处理也就能记住要调用 <code>wait()</code>。</p></blockquote><h4 id="fork-两次"><a href="#fork-两次" class="headerlink" title="fork 两次"></a>fork 两次</h4><p>这个方法很有意思，《Unix 环境高级编程》8.6 节说的非常详细。原理是将子进程成为孤儿进程，从而其的父进程变为 init 进程，通过 init 进程可以处理僵尸进程。测试程序如下所示：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;unistd.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;errno.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">pid_t</span>  pid;</span><br><span class="line">    <span class="comment">//创建第一个子进程</span></span><br><span class="line">    pid = fork();</span><br><span class="line">    <span class="keyword">if</span> (pid &lt; <span class="number">0</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        perror(<span class="string">"fork error:"</span>);</span><br><span class="line">        <span class="built_in">exit</span>(<span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//第一个子进程</span></span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span> (pid == <span class="number">0</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="comment">//子进程再创建子进程</span></span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"I am the first child process.pid:%d\tppid:%d\n"</span>,getpid(),getppid());</span><br><span class="line">        pid = fork();</span><br><span class="line">        <span class="keyword">if</span> (pid &lt; <span class="number">0</span>)</span><br><span class="line">        &#123;</span><br><span class="line">            perror(<span class="string">"fork error:"</span>);</span><br><span class="line">            <span class="built_in">exit</span>(<span class="number">1</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//第一个子进程退出</span></span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span> (pid &gt;<span class="number">0</span>)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">"first procee is exited.\n"</span>);</span><br><span class="line">            <span class="built_in">exit</span>(<span class="number">0</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//第二个子进程</span></span><br><span class="line">        <span class="comment">//睡眠3s保证第一个子进程退出，这样第二个子进程的父亲就是init进程里</span></span><br><span class="line">        sleep(<span class="number">3</span>);</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"I am the second child process.pid: %d\tppid:%d\n"</span>,getpid(),getppid());</span><br><span class="line">        <span class="built_in">exit</span>(<span class="number">0</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//父进程处理第一个子进程退出</span></span><br><span class="line">    <span class="keyword">if</span> (waitpid(pid, <span class="literal">NULL</span>, <span class="number">0</span>) != pid)</span><br><span class="line">    &#123;</span><br><span class="line">        perror(<span class="string">"waitepid error:"</span>);</span><br><span class="line">        <span class="built_in">exit</span>(<span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">exit</span>(<span class="number">0</span>);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h4><ul><li><a href="https://www.cnblogs.com/Anker/p/3271773.html" target="_blank" rel="noopener">https://www.cnblogs.com/Anker/p/3271773.html</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近看到一个进程状态的博客写的比较好，转载记录复习，顺便加点自己的理解注释，形成了这篇文章。&lt;/p&gt;
    
    </summary>
    
      <category term="Linux" scheme="https://murphypei.github.io/categories/Linux/"/>
    
    
      <category term="Linux" scheme="https://murphypei.github.io/tags/Linux/"/>
    
      <category term="c++" scheme="https://murphypei.github.io/tags/c/"/>
    
      <category term="孤儿进程" scheme="https://murphypei.github.io/tags/%E5%AD%A4%E5%84%BF%E8%BF%9B%E7%A8%8B/"/>
    
      <category term="僵尸进程" scheme="https://murphypei.github.io/tags/%E5%83%B5%E5%B0%B8%E8%BF%9B%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>TensorFlow 显示运行中间结果方法</title>
    <link href="https://murphypei.github.io//blog/2019/08/tensorflow-show-layer.html"/>
    <id>https://murphypei.github.io//blog/2019/08/tensorflow-show-layer.html</id>
    <published>2019-08-26T03:22:25.000Z</published>
    <updated>2019-08-27T09:15:25.522Z</updated>
    
    <content type="html"><![CDATA[<p>TensorFlow 以静态图运行，因此想查看中间结果比较麻烦。本文以强化学习的 ppo 网络为例，结合代码注释提供一个思路。</p><a id="more"></a><p>首先是训练过程中模型的保存：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment"># graph.pbtxt</span></span><br><span class="line">tf.train.write_graph(sess.graph_def, path, filename, as_text)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ckpt</span></span><br><span class="line">saver = tf.train.Saver(&#123;var <span class="keyword">for</span> var <span class="keyword">in</span> tf.global_variables()&#125;, max_to_keep=<span class="number">5</span>)</span><br><span class="line">saver.restore(sess, ckpt.model_checkpoint_path)</span><br><span class="line">saver.save(sess, checkpoint_path)</span><br></pre></td></tr></table></figure><p>保存的模型应该有三个文件：<code>*.ckpt.index</code>，<code>*.ckpt.meta</code>，<code>*.ckpt.data-*</code>。之所以保存 <code>*.pbtxt</code>，是因为我们查看模型中间层的时候需要名字，<code>pbtxt</code> 是可以直接查看的模型结构文件，方便我们查看。然后如下调用进行 inference 和显示结果。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#! -*-coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    modelpath = <span class="string">r'../ppo/2/'</span>    <span class="comment"># 存放模型的地方</span></span><br><span class="line">    <span class="comment"># 加载模型和权重</span></span><br><span class="line">    saver = tf.train.import_meta_graph(modelpath + <span class="string">'model.ckpt.meta'</span>)</span><br><span class="line">    saver.restore(sess, tf.train.latest_checkpoint(modelpath))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 创建图</span></span><br><span class="line">    graph = tf.get_default_graph()</span><br><span class="line">    print(<span class="string">'Successfully load the pre-trained model!'</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 加载测试数据</span></span><br><span class="line">    observation_data = np.array(np.load(<span class="string">'../ppo/2/observation.npy'</span>))</span><br><span class="line">    observation_data = observation.reshape((<span class="number">1</span>,<span class="number">197</span>,<span class="number">1</span>))</span><br><span class="line">    print(observation_data.shape) </span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 设置输入 tensor</span></span><br><span class="line">    in_observation = graph.get_tensor_by_name(<span class="string">"ppo/observation:0"</span>) <span class="comment"># :0 表示 batch 中的第一个，如果 batch 是 1 就是全部结果了</span></span><br><span class="line">    print(in_observation.shape)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 设置输出 tensor</span></span><br><span class="line">    out_neglogps = graph.get_tensor_by_name(<span class="string">"ppo/neglogps:0"</span>)   <span class="comment"># :0 同输入</span></span><br><span class="line">    out_actions = graph.get_tensor_by_name(<span class="string">"ppo/actions:0"</span>)</span><br><span class="line">    out_values = graph.get_tensor_by_name(<span class="string">"ppo/values:0"</span>)</span><br><span class="line">    out_fetches = [out_neglogps, out_actions, out_values]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 需要输出的层，其实和输出 tensor 是一类的</span></span><br><span class="line">    mlp_fc0 = graph.get_tensor_by_name(<span class="string">"ppo/model/vf/add:0"</span>)</span><br><span class="line">    mid_fetches = [mlp_fc0]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 要显示的 tensor</span></span><br><span class="line">    fetches = out_fetches + mid_fetches</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 运行图</span></span><br><span class="line">    output = sess.run(fetches, feed_dict=&#123;in_observation: observation_data&#125;)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 打印结果</span></span><br><span class="line">    <span class="keyword">for</span> out <span class="keyword">in</span> output:</span><br><span class="line">        print(<span class="string">"out: "</span>, out)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;TensorFlow 以静态图运行，因此想查看中间结果比较麻烦。本文以强化学习的 ppo 网络为例，结合代码注释提供一个思路。&lt;/p&gt;
    
    </summary>
    
      <category term="深度学习" scheme="https://murphypei.github.io/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="tensorflow" scheme="https://murphypei.github.io/tags/tensorflow/"/>
    
      <category term="静态图" scheme="https://murphypei.github.io/tags/%E9%9D%99%E6%80%81%E5%9B%BE/"/>
    
      <category term="ckpt" scheme="https://murphypei.github.io/tags/ckpt/"/>
    
      <category term="meta" scheme="https://murphypei.github.io/tags/meta/"/>
    
  </entry>
  
  <entry>
    <title>clion 显示动态数组内容</title>
    <link href="https://murphypei.github.io//blog/2019/08/clion-show-dynamic-array.html"/>
    <id>https://murphypei.github.io//blog/2019/08/clion-show-dynamic-array.html</id>
    <published>2019-08-26T02:23:40.000Z</published>
    <updated>2019-08-27T09:15:25.521Z</updated>
    
    <content type="html"><![CDATA[<p>如果要想在 clion 中显示动态数组，直接显示是不行的，需要强制转换为数组格式。</p><a id="more"></a><p>比如如下动态数组指针：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">float</span> *input = <span class="keyword">new</span> <span class="keyword">float</span>[<span class="number">202</span>];</span><br><span class="line"><span class="comment">// fill array input</span></span><br></pre></td></tr></table></figure><p>在调试窗口中右键动态数组的指针，选择 Evaluate Expression，然后做一步转换：<code>(float (*)[202])input</code> ，这时候就会显示数组的内容了。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;如果要想在 clion 中显示动态数组，直接显示是不行的，需要强制转换为数组格式。&lt;/p&gt;
    
    </summary>
    
      <category term="C++" scheme="https://murphypei.github.io/categories/C/"/>
    
    
      <category term="C++" scheme="https://murphypei.github.io/tags/C/"/>
    
      <category term="IDE" scheme="https://murphypei.github.io/tags/IDE/"/>
    
      <category term="clion" scheme="https://murphypei.github.io/tags/clion/"/>
    
  </entry>
  
  <entry>
    <title>C++ 简单内存池实现</title>
    <link href="https://murphypei.github.io//blog/2019/07/memory-pooling.html"/>
    <id>https://murphypei.github.io//blog/2019/07/memory-pooling.html</id>
    <published>2019-07-27T05:54:03.000Z</published>
    <updated>2019-08-27T09:15:25.521Z</updated>
    
    <content type="html"><![CDATA[<p>我之前记录过一个关于 Linux 的 <code>malloc</code> 堆管理的详细介绍：<a href="https://murphypei.github.io/blog/2019/01/linux-heap.html">Linux 堆内存管理深入分析</a>，这篇文章是一个简易的 C++ 内存池的 demo。</p><a id="more"></a><h3 id="为什么需要内存池？"><a href="#为什么需要内存池？" class="headerlink" title="为什么需要内存池？"></a>为什么需要内存池？</h3><p>和线程池类似，这种 xx 池一般都是处于一个共同的目的：减少资源的频繁申请和释放。如果读了之前那篇堆管理的文章我们就知道，实际内存管理是非常复杂的，并不是每次 <code>malloc</code> 和 <code>free</code> 都是简单的申请和释放，这涉及一个效率问题，特别是在频繁的小容量的内存申请的时候。</p><p>一般在初始化的时候申请可用资源，然后重复利用这些资源，最后在不需要的时候统一销毁。</p><p>这里要说明一下，现代编译器的 <code>malloc</code> 管理内存的方式本质就是内存池，<code>malloc</code> 从操作系统申请堆内存，然后将内存划分给应用程序，并进行内存的释放，合并等等管理。大多数情况下，可能你自己设计的内存池还不如 <code>malloc</code> 管理的好，毕竟这些库都是很多人测试很多次了。因此，<strong>请谨慎判断是否需要内存池以及如何设计内存池</strong>。本文仅仅作为一个简单的 demo 来说明内存池的工作原理而已。</p><h3 id="内存池示例"><a href="#内存池示例" class="headerlink" title="内存池示例"></a>内存池示例</h3><p>下面主要以代码的方式进行说明。</p><h4 id="全局内存管理"><a href="#全局内存管理" class="headerlink" title="全局内存管理"></a>全局内存管理</h4><p>首先看一下平时没有内存池的时候对象的生成和释放：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> TEST_NUMBER 1000</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> ARRAY_SIZE 10000</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Rational</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    Rational(<span class="keyword">int</span> a, <span class="keyword">int</span> b = <span class="number">1</span>) : n(a), d(b) &#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="keyword">int</span> n;</span><br><span class="line">    <span class="keyword">int</span> d;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    Rational *arr[ARRAY_SIZE];</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; TEST_NUMBER; i++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; ARRAY_SIZE; ++j)</span><br><span class="line">        &#123;</span><br><span class="line">            arr[j] = <span class="keyword">new</span> Rational(j);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; ARRAY_SIZE; ++j)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">delete</span> arr[j];</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这种默认的时候就是使用全局的内存管理器，<code>new</code> 操作符调用对象的默认 <code>operator new</code> 函数申请内存，<code>operator new</code> 函数内部调用 <code>malloc</code> 申请能够放下对象的内存（大于等于对象的大小）。然后 <code>new</code> 操作符调用类的构造函数堆这块内存进行初始化。 <code>delete</code> 操作符则相反，先调用类的析构函数，然后调用 <code>free</code> 释放内存（不一定会返回给操作系统）。</p><h4 id="类专用内存池"><a href="#类专用内存池" class="headerlink" title="类专用内存池"></a>类专用内存池</h4><p>现在针对我们要用的这个类，使用一个专用的内存池：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;cstddef&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;cstdlib&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> TEST_NUMBER 1000</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> ARRAY_SIZE 10000</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">NextOnFreeList</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    NextOnFreeList *next;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Rational</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    Rational(<span class="keyword">int</span> a = <span class="number">0</span>, <span class="keyword">int</span> b = <span class="number">1</span>) : n(a), d(b) &#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">void</span> *<span class="keyword">operator</span> <span class="title">new</span><span class="params">(<span class="keyword">size_t</span> size)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (freeList == <span class="literal">nullptr</span>)</span><br><span class="line">        &#123;</span><br><span class="line">            expandFreeList();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">auto</span> head = freeList;</span><br><span class="line">        freeList = head-&gt;next;</span><br><span class="line">        <span class="keyword">return</span> head;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="keyword">operator</span> <span class="title">delete</span><span class="params">(<span class="keyword">void</span> *doomed)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        NextOnFreeList *head = <span class="keyword">static_cast</span>&lt;NextOnFreeList *&gt;(doomed);</span><br><span class="line">        head-&gt;next = freeList;</span><br><span class="line">        freeList = head;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">newMemPool</span><span class="params">()</span> </span>&#123; expandFreeList(); &#125;</span><br><span class="line">    <span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">deleteMemPool</span><span class="params">()</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="keyword">static</span> NextOnFreeList *freeList;</span><br><span class="line">    <span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">expandFreeList</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="keyword">static</span> <span class="keyword">const</span> <span class="keyword">size_t</span> EXPANSION_SIZE;</span><br><span class="line">    <span class="keyword">int</span> n;</span><br><span class="line">    <span class="keyword">int</span> d;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">void</span> Rational::deleteMemPool()</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">char</span> *nextPtr = (<span class="keyword">char</span> *)freeList;</span><br><span class="line">    <span class="keyword">while</span> (nextPtr != <span class="literal">nullptr</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        freeList = freeList-&gt;next;</span><br><span class="line">        <span class="keyword">delete</span>[] nextPtr;</span><br><span class="line">        nextPtr = (<span class="keyword">char</span> *)freeList;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> <span class="keyword">size_t</span> Rational::EXPANSION_SIZE = <span class="number">64</span>;</span><br><span class="line">NextOnFreeList *Rational::freeList = <span class="literal">nullptr</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">void</span> Rational::expandFreeList()</span><br><span class="line">&#123;</span><br><span class="line">    <span class="comment">// We must allocate an object large enough to contain the next pointer.  </span></span><br><span class="line">    <span class="keyword">size_t</span> size = (<span class="keyword">sizeof</span>(Rational) &gt; <span class="keyword">sizeof</span>(NextOnFreeList *)) ? <span class="keyword">sizeof</span>(Rational) : <span class="keyword">sizeof</span>(NextOnFreeList *);</span><br><span class="line">    NextOnFreeList *runner = (NextOnFreeList *)(<span class="keyword">new</span> <span class="keyword">char</span>[size]);</span><br><span class="line">    freeList = runner;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; Rational::EXPANSION_SIZE; ++i)</span><br><span class="line">    &#123;</span><br><span class="line">        runner-&gt;next = (NextOnFreeList *)(<span class="keyword">new</span> <span class="keyword">char</span>[size]);</span><br><span class="line">        runner = runner-&gt;next;</span><br><span class="line">    &#125;</span><br><span class="line">    runner-&gt;next = <span class="literal">nullptr</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    Rational *<span class="built_in">array</span>[ARRAY_SIZE];</span><br><span class="line"></span><br><span class="line">    Rational::newMemPool();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; TEST_NUMBER; j++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; ARRAY_SIZE; i++)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="built_in">array</span>[i] = <span class="keyword">new</span> Rational(i);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; ARRAY_SIZE; i++)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">delete</span> <span class="built_in">array</span>[i];</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    Rational::deleteMemPool();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>解释一下：</p><p><code>Rational</code> 这个类维持一个自己类对象专用的内存池，通过 <code>NextOnFreeList</code> 表示的一个空白内存链表进行维护。当我们需要申请内存的时候，直接将 <code>operator new</code> 指向空白链表中第一个节点，因此不需要再调用 <code>malloc</code> 了，而当链表没有空间了，则通过 <code>expandFreeList</code> 进行批量（<code>EXPANSION_SIZE</code>）的扩充，一次申请多块内存。释放的过程则直接将对象所在的节点加入到空白链表的头部，因此也不需要释放内存，减少了内存碎片的管理消耗。</p><p>这个空白链表很有意思，在分配的时候，我们将其看作一个 <code>NextOnFreeList</code> 节点，其中包含一个指针，指向下一个空白的内存块。而在使用的时候将其看作一个 <code>Rational</code> 对象存放的内存，因此申请的内存大小是二者的最大值。</p><h4 id="类模板内存池"><a href="#类模板内存池" class="headerlink" title="类模板内存池"></a>类模板内存池</h4><p>上述的内存池是 <code>Rational</code> 这个类专用的内存池，将上述代码改一改我们就能得到一个适用于不同类的内存池模板了。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;cstddef&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;cstdlib&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> TEST_NUMBER 1000</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> ARRAY_SIZE 10000</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MemoryPool</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    MemoryPool(<span class="keyword">size_t</span> size = EXPANSION_SIZE);</span><br><span class="line">    ~MemoryPool();</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">void</span> *<span class="title">alloc</span><span class="params">(<span class="keyword">size_t</span> size)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (next != <span class="literal">nullptr</span>)</span><br><span class="line">        &#123;</span><br><span class="line">            expandFreeList();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">auto</span> head = next;</span><br><span class="line">        next = next-&gt;next;</span><br><span class="line">        <span class="keyword">return</span> head;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">free</span><span class="params">(<span class="keyword">void</span> *doomed)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        MemoryPool&lt;T&gt; *head = (MemoryPool&lt;T&gt; *)doomed;</span><br><span class="line">        <span class="comment">// merge head to freeList front</span></span><br><span class="line">        head-&gt;next = next;</span><br><span class="line">        next = head;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    MemoryPool&lt;T&gt; *next;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">expandFreeList</span><span class="params">(<span class="keyword">size_t</span> size = EXPANSION_SIZE)</span></span>;</span><br><span class="line">    <span class="keyword">static</span> <span class="keyword">const</span> <span class="keyword">size_t</span> EXPANSION_SIZE = <span class="number">32</span>;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line">MemoryPool&lt;T&gt;::MemoryPool(<span class="keyword">size_t</span> size)</span><br><span class="line">&#123;</span><br><span class="line">    expandFreeList(size);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line">MemoryPool&lt;T&gt;::~MemoryPool()</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">char</span> *nextPtr = (<span class="keyword">char</span> *)next;</span><br><span class="line">    <span class="keyword">while</span> (nextPtr != <span class="literal">nullptr</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        next = next-&gt;next;</span><br><span class="line">        <span class="keyword">delete</span>[] nextPtr;</span><br><span class="line">        nextPtr = (<span class="keyword">char</span> *)next;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line"><span class="keyword">void</span> MemoryPool&lt;T&gt;::expandFreeList(<span class="keyword">size_t</span> size)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">size_t</span> memSize = <span class="keyword">sizeof</span>(T) &gt; <span class="keyword">sizeof</span>(MemoryPool&lt;T&gt; *) ? <span class="keyword">sizeof</span>(T) : <span class="keyword">sizeof</span>(MemoryPool&lt;T&gt; *);</span><br><span class="line">    MemoryPool&lt;T&gt; *runner = (MemoryPool&lt;T&gt; *)<span class="keyword">new</span> <span class="keyword">char</span>[memSize];</span><br><span class="line">    next = runner;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">size_t</span> i = <span class="number">0</span>; i &lt; size - <span class="number">1</span>; ++i)</span><br><span class="line">    &#123;</span><br><span class="line">        runner-&gt;next = (MemoryPool&lt;T&gt; *)<span class="keyword">new</span> <span class="keyword">char</span>[memSize];</span><br><span class="line">        runner = runner-&gt;next;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Rational</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    Rational(<span class="keyword">int</span> a = <span class="number">0</span>, <span class="keyword">int</span> b = <span class="number">1</span>) : n(a), d(b) &#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">void</span> *<span class="keyword">operator</span> <span class="title">new</span><span class="params">(<span class="keyword">size_t</span> size)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> memPool-&gt;alloc(size);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="keyword">operator</span> <span class="title">delete</span><span class="params">(<span class="keyword">void</span> *doomed)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        memPool-&gt;<span class="built_in">free</span>(doomed);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">newMemPool</span><span class="params">()</span> </span>&#123; memPool = <span class="keyword">new</span> MemoryPool&lt;Rational&gt;; &#125;</span><br><span class="line">    <span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">deleteMemPool</span><span class="params">()</span> </span>&#123; <span class="keyword">delete</span> memPool; &#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="keyword">int</span> n; <span class="comment">// Numerator</span></span><br><span class="line">    <span class="keyword">int</span> d; <span class="comment">// Denominator</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">static</span> MemoryPool&lt;Rational&gt; *memPool;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">MemoryPool&lt;Rational&gt; *Rational::memPool = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    Rational *<span class="built_in">array</span>[ARRAY_SIZE];</span><br><span class="line">    Rational::newMemPool();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; TEST_NUMBER; j++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; ARRAY_SIZE; i++)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="built_in">array</span>[i] = <span class="keyword">new</span> Rational(i);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; ARRAY_SIZE; i++)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">delete</span> <span class="built_in">array</span>[i];</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    Rational::deleteMemPool();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>MemoryPool</code> 可以看作将类作为模板参数包装的内存池，其原理和上述基本一模一样。而类的 <code>operator new</code> 和 <code>operator delete</code> 则通过调用 <code>MemoryPool</code> 的接口实现了内存的管理。</p><h4 id="可变大小块内存池"><a href="#可变大小块内存池" class="headerlink" title="可变大小块内存池"></a>可变大小块内存池</h4><p>上述的 <code>MemoryPool</code> 虽然适用于不同的类，但是其特化本质还是固定大小的，我们知道 <code>malloc</code> 可以申请任意大小的内存，我们的内存池往往也需要申请这种任意大小的内存块。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;cstddef&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;cstdlib&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> TEST_NUMBER 1000</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> ARRAY_SIZE 10000</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MemoryChunk</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    MemoryChunk(MemoryChunk *nextChunk, <span class="keyword">size_t</span> chunkSize);</span><br><span class="line">    ~MemoryChunk()</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">delete</span>[](<span class="keyword">char</span> *) mem;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">void</span> *<span class="title">alloc</span><span class="params">(<span class="keyword">size_t</span> requestSize)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="keyword">void</span> *addr = <span class="keyword">static_cast</span>&lt;<span class="keyword">void</span> *&gt;((<span class="keyword">char</span> *)mem + bytesAlreadyAllocated);</span><br><span class="line">        bytesAlreadyAllocated += requestSize;</span><br><span class="line">        <span class="keyword">return</span> addr;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">free</span><span class="params">(<span class="keyword">void</span> *doomed)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="comment">// <span class="doctag">TODO:</span> merge free chunk</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function">MemoryChunk *<span class="title">nextMemChunk</span><span class="params">()</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> next;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">size_t</span> spaceAvailable()</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">return</span> chunkSize - bytesAlreadyAllocated;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">static</span> <span class="keyword">const</span> <span class="keyword">size_t</span> DEFAULT_CHUNK_SIZE = <span class="number">4096</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    MemoryChunk *next;</span><br><span class="line">    <span class="keyword">void</span> *mem;</span><br><span class="line">    <span class="keyword">size_t</span> chunkSize;</span><br><span class="line">    <span class="keyword">size_t</span> bytesAlreadyAllocated;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">MemoryChunk::MemoryChunk(MemoryChunk *nextChunk, <span class="keyword">size_t</span> requestSize)</span><br><span class="line">&#123;</span><br><span class="line">    chunkSize = (requestSize &gt; DEFAULT_CHUNK_SIZE) ? requestSize : DEFAULT_CHUNK_SIZE;</span><br><span class="line">    next = nextChunk;</span><br><span class="line">    bytesAlreadyAllocated = <span class="number">0</span>;</span><br><span class="line">    mem = <span class="keyword">new</span> <span class="keyword">char</span>[chunkSize];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ByteMemoryPool</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    ByteMemoryPool(<span class="keyword">size_t</span> initSize = MemoryChunk::DEFAULT_CHUNK_SIZE);</span><br><span class="line">    ~ByteMemoryPool();</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">void</span> *<span class="title">alloc</span><span class="params">(<span class="keyword">size_t</span> size)</span></span>;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">free</span><span class="params">(<span class="keyword">void</span> *doomed)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    MemoryChunk *listOfMemoryChunks;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">expandStorage</span><span class="params">(<span class="keyword">size_t</span> requestSize)</span></span>;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">ByteMemoryPool::ByteMemoryPool(<span class="keyword">size_t</span> initSize) : listOfMemoryChunks(<span class="literal">nullptr</span>)</span><br><span class="line">&#123;</span><br><span class="line">    expandStorage(initSize);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">ByteMemoryPool::~ByteMemoryPool()</span><br><span class="line">&#123;</span><br><span class="line">    MemoryChunk *memChunk = listOfMemoryChunks;</span><br><span class="line">    <span class="keyword">while</span> (memChunk)</span><br><span class="line">    &#123;</span><br><span class="line">        listOfMemoryChunks = memChunk-&gt;nextMemChunk();</span><br><span class="line">        <span class="keyword">delete</span> memChunk;</span><br><span class="line">        memChunk = listOfMemoryChunks;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">void</span> *ByteMemoryPool::alloc(<span class="keyword">size_t</span> requestSize)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">size_t</span> space = listOfMemoryChunks-&gt;spaceAvailable();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// if there is not enough empty size in current chunk,  expand an new chunk and add to chunk list.</span></span><br><span class="line">    <span class="keyword">if</span> (space &lt; requestSize)</span><br><span class="line">    &#123;</span><br><span class="line">        expandStorage(requestSize);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> listOfMemoryChunks-&gt;alloc(requestSize);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">inline</span> <span class="keyword">void</span> ByteMemoryPool::<span class="built_in">free</span>(<span class="keyword">void</span> *doomed)</span><br><span class="line">&#123;</span><br><span class="line">    listOfMemoryChunks-&gt;<span class="built_in">free</span>(doomed);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">void</span> ByteMemoryPool::expandStorage(<span class="keyword">size_t</span> requestSize)</span><br><span class="line">&#123;</span><br><span class="line">    listOfMemoryChunks = <span class="keyword">new</span> MemoryChunk(listOfMemoryChunks, requestSize);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Rational</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    Rational(<span class="keyword">int</span> a = <span class="number">0</span>, <span class="keyword">int</span> b = <span class="number">1</span>) : n(a), d(b) &#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">void</span> *<span class="keyword">operator</span> <span class="title">new</span><span class="params">(<span class="keyword">size_t</span> size)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> memPool-&gt;alloc(size);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="keyword">operator</span> <span class="title">delete</span><span class="params">(<span class="keyword">void</span> *doomed)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        memPool-&gt;<span class="built_in">free</span>(doomed);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">newMemPool</span><span class="params">()</span> </span>&#123; memPool = <span class="keyword">new</span> ByteMemoryPool; &#125;</span><br><span class="line">    <span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">deleteMemPool</span><span class="params">()</span> </span>&#123; <span class="keyword">delete</span> memPool; &#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="keyword">int</span> n; <span class="comment">// Numerator</span></span><br><span class="line">    <span class="keyword">int</span> d; <span class="comment">// Denominator</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">static</span> ByteMemoryPool *memPool;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">ByteMemoryPool *Rational::memPool = <span class="literal">nullptr</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    Rational *<span class="built_in">array</span>[ARRAY_SIZE];</span><br><span class="line"></span><br><span class="line">    Rational::newMemPool();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; TEST_NUMBER; j++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; ARRAY_SIZE; i++)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="built_in">array</span>[i] = <span class="keyword">new</span> Rational(i);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; ARRAY_SIZE; i++)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">delete</span> <span class="built_in">array</span>[i];</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    Rational::deleteMemPool();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li><code>MemoryChunk</code> 和 <code>malloc</code> 中的 <code>chunk</code> 很像，可以是任意大小的，不同的 <code>MemoryChunk</code> 以链表的方式连接在一起。每个 <code>MemoryChunk</code> 记录块的大小和已经使用的内存大小。</li><li><code>ByteMemoryPool</code> 就是维护的内存池，当我们需要 <code>alloc</code> 的时候，我们检查当前的 <code>MemoryChunk</code> 是否有足够的空间来分配使用，不够的话则需要扩充一个大块，然后将其加入到链表中。</li></ul><p>最后再次强调，这个内存池 demo 非常的粗糙，远不及之前那篇堆内存管理介绍的那么复杂，仅仅是作为一个说明，说明内存池基本的工作原理。当然，内存池的管理还有多线程等等诸多复杂的问题需要考虑，因此才有开头我说的，一定要想想自己设计的需求以及性能。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;我之前记录过一个关于 Linux 的 &lt;code&gt;malloc&lt;/code&gt; 堆管理的详细介绍：&lt;a href=&quot;https://murphypei.github.io/blog/2019/01/linux-heap.html&quot;&gt;Linux 堆内存管理深入分析&lt;/a&gt;，这篇文章是一个简易的 C++ 内存池的 demo。&lt;/p&gt;
    
    </summary>
    
      <category term="C++" scheme="https://murphypei.github.io/categories/C/"/>
    
    
      <category term="C++" scheme="https://murphypei.github.io/tags/C/"/>
    
      <category term="malloc" scheme="https://murphypei.github.io/tags/malloc/"/>
    
      <category term="内存池" scheme="https://murphypei.github.io/tags/%E5%86%85%E5%AD%98%E6%B1%A0/"/>
    
      <category term="memory pooling" scheme="https://murphypei.github.io/tags/memory-pooling/"/>
    
  </entry>
  
  <entry>
    <title>线程安全和可重入函数</title>
    <link href="https://murphypei.github.io//blog/2019/07/thread-safe-reentrant-function.html"/>
    <id>https://murphypei.github.io//blog/2019/07/thread-safe-reentrant-function.html</id>
    <published>2019-07-16T07:58:43.000Z</published>
    <updated>2019-07-24T08:01:17.658Z</updated>
    
    <content type="html"><![CDATA[<p>今天看到一篇文章中提高 malloc 是线程安全的，但是不可重入。对这方面以前关注不多，因此找了一些资料，记录一下。</p><a id="more"></a><h3 id="线程安全"><a href="#线程安全" class="headerlink" title="线程安全"></a>线程安全</h3><p>首先明确线程不安全的原因，一般来说线程不安全主要是因为”共享数据”，那仫什仫是共享数据呢？主要有以下几个方面：</p><ul><li>函数的返回值被一个全局变量所接收</li><li>由调用者传入的线程间共享的指针变量或者引用变量</li><li>函数内部本来就会使用的共享静态变量</li></ul><p>通常来说，多线程是为了在同一时间内能够处理更多的同样类型的事情，但是线程不安全却阻碍了我们达到我们的目的。所以，我们有的时候不得不想方设法的把线程不安全的函数改写成线程安全的。也就是虽然会发生这些情况，但是我们也可以通过互斥锁等机制达到线程安全的目的，将一个不安全的线程函数变得安全。</p><p>而对于线程安全，我们可以简单的认为就是多线程调用的结果不会发生改变。</p><blockquote><p>一个函数被称为线程安全的（thread-safe），当且仅当被多个并发进程反复调用时，它会一直产生正确的结果。</p></blockquote><h3 id="可重入函数"><a href="#可重入函数" class="headerlink" title="可重入函数"></a>可重入函数</h3><p>首先了解一下什么叫做函数的重入：</p><blockquote><p>如果一个函数被不同的执行流程调用，就有可能在上一次调用还没有完成时再次进入该函数，这就叫重入。</p></blockquote><p>什么意思呢？比如一个函数有 5 条执行语句，第一个线程调用时执行到第 3 条语句，第二个线程也开始调用了，也就是多个线程同时进入这个函数了，发生了函数的重入。</p><p>举个 CSDN 上面看到的例子：</p><p><img src="/images/posts/cplusplus/reentrant-function.png" alt="函数重入调用"></p><p>由上图可知当一个函数访问一个全局链表，就有可能因为重入而造成丢失数据（看红色注释），这就叫不可重入函数；相反的，如果一个函数值调用自己的局部变量和函数，则称为可重入函数。确保一个函数是可重入函数应该满足以下几个条件：</p><ul><li>不在函数内部使用静态或者是全局变量</li><li>不返回静态或全局数据，数据的产生都由调用者提供</li><li>尽量使用本地数据，或者通过重新定义变量拷贝全局变量来保护全局变量</li><li>不调用不可重入函数</li></ul><p>可重入函数又分为显式可重入和隐式可重入：</p><ul><li>显式可重入函数：如果所有函数的参数都是传值传递的(没有指针)，并且所有的数据引用都是本地的自动栈变量(也就是说没有引用静态或全局变量)，那么函数就是显示可重入的，也就是说无论如何调用，我们都可确定它是可重入的。</li><li>隐式可重入函数：可重入函数中的一些参数是引用传递(使用了指针)，也就是说，在调用线程的时候传递指向非共享数据的指针时，它才是可重入的。</li></ul><p>如果满足以下条件则是一定是不可重入的：</p><ul><li>函数体内使用了静态的数据结构</li><li>通过 malloc 和 free 来申请和释放内存，因为 malloc 是通过全局链表来管理堆的</li><li>调用了标准 I/O 库，因为库里存在大多数都是以不可重入的方式使用全局变量或者是静态变量</li></ul><p>为什么线程锁不能达到可重入目的呢？想一想互斥两个字的含义吧。</p><h3 id="可重入和线程安全的关系"><a href="#可重入和线程安全的关系" class="headerlink" title="可重入和线程安全的关系"></a>可重入和线程安全的关系</h3><p>很明显，<strong>可重入函数规则更加严格：可重入函数一定是线程安全的，但是线程安全函数不一定可重入</strong>。最显著的例子就是本文开头提到的 malloc 了。</p><p>我们知道 malloc 在堆上分配内存，而其内部为了效率，维护了一个堆块链表，这个链表是全局静态变量。但是我们也清楚 malloc 的很多实现都是线程安全的，比如 <code>libc</code> 中有非线程安全/线程安全两个版本 malloc 函数，而且编译器会智能帮你选择是不是需要线程安全的 malloc，因为线程安全会降低效率。那么线程安全的 malloc 是怎么做到的呢，就是前面提到的线程互斥锁。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;今天看到一篇文章中提高 malloc 是线程安全的，但是不可重入。对这方面以前关注不多，因此找了一些资料，记录一下。&lt;/p&gt;
    
    </summary>
    
      <category term="C++" scheme="https://murphypei.github.io/categories/C/"/>
    
    
      <category term="C++" scheme="https://murphypei.github.io/tags/C/"/>
    
      <category term="线程安全" scheme="https://murphypei.github.io/tags/%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8/"/>
    
      <category term="可重入函数" scheme="https://murphypei.github.io/tags/%E5%8F%AF%E9%87%8D%E5%85%A5%E5%87%BD%E6%95%B0/"/>
    
      <category term="malloc" scheme="https://murphypei.github.io/tags/malloc/"/>
    
  </entry>
  
</feed>
